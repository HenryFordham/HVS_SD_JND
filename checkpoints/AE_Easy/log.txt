[2022-07-16 13:39:21,871][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-16 13:39:21,871][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-16 13:39:28,513][feature_train_ori.py][L382][INFO] DataParallel(
  (module): Concatenation(
    (relu): LeakyReLU(negative_slope=0.01)
    (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
    (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
    (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
    (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
    (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
    (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv11): ConvTranspose2d(4096, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (conv12): ConvTranspose2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
    (conv13): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (conv14): ConvTranspose2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
    (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
    (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
    (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
    (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
    (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
  )
)
[2022-07-16 13:43:03,421][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-16 13:43:03,421][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-16 13:43:10,069][feature_train_ori.py][L382][INFO] DataParallel(
  (module): Concatenation(
    (relu): LeakyReLU(negative_slope=0.01)
    (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
    (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
    (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
    (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
    (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
    (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv11): ConvTranspose2d(4096, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (conv12): ConvTranspose2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
    (conv13): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (conv14): ConvTranspose2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
    (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
    (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
    (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
    (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
    (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
  )
)
[2022-07-16 13:43:13,245][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-16 13:43:47,196][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-16 13:43:47,197][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-16 13:43:53,774][feature_train_ori.py][L382][INFO] DataParallel(
  (module): Concatenation(
    (relu): LeakyReLU(negative_slope=0.01)
    (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
    (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
    (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
    (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
    (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
    (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv11): ConvTranspose2d(4096, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (conv12): ConvTranspose2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
    (conv13): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (conv14): ConvTranspose2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
    (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
    (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
    (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
    (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
    (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
  )
)
[2022-07-16 13:43:56,934][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-16 13:45:22,987][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-16 13:45:22,987][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-16 13:45:29,569][feature_train_ori.py][L382][INFO] DataParallel(
  (module): Concatenation(
    (relu): LeakyReLU(negative_slope=0.01)
    (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
    (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
    (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
    (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
    (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
    (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv11): ConvTranspose2d(4096, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (conv12): ConvTranspose2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
    (conv13): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (conv14): ConvTranspose2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
    (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
    (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
    (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
    (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
    (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
  )
)
[2022-07-16 13:45:32,721][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-16 13:47:09,421][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-16 13:47:09,422][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-16 13:47:15,980][feature_train_ori.py][L382][INFO] DataParallel(
  (module): Concatenation(
    (relu): LeakyReLU(negative_slope=0.01)
    (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
    (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
    (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
    (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
    (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
    (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv11): ConvTranspose2d(4096, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (conv12): ConvTranspose2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
    (conv13): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (conv14): ConvTranspose2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
    (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
    (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
    (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
    (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
    (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
  )
)
[2022-07-16 13:47:19,131][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-16 13:48:11,683][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-16 13:48:11,683][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-16 13:48:18,260][feature_train_ori.py][L382][INFO] DataParallel(
  (module): Concatenation(
    (relu): LeakyReLU(negative_slope=0.01)
    (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
    (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
    (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
    (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
    (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
    (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv11): ConvTranspose2d(4096, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (conv12): ConvTranspose2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
    (conv13): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (conv14): ConvTranspose2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
    (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
    (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
    (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
    (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
    (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
  )
)
[2022-07-16 13:48:21,463][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-16 13:49:47,931][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-16 13:49:47,931][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-16 13:49:54,579][feature_train_ori.py][L382][INFO] DataParallel(
  (module): Concatenation(
    (relu): LeakyReLU(negative_slope=0.01)
    (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
    (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
    (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
    (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
    (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
    (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv11): ConvTranspose2d(4096, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (conv12): ConvTranspose2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
    (conv13): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (conv14): ConvTranspose2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
    (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
    (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
    (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
    (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
    (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
  )
)
[2022-07-16 13:49:57,729][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-16 13:52:38,701][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-16 13:52:38,701][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-16 13:52:45,325][feature_train_ori.py][L382][INFO] DataParallel(
  (module): Concatenation(
    (relu): LeakyReLU(negative_slope=0.01)
    (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
    (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
    (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
    (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
    (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
    (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv11): ConvTranspose2d(4096, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (conv12): ConvTranspose2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
    (conv13): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (conv14): ConvTranspose2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
    (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
    (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
    (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
    (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
    (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
  )
)
[2022-07-16 13:52:48,486][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-16 13:54:55,272][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-16 13:54:55,273][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-16 13:55:01,879][feature_train_ori.py][L383][INFO] DataParallel(
  (module): Concatenation(
    (relu): LeakyReLU(negative_slope=0.01)
    (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
    (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
    (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
    (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
    (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
    (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv11): ConvTranspose2d(4096, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (conv12): ConvTranspose2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
    (conv13): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (conv14): ConvTranspose2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
    (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
    (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
    (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
    (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
    (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
  )
)
[2022-07-16 13:55:05,037][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-16 14:05:33,412][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-16 14:05:33,413][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-16 14:05:39,982][feature_train_ori.py][L383][INFO] DataParallel(
  (module): Concatenation(
    (relu): LeakyReLU(negative_slope=0.01)
    (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
    (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
    (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
    (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
    (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
    (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv11): ConvTranspose2d(4096, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (conv12): ConvTranspose2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
    (conv13): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (conv14): ConvTranspose2d(512, 128, kernel_size=(1, 1), stride=(1, 1))
    (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
    (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
    (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
    (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
    (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
  )
)
[2022-07-16 14:05:47,184][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-16 14:07:28,539][feature_train_ori.py][L341][INFO] Step [1/2500000=0.00%] | Epoch 0 | Time 100.838 (100.838) | Lr 0.0001 | AIC Loss 0.02496 (0.02496) | All Losses 0.28056 (0.28056)
[2022-07-16 14:08:41,901][feature_train_ori.py][L341][INFO] Step [2/2500000=0.00%] | Epoch 0 | Time 73.336 (73.336) | Lr 0.0001 | AIC Loss 0.06718 (0.06718) | All Losses 0.25894 (0.25894)
[2022-07-16 14:09:53,404][feature_train_ori.py][L341][INFO] Step [3/2500000=0.00%] | Epoch 0 | Time 71.479 (71.479) | Lr 0.0001 | AIC Loss 0.08584 (0.08584) | All Losses 0.23578 (0.23578)
[2022-07-16 14:11:02,044][feature_train_ori.py][L341][INFO] Step [4/2500000=0.00%] | Epoch 0 | Time 68.614 (68.614) | Lr 0.0001 | AIC Loss 0.07158 (0.07158) | All Losses 0.22842 (0.22842)
[2022-07-16 14:12:10,827][feature_train_ori.py][L341][INFO] Step [5/2500000=0.00%] | Epoch 0 | Time 68.758 (68.758) | Lr 0.0001 | AIC Loss 0.05883 (0.05883) | All Losses 0.22355 (0.22355)
[2022-07-16 14:13:19,438][feature_train_ori.py][L341][INFO] Step [6/2500000=0.00%] | Epoch 0 | Time 68.585 (68.585) | Lr 0.0001 | AIC Loss 0.07550 (0.07550) | All Losses 0.23493 (0.23493)
[2022-07-16 14:14:28,180][feature_train_ori.py][L341][INFO] Step [7/2500000=0.00%] | Epoch 0 | Time 68.717 (68.717) | Lr 0.0001 | AIC Loss 0.06727 (0.06727) | All Losses 0.21296 (0.21296)
[2022-07-16 14:15:36,683][feature_train_ori.py][L341][INFO] Step [8/2500000=0.00%] | Epoch 0 | Time 68.476 (68.476) | Lr 0.0001 | AIC Loss 0.07544 (0.07544) | All Losses 0.20368 (0.20368)
[2022-07-16 14:16:45,488][feature_train_ori.py][L341][INFO] Step [9/2500000=0.00%] | Epoch 0 | Time 68.780 (68.780) | Lr 0.0001 | AIC Loss 0.06573 (0.06573) | All Losses 0.20337 (0.20337)
[2022-07-16 14:17:54,138][feature_train_ori.py][L341][INFO] Step [10/2500000=0.00%] | Epoch 0 | Time 68.625 (68.625) | Lr 0.0001 | AIC Loss 0.06797 (0.06797) | All Losses 0.19770 (0.19770)
[2022-07-16 14:19:04,854][feature_train_ori.py][L341][INFO] Step [11/2500000=0.00%] | Epoch 0 | Time 69.001 (69.001) | Lr 0.0001 | AIC Loss 0.05341 (0.05341) | All Losses 0.21192 (0.21192)
[2022-07-16 14:20:13,419][feature_train_ori.py][L341][INFO] Step [12/2500000=0.00%] | Epoch 0 | Time 68.540 (68.540) | Lr 0.0001 | AIC Loss 0.06742 (0.06742) | All Losses 0.21971 (0.21971)
[2022-07-16 14:21:22,722][feature_train_ori.py][L341][INFO] Step [13/2500000=0.00%] | Epoch 0 | Time 69.278 (69.278) | Lr 0.0001 | AIC Loss 0.06770 (0.06770) | All Losses 0.19662 (0.19662)
[2022-07-16 14:22:31,500][feature_train_ori.py][L341][INFO] Step [14/2500000=0.00%] | Epoch 0 | Time 68.751 (68.751) | Lr 0.0001 | AIC Loss 0.07839 (0.07839) | All Losses 0.21692 (0.21692)
[2022-07-16 14:23:39,906][feature_train_ori.py][L341][INFO] Step [15/2500000=0.00%] | Epoch 0 | Time 68.379 (68.379) | Lr 0.0001 | AIC Loss 0.07928 (0.07928) | All Losses 0.20632 (0.20632)
[2022-07-16 14:24:48,826][feature_train_ori.py][L341][INFO] Step [16/2500000=0.00%] | Epoch 0 | Time 68.895 (68.895) | Lr 0.0001 | AIC Loss 0.06117 (0.06117) | All Losses 0.20009 (0.20009)
[2022-07-16 14:25:57,751][feature_train_ori.py][L341][INFO] Step [17/2500000=0.00%] | Epoch 0 | Time 68.902 (68.902) | Lr 0.0001 | AIC Loss 0.05506 (0.05506) | All Losses 0.20863 (0.20863)
[2022-07-16 14:27:06,343][feature_train_ori.py][L341][INFO] Step [18/2500000=0.00%] | Epoch 0 | Time 68.567 (68.567) | Lr 0.0001 | AIC Loss 0.06412 (0.06412) | All Losses 0.22255 (0.22255)
[2022-07-16 14:28:14,712][feature_train_ori.py][L341][INFO] Step [19/2500000=0.00%] | Epoch 0 | Time 68.343 (68.343) | Lr 0.0001 | AIC Loss 0.06729 (0.06729) | All Losses 0.20091 (0.20091)
[2022-07-16 14:29:23,131][feature_train_ori.py][L341][INFO] Step [20/2500000=0.00%] | Epoch 0 | Time 68.394 (68.394) | Lr 0.0001 | AIC Loss 0.06649 (0.06649) | All Losses 0.20195 (0.20195)
[2022-07-16 14:30:33,509][feature_train_ori.py][L341][INFO] Step [21/2500000=0.00%] | Epoch 0 | Time 68.660 (68.660) | Lr 0.0001 | AIC Loss 0.07020 (0.07020) | All Losses 0.20401 (0.20401)
[2022-07-16 14:31:41,868][feature_train_ori.py][L341][INFO] Step [22/2500000=0.00%] | Epoch 0 | Time 68.332 (68.332) | Lr 0.0001 | AIC Loss 0.08011 (0.08011) | All Losses 0.19916 (0.19916)
[2022-07-16 14:32:50,098][feature_train_ori.py][L341][INFO] Step [23/2500000=0.00%] | Epoch 0 | Time 68.205 (68.205) | Lr 0.0001 | AIC Loss 0.06793 (0.06793) | All Losses 0.19341 (0.19341)
[2022-07-16 14:33:58,596][feature_train_ori.py][L341][INFO] Step [24/2500000=0.00%] | Epoch 0 | Time 68.472 (68.472) | Lr 0.0001 | AIC Loss 0.07043 (0.07043) | All Losses 0.20575 (0.20575)
[2022-07-16 14:35:07,826][feature_train_ori.py][L341][INFO] Step [25/2500000=0.00%] | Epoch 0 | Time 69.204 (69.204) | Lr 0.0001 | AIC Loss 0.06820 (0.06820) | All Losses 0.21061 (0.21061)
[2022-07-16 14:36:16,193][feature_train_ori.py][L341][INFO] Step [26/2500000=0.00%] | Epoch 0 | Time 68.341 (68.341) | Lr 0.0001 | AIC Loss 0.06688 (0.06688) | All Losses 0.19363 (0.19363)
[2022-07-16 14:37:24,645][feature_train_ori.py][L341][INFO] Step [27/2500000=0.00%] | Epoch 0 | Time 68.426 (68.426) | Lr 0.0001 | AIC Loss 0.07003 (0.07003) | All Losses 0.20322 (0.20322)
[2022-07-16 14:38:32,801][feature_train_ori.py][L341][INFO] Step [28/2500000=0.00%] | Epoch 0 | Time 68.131 (68.131) | Lr 0.0001 | AIC Loss 0.06005 (0.06005) | All Losses 0.20076 (0.20076)
[2022-07-16 14:39:40,831][feature_train_ori.py][L341][INFO] Step [29/2500000=0.00%] | Epoch 0 | Time 68.006 (68.006) | Lr 0.0001 | AIC Loss 0.06159 (0.06159) | All Losses 0.18462 (0.18462)
[2022-07-16 14:40:48,845][feature_train_ori.py][L341][INFO] Step [30/2500000=0.00%] | Epoch 0 | Time 67.989 (67.989) | Lr 0.0001 | AIC Loss 0.07174 (0.07174) | All Losses 0.19619 (0.19619)
[2022-07-16 14:41:58,883][feature_train_ori.py][L341][INFO] Step [31/2500000=0.00%] | Epoch 0 | Time 68.366 (68.366) | Lr 0.0001 | AIC Loss 0.08136 (0.08136) | All Losses 0.20858 (0.20858)
[2022-07-16 14:43:07,476][feature_train_ori.py][L341][INFO] Step [32/2500000=0.00%] | Epoch 0 | Time 68.568 (68.568) | Lr 0.0001 | AIC Loss 0.07954 (0.07954) | All Losses 0.20542 (0.20542)
[2022-07-16 14:44:16,000][feature_train_ori.py][L341][INFO] Step [33/2500000=0.00%] | Epoch 0 | Time 68.501 (68.501) | Lr 0.0001 | AIC Loss 0.05124 (0.05124) | All Losses 0.20281 (0.20281)
[2022-07-16 14:45:24,666][feature_train_ori.py][L341][INFO] Step [34/2500000=0.00%] | Epoch 0 | Time 68.641 (68.641) | Lr 0.0001 | AIC Loss 0.05417 (0.05417) | All Losses 0.18636 (0.18636)
[2022-07-16 14:46:33,239][feature_train_ori.py][L341][INFO] Step [35/2500000=0.00%] | Epoch 0 | Time 68.548 (68.548) | Lr 0.0001 | AIC Loss 0.07391 (0.07391) | All Losses 0.19592 (0.19592)
[2022-07-16 14:47:41,779][feature_train_ori.py][L341][INFO] Step [36/2500000=0.00%] | Epoch 0 | Time 68.515 (68.515) | Lr 0.0001 | AIC Loss 0.07644 (0.07644) | All Losses 0.19412 (0.19412)
[2022-07-16 14:48:50,593][feature_train_ori.py][L341][INFO] Step [37/2500000=0.00%] | Epoch 0 | Time 68.789 (68.789) | Lr 0.0001 | AIC Loss 0.06282 (0.06282) | All Losses 0.17827 (0.17827)
[2022-07-16 14:49:59,213][feature_train_ori.py][L341][INFO] Step [38/2500000=0.00%] | Epoch 0 | Time 68.596 (68.596) | Lr 0.0001 | AIC Loss 0.07259 (0.07259) | All Losses 0.18228 (0.18228)
[2022-07-16 14:51:07,988][feature_train_ori.py][L341][INFO] Step [39/2500000=0.00%] | Epoch 0 | Time 68.749 (68.749) | Lr 0.0001 | AIC Loss 0.06944 (0.06944) | All Losses 0.18970 (0.18970)
[2022-07-16 14:52:16,317][feature_train_ori.py][L341][INFO] Step [40/2500000=0.00%] | Epoch 0 | Time 68.304 (68.304) | Lr 0.0001 | AIC Loss 0.07083 (0.07083) | All Losses 0.19150 (0.19150)
[2022-07-16 14:53:27,074][feature_train_ori.py][L341][INFO] Step [41/2500000=0.00%] | Epoch 0 | Time 69.036 (69.036) | Lr 0.0001 | AIC Loss 0.06420 (0.06420) | All Losses 0.19780 (0.19780)
[2022-07-16 14:54:35,798][feature_train_ori.py][L341][INFO] Step [42/2500000=0.00%] | Epoch 0 | Time 68.693 (68.693) | Lr 0.0001 | AIC Loss 0.05740 (0.05740) | All Losses 0.17556 (0.17556)
[2022-07-16 14:55:44,257][feature_train_ori.py][L341][INFO] Step [43/2500000=0.00%] | Epoch 0 | Time 68.431 (68.431) | Lr 0.0001 | AIC Loss 0.06082 (0.06082) | All Losses 0.20504 (0.20504)
[2022-07-16 14:56:52,205][feature_train_ori.py][L341][INFO] Step [44/2500000=0.00%] | Epoch 0 | Time 67.922 (67.922) | Lr 0.0001 | AIC Loss 0.06795 (0.06795) | All Losses 0.18411 (0.18411)
[2022-07-16 14:58:00,050][feature_train_ori.py][L341][INFO] Step [45/2500000=0.00%] | Epoch 0 | Time 67.818 (67.818) | Lr 0.0001 | AIC Loss 0.06574 (0.06574) | All Losses 0.17178 (0.17178)
[2022-07-16 14:59:07,982][feature_train_ori.py][L341][INFO] Step [46/2500000=0.00%] | Epoch 0 | Time 67.907 (67.907) | Lr 0.0001 | AIC Loss 0.06532 (0.06532) | All Losses 0.17244 (0.17244)
[2022-07-16 15:00:16,166][feature_train_ori.py][L341][INFO] Step [47/2500000=0.00%] | Epoch 0 | Time 68.157 (68.157) | Lr 0.0001 | AIC Loss 0.05559 (0.05559) | All Losses 0.18079 (0.18079)
[2022-07-16 15:01:24,051][feature_train_ori.py][L341][INFO] Step [48/2500000=0.00%] | Epoch 0 | Time 67.860 (67.860) | Lr 0.0001 | AIC Loss 0.07557 (0.07557) | All Losses 0.20218 (0.20218)
[2022-07-16 15:02:31,995][feature_train_ori.py][L341][INFO] Step [49/2500000=0.00%] | Epoch 0 | Time 67.917 (67.917) | Lr 0.0001 | AIC Loss 0.06284 (0.06284) | All Losses 0.17101 (0.17101)
[2022-07-16 15:03:40,430][feature_train_ori.py][L341][INFO] Step [50/2500000=0.00%] | Epoch 0 | Time 68.407 (68.407) | Lr 0.0001 | AIC Loss 0.07064 (0.07064) | All Losses 0.17861 (0.17861)
[2022-07-16 15:04:51,024][feature_train_ori.py][L341][INFO] Step [51/2500000=0.00%] | Epoch 0 | Time 68.914 (68.914) | Lr 0.0001 | AIC Loss 0.06572 (0.06572) | All Losses 0.18637 (0.18637)
[2022-07-16 15:05:59,377][feature_train_ori.py][L341][INFO] Step [52/2500000=0.00%] | Epoch 0 | Time 68.326 (68.326) | Lr 0.0001 | AIC Loss 0.05897 (0.05897) | All Losses 0.17540 (0.17540)
[2022-07-16 15:07:07,454][feature_train_ori.py][L341][INFO] Step [53/2500000=0.00%] | Epoch 0 | Time 68.052 (68.052) | Lr 0.0001 | AIC Loss 0.06832 (0.06832) | All Losses 0.18267 (0.18267)
[2022-07-16 15:08:15,833][feature_train_ori.py][L341][INFO] Step [54/2500000=0.00%] | Epoch 0 | Time 68.354 (68.354) | Lr 0.0001 | AIC Loss 0.06360 (0.06360) | All Losses 0.17548 (0.17548)
[2022-07-16 15:09:24,111][feature_train_ori.py][L341][INFO] Step [55/2500000=0.00%] | Epoch 0 | Time 68.253 (68.253) | Lr 0.0001 | AIC Loss 0.08319 (0.08319) | All Losses 0.20920 (0.20920)
[2022-07-16 15:10:32,177][feature_train_ori.py][L341][INFO] Step [56/2500000=0.00%] | Epoch 0 | Time 68.042 (68.042) | Lr 0.0001 | AIC Loss 0.06479 (0.06479) | All Losses 0.17526 (0.17526)
[2022-07-16 15:11:40,261][feature_train_ori.py][L341][INFO] Step [57/2500000=0.00%] | Epoch 0 | Time 68.059 (68.059) | Lr 0.0001 | AIC Loss 0.05925 (0.05925) | All Losses 0.17727 (0.17727)
[2022-07-16 15:12:48,263][feature_train_ori.py][L341][INFO] Step [58/2500000=0.00%] | Epoch 0 | Time 67.977 (67.977) | Lr 0.0001 | AIC Loss 0.06827 (0.06827) | All Losses 0.19257 (0.19257)
[2022-07-16 15:13:55,886][feature_train_ori.py][L341][INFO] Step [59/2500000=0.00%] | Epoch 0 | Time 67.597 (67.597) | Lr 0.0001 | AIC Loss 0.07950 (0.07950) | All Losses 0.19938 (0.19938)
[2022-07-16 15:15:03,761][feature_train_ori.py][L341][INFO] Step [60/2500000=0.00%] | Epoch 0 | Time 67.849 (67.849) | Lr 0.0001 | AIC Loss 0.07307 (0.07307) | All Losses 0.17476 (0.17476)
[2022-07-16 15:16:13,939][feature_train_ori.py][L341][INFO] Step [61/2500000=0.00%] | Epoch 0 | Time 68.505 (68.505) | Lr 0.0001 | AIC Loss 0.06637 (0.06637) | All Losses 0.17441 (0.17441)
[2022-07-16 15:17:22,153][feature_train_ori.py][L341][INFO] Step [62/2500000=0.00%] | Epoch 0 | Time 68.188 (68.188) | Lr 0.0001 | AIC Loss 0.07335 (0.07335) | All Losses 0.20061 (0.20061)
[2022-07-16 15:18:30,184][feature_train_ori.py][L341][INFO] Step [63/2500000=0.00%] | Epoch 0 | Time 68.007 (68.007) | Lr 0.0001 | AIC Loss 0.07181 (0.07181) | All Losses 0.19515 (0.19515)
[2022-07-16 15:19:38,877][feature_train_ori.py][L341][INFO] Step [64/2500000=0.00%] | Epoch 0 | Time 68.668 (68.668) | Lr 0.0001 | AIC Loss 0.06195 (0.06195) | All Losses 0.17898 (0.17898)
[2022-07-16 15:20:47,200][feature_train_ori.py][L341][INFO] Step [65/2500000=0.00%] | Epoch 0 | Time 68.299 (68.299) | Lr 0.0001 | AIC Loss 0.05657 (0.05657) | All Losses 0.18266 (0.18266)
[2022-07-16 15:21:55,101][feature_train_ori.py][L341][INFO] Step [66/2500000=0.00%] | Epoch 0 | Time 67.876 (67.876) | Lr 0.0001 | AIC Loss 0.06671 (0.06671) | All Losses 0.18526 (0.18526)
[2022-07-16 15:23:03,180][feature_train_ori.py][L341][INFO] Step [67/2500000=0.00%] | Epoch 0 | Time 68.054 (68.054) | Lr 0.0001 | AIC Loss 0.06814 (0.06814) | All Losses 0.18502 (0.18502)
[2022-07-16 15:24:11,374][feature_train_ori.py][L341][INFO] Step [68/2500000=0.00%] | Epoch 0 | Time 68.170 (68.170) | Lr 0.0001 | AIC Loss 0.06533 (0.06533) | All Losses 0.18954 (0.18954)
[2022-07-16 15:25:19,467][feature_train_ori.py][L341][INFO] Step [69/2500000=0.00%] | Epoch 0 | Time 68.067 (68.067) | Lr 0.0001 | AIC Loss 0.06568 (0.06568) | All Losses 0.19507 (0.19507)
[2022-07-16 15:26:27,797][feature_train_ori.py][L341][INFO] Step [70/2500000=0.00%] | Epoch 0 | Time 68.307 (68.307) | Lr 0.0001 | AIC Loss 0.06793 (0.06793) | All Losses 0.18018 (0.18018)
[2022-07-16 15:27:37,320][feature_train_ori.py][L341][INFO] Step [71/2500000=0.00%] | Epoch 0 | Time 67.818 (67.818) | Lr 0.0001 | AIC Loss 0.06408 (0.06408) | All Losses 0.17525 (0.17525)
[2022-07-16 15:28:45,443][feature_train_ori.py][L341][INFO] Step [72/2500000=0.00%] | Epoch 0 | Time 68.099 (68.099) | Lr 0.0001 | AIC Loss 0.06360 (0.06360) | All Losses 0.18190 (0.18190)
[2022-07-16 15:29:53,706][feature_train_ori.py][L341][INFO] Step [73/2500000=0.00%] | Epoch 0 | Time 68.239 (68.239) | Lr 0.0001 | AIC Loss 0.06347 (0.06347) | All Losses 0.19392 (0.19392)
[2022-07-16 15:31:01,762][feature_train_ori.py][L341][INFO] Step [74/2500000=0.00%] | Epoch 0 | Time 68.033 (68.033) | Lr 0.0001 | AIC Loss 0.07146 (0.07146) | All Losses 0.18236 (0.18236)
[2022-07-16 15:32:09,755][feature_train_ori.py][L341][INFO] Step [75/2500000=0.00%] | Epoch 0 | Time 67.966 (67.966) | Lr 0.0001 | AIC Loss 0.06889 (0.06889) | All Losses 0.16988 (0.16988)
[2022-07-16 15:33:17,773][feature_train_ori.py][L341][INFO] Step [76/2500000=0.00%] | Epoch 0 | Time 67.994 (67.994) | Lr 0.0001 | AIC Loss 0.07109 (0.07109) | All Losses 0.18017 (0.18017)
[2022-07-16 15:34:25,790][feature_train_ori.py][L341][INFO] Step [77/2500000=0.00%] | Epoch 0 | Time 67.991 (67.991) | Lr 0.0001 | AIC Loss 0.06236 (0.06236) | All Losses 0.17568 (0.17568)
[2022-07-16 15:35:33,636][feature_train_ori.py][L341][INFO] Step [78/2500000=0.00%] | Epoch 0 | Time 67.823 (67.823) | Lr 0.0001 | AIC Loss 0.06246 (0.06246) | All Losses 0.18573 (0.18573)
[2022-07-16 15:36:42,067][feature_train_ori.py][L341][INFO] Step [79/2500000=0.00%] | Epoch 0 | Time 68.407 (68.407) | Lr 0.0001 | AIC Loss 0.05487 (0.05487) | All Losses 0.17628 (0.17628)
[2022-07-16 15:37:50,559][feature_train_ori.py][L341][INFO] Step [80/2500000=0.00%] | Epoch 0 | Time 68.468 (68.468) | Lr 0.0001 | AIC Loss 0.06186 (0.06186) | All Losses 0.18030 (0.18030)
[2022-07-16 15:39:00,443][feature_train_ori.py][L341][INFO] Step [81/2500000=0.00%] | Epoch 0 | Time 68.171 (68.171) | Lr 0.0001 | AIC Loss 0.06675 (0.06675) | All Losses 0.18483 (0.18483)
[2022-07-16 15:40:08,783][feature_train_ori.py][L341][INFO] Step [82/2500000=0.00%] | Epoch 0 | Time 68.317 (68.317) | Lr 0.0001 | AIC Loss 0.06714 (0.06714) | All Losses 0.17613 (0.17613)
[2022-07-16 15:41:16,849][feature_train_ori.py][L341][INFO] Step [83/2500000=0.00%] | Epoch 0 | Time 68.042 (68.042) | Lr 0.0001 | AIC Loss 0.06625 (0.06625) | All Losses 0.18024 (0.18024)
[2022-07-16 15:42:25,009][feature_train_ori.py][L341][INFO] Step [84/2500000=0.00%] | Epoch 0 | Time 68.136 (68.136) | Lr 0.0001 | AIC Loss 0.05808 (0.05808) | All Losses 0.18460 (0.18460)
[2022-07-16 15:43:33,122][feature_train_ori.py][L341][INFO] Step [85/2500000=0.00%] | Epoch 0 | Time 68.088 (68.088) | Lr 0.0001 | AIC Loss 0.06283 (0.06283) | All Losses 0.17428 (0.17428)
[2022-07-16 15:44:41,244][feature_train_ori.py][L341][INFO] Step [86/2500000=0.00%] | Epoch 0 | Time 68.099 (68.099) | Lr 0.0001 | AIC Loss 0.05904 (0.05904) | All Losses 0.17869 (0.17869)
[2022-07-16 15:45:49,622][feature_train_ori.py][L341][INFO] Step [87/2500000=0.00%] | Epoch 0 | Time 68.355 (68.355) | Lr 0.0001 | AIC Loss 0.06130 (0.06130) | All Losses 0.17750 (0.17750)
[2022-07-16 15:46:57,479][feature_train_ori.py][L341][INFO] Step [88/2500000=0.00%] | Epoch 0 | Time 67.832 (67.832) | Lr 0.0001 | AIC Loss 0.07135 (0.07135) | All Losses 0.17412 (0.17412)
[2022-07-16 15:48:05,645][feature_train_ori.py][L341][INFO] Step [89/2500000=0.00%] | Epoch 0 | Time 68.140 (68.140) | Lr 0.0001 | AIC Loss 0.06895 (0.06895) | All Losses 0.17428 (0.17428)
[2022-07-16 15:49:13,735][feature_train_ori.py][L341][INFO] Step [90/2500000=0.00%] | Epoch 0 | Time 68.066 (68.066) | Lr 0.0001 | AIC Loss 0.06121 (0.06121) | All Losses 0.18116 (0.18116)
[2022-07-16 15:50:23,528][feature_train_ori.py][L341][INFO] Step [91/2500000=0.00%] | Epoch 0 | Time 68.091 (68.091) | Lr 0.0001 | AIC Loss 0.05501 (0.05501) | All Losses 0.17551 (0.17551)
[2022-07-16 15:51:31,504][feature_train_ori.py][L341][INFO] Step [92/2500000=0.00%] | Epoch 0 | Time 67.951 (67.951) | Lr 0.0001 | AIC Loss 0.05808 (0.05808) | All Losses 0.17330 (0.17330)
[2022-07-16 15:52:39,748][feature_train_ori.py][L341][INFO] Step [93/2500000=0.00%] | Epoch 0 | Time 68.219 (68.219) | Lr 0.0001 | AIC Loss 0.07359 (0.07359) | All Losses 0.19422 (0.19422)
[2022-07-16 22:12:13,221][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-16 22:12:13,221][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-16 22:12:19,339][feature_train_ori.py][L383][INFO] DataParallel(
  (module): Concatenation(
    (relu): LeakyReLU(negative_slope=0.01)
    (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
    (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
    (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
    (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
    (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
    (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
    (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
    (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv11): Conv2d(4096, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)
    (conv12): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)
    (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
    (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
    (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
    (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
    (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
  )
)
[2022-07-16 22:12:26,818][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-16 22:15:35,140][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-16 22:15:35,140][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-16 22:15:41,197][feature_train_ori.py][L383][INFO] Concatenation(
  (relu): LeakyReLU(negative_slope=0.01)
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
  (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
  (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv11): Conv2d(4096, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)
  (conv12): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)
  (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
  (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
  (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
)
[2022-07-16 22:15:48,496][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-16 22:17:02,816][feature_train_ori.py][L341][INFO] Step [1/2500000=0.00%] | Epoch 0 | Time 73.857 (73.857) | Lr 0.0001 | AIC Loss 0.01841 (0.01841) | All Losses 0.13850 (0.13850)
[2022-07-16 22:18:15,869][feature_train_ori.py][L341][INFO] Step [2/2500000=0.00%] | Epoch 0 | Time 73.037 (73.037) | Lr 0.0001 | AIC Loss 0.38794 (0.38794) | All Losses 0.45330 (0.45330)
[2022-07-16 22:19:26,557][feature_train_ori.py][L341][INFO] Step [3/2500000=0.00%] | Epoch 0 | Time 70.669 (70.669) | Lr 0.0001 | AIC Loss 0.28186 (0.28186) | All Losses 0.32086 (0.32086)
[2022-07-16 22:20:37,031][feature_train_ori.py][L341][INFO] Step [4/2500000=0.00%] | Epoch 0 | Time 70.455 (70.455) | Lr 0.0001 | AIC Loss 0.21933 (0.21933) | All Losses 0.23517 (0.23517)
[2022-07-16 22:21:47,917][feature_train_ori.py][L341][INFO] Step [5/2500000=0.00%] | Epoch 0 | Time 70.867 (70.867) | Lr 0.0001 | AIC Loss 0.15506 (0.15506) | All Losses 0.16899 (0.16899)
[2022-07-16 22:22:59,492][feature_train_ori.py][L341][INFO] Step [6/2500000=0.00%] | Epoch 0 | Time 71.558 (71.558) | Lr 0.0001 | AIC Loss 0.10621 (0.10621) | All Losses 0.12599 (0.12599)
[2022-07-16 22:24:11,319][feature_train_ori.py][L341][INFO] Step [7/2500000=0.00%] | Epoch 0 | Time 71.808 (71.808) | Lr 0.0001 | AIC Loss 0.03568 (0.03568) | All Losses 0.11528 (0.11528)
[2022-07-16 22:25:22,859][feature_train_ori.py][L341][INFO] Step [8/2500000=0.00%] | Epoch 0 | Time 71.521 (71.521) | Lr 0.0001 | AIC Loss 0.03950 (0.03950) | All Losses 0.09822 (0.09822)
[2022-07-16 22:26:33,933][feature_train_ori.py][L341][INFO] Step [9/2500000=0.00%] | Epoch 0 | Time 71.056 (71.056) | Lr 0.0001 | AIC Loss 0.05669 (0.05669) | All Losses 0.11702 (0.11702)
[2022-07-16 22:27:45,132][feature_train_ori.py][L341][INFO] Step [10/2500000=0.00%] | Epoch 0 | Time 71.180 (71.180) | Lr 0.0001 | AIC Loss 0.06274 (0.06274) | All Losses 0.10016 (0.10016)
[2022-07-16 22:29:02,748][feature_train_ori.py][L341][INFO] Step [11/2500000=0.00%] | Epoch 0 | Time 71.825 (71.825) | Lr 0.0001 | AIC Loss 0.05882 (0.05882) | All Losses 0.08300 (0.08300)
[2022-07-16 22:30:15,547][feature_train_ori.py][L341][INFO] Step [12/2500000=0.00%] | Epoch 0 | Time 72.781 (72.781) | Lr 0.0001 | AIC Loss 0.06138 (0.06138) | All Losses 0.09403 (0.09403)
[2022-07-16 22:31:26,860][feature_train_ori.py][L341][INFO] Step [13/2500000=0.00%] | Epoch 0 | Time 71.294 (71.294) | Lr 0.0001 | AIC Loss 0.06268 (0.06268) | All Losses 0.09030 (0.09030)
[2022-07-16 22:32:38,665][feature_train_ori.py][L341][INFO] Step [14/2500000=0.00%] | Epoch 0 | Time 71.787 (71.787) | Lr 0.0001 | AIC Loss 0.04635 (0.04635) | All Losses 0.08413 (0.08413)
[2022-07-16 22:33:51,282][feature_train_ori.py][L341][INFO] Step [15/2500000=0.00%] | Epoch 0 | Time 72.599 (72.599) | Lr 0.0001 | AIC Loss 0.03945 (0.03945) | All Losses 0.08486 (0.08486)
[2022-07-16 22:35:03,596][feature_train_ori.py][L341][INFO] Step [16/2500000=0.00%] | Epoch 0 | Time 72.296 (72.296) | Lr 0.0001 | AIC Loss 0.05101 (0.05101) | All Losses 0.09587 (0.09587)
[2022-07-16 22:36:14,847][feature_train_ori.py][L341][INFO] Step [17/2500000=0.00%] | Epoch 0 | Time 71.233 (71.233) | Lr 0.0001 | AIC Loss 0.04505 (0.04505) | All Losses 0.08957 (0.08957)
[2022-07-16 22:37:26,142][feature_train_ori.py][L341][INFO] Step [18/2500000=0.00%] | Epoch 0 | Time 71.277 (71.277) | Lr 0.0001 | AIC Loss 0.04328 (0.04328) | All Losses 0.07948 (0.07948)
[2022-07-16 22:38:39,084][feature_train_ori.py][L341][INFO] Step [19/2500000=0.00%] | Epoch 0 | Time 72.924 (72.924) | Lr 0.0001 | AIC Loss 0.04803 (0.04803) | All Losses 0.08987 (0.08987)
[2022-07-16 22:39:49,705][feature_train_ori.py][L341][INFO] Step [20/2500000=0.00%] | Epoch 0 | Time 70.602 (70.602) | Lr 0.0001 | AIC Loss 0.04738 (0.04738) | All Losses 0.09183 (0.09183)
[2022-07-16 22:41:06,493][feature_train_ori.py][L341][INFO] Step [21/2500000=0.00%] | Epoch 0 | Time 70.773 (70.773) | Lr 0.0001 | AIC Loss 0.05410 (0.05410) | All Losses 0.09135 (0.09135)
[2022-07-16 22:42:16,777][feature_train_ori.py][L341][INFO] Step [22/2500000=0.00%] | Epoch 0 | Time 70.256 (70.256) | Lr 0.0001 | AIC Loss 0.05058 (0.05058) | All Losses 0.07200 (0.07200)
[2022-07-16 22:43:29,238][feature_train_ori.py][L341][INFO] Step [23/2500000=0.00%] | Epoch 0 | Time 72.443 (72.443) | Lr 0.0001 | AIC Loss 0.04019 (0.04019) | All Losses 0.08118 (0.08118)
[2022-07-16 22:44:40,338][feature_train_ori.py][L341][INFO] Step [24/2500000=0.00%] | Epoch 0 | Time 71.081 (71.081) | Lr 0.0001 | AIC Loss 0.03749 (0.03749) | All Losses 0.08554 (0.08554)
[2022-07-16 22:45:52,389][feature_train_ori.py][L341][INFO] Step [25/2500000=0.00%] | Epoch 0 | Time 72.033 (72.033) | Lr 0.0001 | AIC Loss 0.03987 (0.03987) | All Losses 0.07838 (0.07838)
[2022-07-16 22:47:03,734][feature_train_ori.py][L341][INFO] Step [26/2500000=0.00%] | Epoch 0 | Time 71.327 (71.327) | Lr 0.0001 | AIC Loss 0.05655 (0.05655) | All Losses 0.08998 (0.08998)
[2022-07-16 22:48:15,504][feature_train_ori.py][L341][INFO] Step [27/2500000=0.00%] | Epoch 0 | Time 71.752 (71.752) | Lr 0.0001 | AIC Loss 0.05188 (0.05188) | All Losses 0.09427 (0.09427)
[2022-07-16 22:49:27,044][feature_train_ori.py][L341][INFO] Step [28/2500000=0.00%] | Epoch 0 | Time 71.522 (71.522) | Lr 0.0001 | AIC Loss 0.04842 (0.04842) | All Losses 0.07686 (0.07686)
[2022-07-16 22:50:38,378][feature_train_ori.py][L341][INFO] Step [29/2500000=0.00%] | Epoch 0 | Time 71.314 (71.314) | Lr 0.0001 | AIC Loss 0.05314 (0.05314) | All Losses 0.09630 (0.09630)
[2022-07-16 22:51:49,050][feature_train_ori.py][L341][INFO] Step [30/2500000=0.00%] | Epoch 0 | Time 70.653 (70.653) | Lr 0.0001 | AIC Loss 0.05234 (0.05234) | All Losses 0.08484 (0.08484)
[2022-07-16 22:53:05,988][feature_train_ori.py][L341][INFO] Step [31/2500000=0.00%] | Epoch 0 | Time 71.059 (71.059) | Lr 0.0001 | AIC Loss 0.04368 (0.04368) | All Losses 0.07778 (0.07778)
[2022-07-16 22:54:16,312][feature_train_ori.py][L341][INFO] Step [32/2500000=0.00%] | Epoch 0 | Time 70.296 (70.296) | Lr 0.0001 | AIC Loss 0.04684 (0.04684) | All Losses 0.09141 (0.09141)
[2022-07-16 22:55:26,659][feature_train_ori.py][L341][INFO] Step [33/2500000=0.00%] | Epoch 0 | Time 70.327 (70.327) | Lr 0.0001 | AIC Loss 0.04346 (0.04346) | All Losses 0.07493 (0.07493)
[2022-07-16 22:56:37,786][feature_train_ori.py][L341][INFO] Step [34/2500000=0.00%] | Epoch 0 | Time 71.109 (71.109) | Lr 0.0001 | AIC Loss 0.03955 (0.03955) | All Losses 0.07472 (0.07472)
[2022-07-16 22:57:48,532][feature_train_ori.py][L341][INFO] Step [35/2500000=0.00%] | Epoch 0 | Time 70.726 (70.726) | Lr 0.0001 | AIC Loss 0.03920 (0.03920) | All Losses 0.07459 (0.07459)
[2022-07-16 22:59:00,106][feature_train_ori.py][L341][INFO] Step [36/2500000=0.00%] | Epoch 0 | Time 71.556 (71.556) | Lr 0.0001 | AIC Loss 0.04192 (0.04192) | All Losses 0.07723 (0.07723)
[2022-07-16 23:00:10,809][feature_train_ori.py][L341][INFO] Step [37/2500000=0.00%] | Epoch 0 | Time 70.682 (70.682) | Lr 0.0001 | AIC Loss 0.04778 (0.04778) | All Losses 0.08584 (0.08584)
[2022-07-16 23:01:23,208][feature_train_ori.py][L341][INFO] Step [38/2500000=0.00%] | Epoch 0 | Time 72.381 (72.381) | Lr 0.0001 | AIC Loss 0.04721 (0.04721) | All Losses 0.08799 (0.08799)
[2022-07-16 23:02:35,118][feature_train_ori.py][L341][INFO] Step [39/2500000=0.00%] | Epoch 0 | Time 71.892 (71.892) | Lr 0.0001 | AIC Loss 0.04058 (0.04058) | All Losses 0.07963 (0.07963)
[2022-07-16 23:03:44,716][feature_train_ori.py][L341][INFO] Step [40/2500000=0.00%] | Epoch 0 | Time 69.580 (69.580) | Lr 0.0001 | AIC Loss 0.03872 (0.03872) | All Losses 0.06569 (0.06569)
[2022-07-16 23:05:05,242][feature_train_ori.py][L341][INFO] Step [41/2500000=0.00%] | Epoch 0 | Time 71.991 (71.991) | Lr 0.0001 | AIC Loss 0.04883 (0.04883) | All Losses 0.08284 (0.08284)
[2022-07-16 23:08:07,501][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-16 23:08:07,501][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-16 23:08:13,694][feature_train_ori.py][L383][INFO] Concatenation(
  (relu): LeakyReLU(negative_slope=0.01)
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
  (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
  (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv11): Conv2d(4096, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)
  (conv12): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)
  (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
  (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
  (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
)
[2022-07-16 23:08:21,202][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-16 23:09:36,491][feature_train_ori.py][L341][INFO] Step [1/2500000=0.00%] | Epoch 0 | Time 74.825 (74.825) | Lr 0.0001 | AIC Loss 0.02702 (0.02702) | All Losses 1.44192 (1.44192)
[2022-07-16 23:10:49,896][feature_train_ori.py][L341][INFO] Step [2/2500000=0.00%] | Epoch 0 | Time 73.385 (73.385) | Lr 0.0001 | AIC Loss 0.38609 (0.38609) | All Losses 0.41133 (0.41133)
[2022-07-16 23:12:00,818][feature_train_ori.py][L341][INFO] Step [3/2500000=0.00%] | Epoch 0 | Time 70.904 (70.904) | Lr 0.0001 | AIC Loss 0.35148 (0.35148) | All Losses 0.36478 (0.36478)
[2022-07-16 23:13:11,940][feature_train_ori.py][L341][INFO] Step [4/2500000=0.00%] | Epoch 0 | Time 71.104 (71.104) | Lr 0.0001 | AIC Loss 0.31598 (0.31598) | All Losses 0.35351 (0.35351)
[2022-07-16 23:14:24,630][feature_train_ori.py][L341][INFO] Step [5/2500000=0.00%] | Epoch 0 | Time 72.672 (72.672) | Lr 0.0001 | AIC Loss 0.31200 (0.31200) | All Losses 0.40558 (0.40558)
[2022-07-16 23:15:36,116][feature_train_ori.py][L341][INFO] Step [6/2500000=0.00%] | Epoch 0 | Time 71.467 (71.467) | Lr 0.0001 | AIC Loss 0.29935 (0.29935) | All Losses 0.43316 (0.43316)
[2022-07-16 23:16:46,986][feature_train_ori.py][L341][INFO] Step [7/2500000=0.00%] | Epoch 0 | Time 70.852 (70.852) | Lr 0.0001 | AIC Loss 0.27850 (0.27850) | All Losses 0.35614 (0.35614)
[2022-07-16 23:17:57,888][feature_train_ori.py][L341][INFO] Step [8/2500000=0.00%] | Epoch 0 | Time 70.884 (70.884) | Lr 0.0001 | AIC Loss 0.25610 (0.25610) | All Losses 0.41873 (0.41873)
[2022-07-16 23:19:10,127][feature_train_ori.py][L341][INFO] Step [9/2500000=0.00%] | Epoch 0 | Time 72.221 (72.221) | Lr 0.0001 | AIC Loss 0.24912 (0.24912) | All Losses 0.47747 (0.47747)
[2022-07-16 23:20:21,684][feature_train_ori.py][L341][INFO] Step [10/2500000=0.00%] | Epoch 0 | Time 71.540 (71.540) | Lr 0.0001 | AIC Loss 0.25806 (0.25806) | All Losses 0.32802 (0.32802)
[2022-07-16 23:21:41,704][feature_train_ori.py][L341][INFO] Step [11/2500000=0.00%] | Epoch 0 | Time 73.288 (73.288) | Lr 0.0001 | AIC Loss 0.24695 (0.24695) | All Losses 0.31918 (0.31918)
[2022-07-16 23:22:53,796][feature_train_ori.py][L341][INFO] Step [12/2500000=0.00%] | Epoch 0 | Time 72.074 (72.074) | Lr 0.0001 | AIC Loss 0.23077 (0.23077) | All Losses 0.36645 (0.36645)
[2022-07-16 23:23:38,510][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-16 23:23:38,511][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-16 23:23:44,698][feature_train_ori.py][L383][INFO] Concatenation(
  (relu): LeakyReLU(negative_slope=0.01)
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
  (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
  (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv11): Conv2d(4096, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)
  (conv12): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)
  (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
  (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
  (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
)
[2022-07-16 23:23:52,004][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-16 23:25:07,948][feature_train_ori.py][L341][INFO] Step [1/2500000=0.00%] | Epoch 0 | Time 75.495 (75.495) | Lr 0.0001 | AIC Loss 0.03135 (0.03135) | All Losses 0.15375 (0.15375)
[2022-07-16 23:26:22,114][feature_train_ori.py][L341][INFO] Step [2/2500000=0.00%] | Epoch 0 | Time 74.148 (74.148) | Lr 0.0001 | AIC Loss 0.32107 (0.32107) | All Losses 0.33387 (0.33387)
[2022-07-16 23:27:33,243][feature_train_ori.py][L341][INFO] Step [3/2500000=0.00%] | Epoch 0 | Time 71.111 (71.111) | Lr 0.0001 | AIC Loss 0.17740 (0.17740) | All Losses 0.21616 (0.21616)
[2022-07-16 23:28:44,188][feature_train_ori.py][L341][INFO] Step [4/2500000=0.00%] | Epoch 0 | Time 70.928 (70.928) | Lr 0.0001 | AIC Loss 0.06457 (0.06457) | All Losses 0.14474 (0.14474)
[2022-07-16 23:29:55,731][feature_train_ori.py][L341][INFO] Step [5/2500000=0.00%] | Epoch 0 | Time 71.525 (71.525) | Lr 0.0001 | AIC Loss 0.04095 (0.04095) | All Losses 0.13295 (0.13295)
[2022-07-16 23:31:07,071][feature_train_ori.py][L341][INFO] Step [6/2500000=0.00%] | Epoch 0 | Time 71.322 (71.322) | Lr 0.0001 | AIC Loss 0.03689 (0.03689) | All Losses 0.14723 (0.14723)
[2022-07-16 23:32:17,890][feature_train_ori.py][L341][INFO] Step [7/2500000=0.00%] | Epoch 0 | Time 70.801 (70.801) | Lr 0.0001 | AIC Loss 0.02937 (0.02937) | All Losses 0.14703 (0.14703)
[2022-07-16 23:33:23,473][feature_train_ori.py][L341][INFO] Step [8/2500000=0.00%] | Epoch 0 | Time 65.565 (65.565) | Lr 0.0001 | AIC Loss 0.03019 (0.03019) | All Losses 0.13276 (0.13276)
[2022-07-16 23:34:29,004][feature_train_ori.py][L341][INFO] Step [9/2500000=0.00%] | Epoch 0 | Time 65.513 (65.513) | Lr 0.0001 | AIC Loss 0.04046 (0.04046) | All Losses 0.14944 (0.14944)
[2022-07-16 23:35:34,901][feature_train_ori.py][L341][INFO] Step [10/2500000=0.00%] | Epoch 0 | Time 65.880 (65.880) | Lr 0.0001 | AIC Loss 0.02839 (0.02839) | All Losses 0.13597 (0.13597)
[2022-07-16 23:36:45,291][feature_train_ori.py][L341][INFO] Step [11/2500000=0.00%] | Epoch 0 | Time 64.597 (64.597) | Lr 0.0001 | AIC Loss 0.03075 (0.03075) | All Losses 0.12361 (0.12361)
[2022-07-16 23:37:50,782][feature_train_ori.py][L341][INFO] Step [12/2500000=0.00%] | Epoch 0 | Time 65.473 (65.473) | Lr 0.0001 | AIC Loss 0.04298 (0.04298) | All Losses 0.13650 (0.13650)
[2022-07-16 23:38:56,210][feature_train_ori.py][L341][INFO] Step [13/2500000=0.00%] | Epoch 0 | Time 65.410 (65.410) | Lr 0.0001 | AIC Loss 0.03502 (0.03502) | All Losses 0.13843 (0.13843)
[2022-07-16 23:40:01,938][feature_train_ori.py][L341][INFO] Step [14/2500000=0.00%] | Epoch 0 | Time 65.710 (65.710) | Lr 0.0001 | AIC Loss 0.03556 (0.03556) | All Losses 0.13724 (0.13724)
[2022-07-16 23:41:06,653][feature_train_ori.py][L341][INFO] Step [15/2500000=0.00%] | Epoch 0 | Time 64.697 (64.697) | Lr 0.0001 | AIC Loss 0.03566 (0.03566) | All Losses 0.13271 (0.13271)
[2022-07-16 23:42:11,554][feature_train_ori.py][L341][INFO] Step [16/2500000=0.00%] | Epoch 0 | Time 64.883 (64.883) | Lr 0.0001 | AIC Loss 0.03581 (0.03581) | All Losses 0.12612 (0.12612)
[2022-07-16 23:43:17,237][feature_train_ori.py][L341][INFO] Step [17/2500000=0.00%] | Epoch 0 | Time 65.666 (65.666) | Lr 0.0001 | AIC Loss 0.03090 (0.03090) | All Losses 0.12261 (0.12261)
[2022-07-16 23:44:23,267][feature_train_ori.py][L341][INFO] Step [18/2500000=0.00%] | Epoch 0 | Time 66.012 (66.012) | Lr 0.0001 | AIC Loss 0.02925 (0.02925) | All Losses 0.13462 (0.13462)
[2022-07-16 23:45:31,825][feature_train_ori.py][L341][INFO] Step [19/2500000=0.00%] | Epoch 0 | Time 68.539 (68.539) | Lr 0.0001 | AIC Loss 0.03654 (0.03654) | All Losses 0.12905 (0.12905)
[2022-07-16 23:46:42,463][feature_train_ori.py][L341][INFO] Step [20/2500000=0.00%] | Epoch 0 | Time 70.621 (70.621) | Lr 0.0001 | AIC Loss 0.03402 (0.03402) | All Losses 0.13189 (0.13189)
[2022-07-16 23:47:58,168][feature_train_ori.py][L341][INFO] Step [21/2500000=0.00%] | Epoch 0 | Time 69.740 (69.740) | Lr 0.0001 | AIC Loss 0.03475 (0.03475) | All Losses 0.13098 (0.13098)
[2022-07-16 23:49:08,700][feature_train_ori.py][L341][INFO] Step [22/2500000=0.00%] | Epoch 0 | Time 70.514 (70.514) | Lr 0.0001 | AIC Loss 0.02823 (0.02823) | All Losses 0.12616 (0.12616)
[2022-07-21 21:55:28,522][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-21 21:55:28,523][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-21 21:55:36,637][feature_train_ori.py][L383][INFO] Concatenation(
  (relu): LeakyReLU(negative_slope=0.01)
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv11): ConvTranspose2d(4096, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv11_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv12): ConvTranspose2d(512, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv12_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
  (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
  (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
)
[2022-07-21 21:55:46,362][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-21 21:56:54,036][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-21 21:56:54,036][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-21 21:56:59,866][feature_train_ori.py][L383][INFO] Concatenation(
  (relu): LeakyReLU(negative_slope=0.01)
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv11): ConvTranspose2d(4096, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv11_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv12): ConvTranspose2d(512, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv12_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
  (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
  (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
)
[2022-07-21 21:57:06,925][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-21 21:58:18,660][feature_train_ori.py][L341][INFO] Step [1/2500000=0.00%] | Epoch 0 | Time 71.245 (71.245) | Lr 0.0001 | AIC Loss 0.02253 (0.02253) | All Losses 0.28396 (0.28396)
[2022-07-21 21:59:30,023][feature_train_ori.py][L341][INFO] Step [2/2500000=0.00%] | Epoch 0 | Time 71.347 (71.347) | Lr 0.0001 | AIC Loss 0.08497 (0.08497) | All Losses 0.21675 (0.21675)
[2022-07-21 22:00:39,173][feature_train_ori.py][L341][INFO] Step [3/2500000=0.00%] | Epoch 0 | Time 69.136 (69.136) | Lr 0.0001 | AIC Loss 0.12581 (0.12581) | All Losses 0.23265 (0.23265)
[2022-07-21 22:01:47,599][feature_train_ori.py][L341][INFO] Step [4/2500000=0.00%] | Epoch 0 | Time 68.408 (68.408) | Lr 0.0001 | AIC Loss 0.08429 (0.08429) | All Losses 0.21024 (0.21024)
[2022-07-21 22:02:56,134][feature_train_ori.py][L341][INFO] Step [5/2500000=0.00%] | Epoch 0 | Time 68.520 (68.520) | Lr 0.0001 | AIC Loss 0.06153 (0.06153) | All Losses 0.20268 (0.20268)
[2022-07-21 22:04:04,874][feature_train_ori.py][L341][INFO] Step [6/2500000=0.00%] | Epoch 0 | Time 68.725 (68.725) | Lr 0.0001 | AIC Loss 0.06035 (0.06035) | All Losses 0.20940 (0.20940)
[2022-07-21 22:05:14,897][feature_train_ori.py][L341][INFO] Step [7/2500000=0.00%] | Epoch 0 | Time 70.006 (70.006) | Lr 0.0001 | AIC Loss 0.04547 (0.04547) | All Losses 0.20016 (0.20016)
[2022-07-21 22:06:24,222][feature_train_ori.py][L341][INFO] Step [8/2500000=0.00%] | Epoch 0 | Time 69.305 (69.305) | Lr 0.0001 | AIC Loss 0.09039 (0.09039) | All Losses 0.22674 (0.22674)
[2022-07-21 22:07:33,127][feature_train_ori.py][L341][INFO] Step [9/2500000=0.00%] | Epoch 0 | Time 68.885 (68.885) | Lr 0.0001 | AIC Loss 0.08332 (0.08332) | All Losses 0.21511 (0.21511)
[2022-07-21 22:08:43,548][feature_train_ori.py][L341][INFO] Step [10/2500000=0.00%] | Epoch 0 | Time 70.400 (70.400) | Lr 0.0001 | AIC Loss 0.07375 (0.07375) | All Losses 0.19142 (0.19142)
[2022-07-21 22:09:58,743][feature_train_ori.py][L341][INFO] Step [11/2500000=0.00%] | Epoch 0 | Time 68.891 (68.891) | Lr 0.0001 | AIC Loss 0.06308 (0.06308) | All Losses 0.20062 (0.20062)
[2022-07-21 22:11:08,121][feature_train_ori.py][L341][INFO] Step [12/2500000=0.00%] | Epoch 0 | Time 69.360 (69.360) | Lr 0.0001 | AIC Loss 0.06297 (0.06297) | All Losses 0.20794 (0.20794)
[2022-07-21 22:12:17,498][feature_train_ori.py][L341][INFO] Step [13/2500000=0.00%] | Epoch 0 | Time 69.360 (69.360) | Lr 0.0001 | AIC Loss 0.06053 (0.06053) | All Losses 0.20192 (0.20192)
[2022-07-21 22:13:25,260][feature_train_ori.py][L341][INFO] Step [14/2500000=0.00%] | Epoch 0 | Time 67.745 (67.745) | Lr 0.0001 | AIC Loss 0.08758 (0.08758) | All Losses 0.22226 (0.22226)
[2022-07-21 22:14:34,135][feature_train_ori.py][L341][INFO] Step [15/2500000=0.00%] | Epoch 0 | Time 68.858 (68.858) | Lr 0.0001 | AIC Loss 0.07664 (0.07664) | All Losses 0.20641 (0.20641)
[2022-07-21 22:15:42,706][feature_train_ori.py][L341][INFO] Step [16/2500000=0.00%] | Epoch 0 | Time 68.552 (68.552) | Lr 0.0001 | AIC Loss 0.07194 (0.07194) | All Losses 0.19181 (0.19181)
[2022-07-21 22:16:50,658][feature_train_ori.py][L341][INFO] Step [17/2500000=0.00%] | Epoch 0 | Time 67.935 (67.935) | Lr 0.0001 | AIC Loss 0.06259 (0.06259) | All Losses 0.18654 (0.18654)
[2022-07-21 22:17:59,581][feature_train_ori.py][L341][INFO] Step [18/2500000=0.00%] | Epoch 0 | Time 68.905 (68.905) | Lr 0.0001 | AIC Loss 0.06112 (0.06112) | All Losses 0.20966 (0.20966)
[2022-07-21 22:19:07,574][feature_train_ori.py][L341][INFO] Step [19/2500000=0.00%] | Epoch 0 | Time 67.975 (67.975) | Lr 0.0001 | AIC Loss 0.05965 (0.05965) | All Losses 0.19354 (0.19354)
[2022-07-21 22:20:16,766][feature_train_ori.py][L341][INFO] Step [20/2500000=0.00%] | Epoch 0 | Time 69.175 (69.175) | Lr 0.0001 | AIC Loss 0.07090 (0.07090) | All Losses 0.20484 (0.20484)
[2022-07-21 22:21:33,354][feature_train_ori.py][L341][INFO] Step [21/2500000=0.00%] | Epoch 0 | Time 70.097 (70.097) | Lr 0.0001 | AIC Loss 0.06826 (0.06826) | All Losses 0.20105 (0.20105)
[2022-07-21 22:22:42,820][feature_train_ori.py][L341][INFO] Step [22/2500000=0.00%] | Epoch 0 | Time 69.449 (69.449) | Lr 0.0001 | AIC Loss 0.05870 (0.05870) | All Losses 0.17654 (0.17654)
[2022-07-21 22:23:51,564][feature_train_ori.py][L341][INFO] Step [23/2500000=0.00%] | Epoch 0 | Time 68.726 (68.726) | Lr 0.0001 | AIC Loss 0.06366 (0.06366) | All Losses 0.17736 (0.17736)
[2022-07-21 22:25:00,186][feature_train_ori.py][L341][INFO] Step [24/2500000=0.00%] | Epoch 0 | Time 68.604 (68.604) | Lr 0.0001 | AIC Loss 0.06958 (0.06958) | All Losses 0.19232 (0.19232)
[2022-07-21 22:26:08,996][feature_train_ori.py][L341][INFO] Step [25/2500000=0.00%] | Epoch 0 | Time 68.793 (68.793) | Lr 0.0001 | AIC Loss 0.05841 (0.05841) | All Losses 0.17664 (0.17664)
[2022-07-21 22:27:17,600][feature_train_ori.py][L341][INFO] Step [26/2500000=0.00%] | Epoch 0 | Time 68.586 (68.586) | Lr 0.0001 | AIC Loss 0.06668 (0.06668) | All Losses 0.18176 (0.18176)
[2022-07-21 22:28:26,208][feature_train_ori.py][L341][INFO] Step [27/2500000=0.00%] | Epoch 0 | Time 68.589 (68.589) | Lr 0.0001 | AIC Loss 0.07612 (0.07612) | All Losses 0.18724 (0.18724)
[2022-07-21 22:29:35,302][feature_train_ori.py][L341][INFO] Step [28/2500000=0.00%] | Epoch 0 | Time 69.074 (69.074) | Lr 0.0001 | AIC Loss 0.06166 (0.06166) | All Losses 0.19223 (0.19223)
[2022-07-21 22:30:44,198][feature_train_ori.py][L341][INFO] Step [29/2500000=0.00%] | Epoch 0 | Time 68.877 (68.877) | Lr 0.0001 | AIC Loss 0.05953 (0.05953) | All Losses 0.17700 (0.17700)
[2022-07-21 22:31:53,516][feature_train_ori.py][L341][INFO] Step [30/2500000=0.00%] | Epoch 0 | Time 69.301 (69.301) | Lr 0.0001 | AIC Loss 0.06456 (0.06456) | All Losses 0.18317 (0.18317)
[2022-07-21 22:33:09,664][feature_train_ori.py][L341][INFO] Step [31/2500000=0.00%] | Epoch 0 | Time 69.546 (69.546) | Lr 0.0001 | AIC Loss 0.06756 (0.06756) | All Losses 0.18453 (0.18453)
[2022-07-21 22:34:20,028][feature_train_ori.py][L341][INFO] Step [32/2500000=0.00%] | Epoch 0 | Time 70.345 (70.345) | Lr 0.0001 | AIC Loss 0.06730 (0.06730) | All Losses 0.17540 (0.17540)
[2022-07-21 22:35:28,477][feature_train_ori.py][L341][INFO] Step [33/2500000=0.00%] | Epoch 0 | Time 68.428 (68.428) | Lr 0.0001 | AIC Loss 0.07351 (0.07351) | All Losses 0.19502 (0.19502)
[2022-07-21 22:36:37,701][feature_train_ori.py][L341][INFO] Step [34/2500000=0.00%] | Epoch 0 | Time 69.205 (69.205) | Lr 0.0001 | AIC Loss 0.06602 (0.06602) | All Losses 0.17048 (0.17048)
[2022-07-21 22:37:46,532][feature_train_ori.py][L341][INFO] Step [35/2500000=0.00%] | Epoch 0 | Time 68.812 (68.812) | Lr 0.0001 | AIC Loss 0.07617 (0.07617) | All Losses 0.20491 (0.20491)
[2022-07-21 22:38:56,184][feature_train_ori.py][L341][INFO] Step [36/2500000=0.00%] | Epoch 0 | Time 69.632 (69.632) | Lr 0.0001 | AIC Loss 0.05474 (0.05474) | All Losses 0.17221 (0.17221)
[2022-07-21 22:40:05,311][feature_train_ori.py][L341][INFO] Step [37/2500000=0.00%] | Epoch 0 | Time 69.106 (69.106) | Lr 0.0001 | AIC Loss 0.05363 (0.05363) | All Losses 0.17742 (0.17742)
[2022-07-21 22:41:15,043][feature_train_ori.py][L341][INFO] Step [38/2500000=0.00%] | Epoch 0 | Time 69.713 (69.713) | Lr 0.0001 | AIC Loss 0.06767 (0.06767) | All Losses 0.19078 (0.19078)
[2022-07-21 22:42:23,915][feature_train_ori.py][L341][INFO] Step [39/2500000=0.00%] | Epoch 0 | Time 68.851 (68.851) | Lr 0.0001 | AIC Loss 0.06240 (0.06240) | All Losses 0.16820 (0.16820)
[2022-07-21 22:43:33,262][feature_train_ori.py][L341][INFO] Step [40/2500000=0.00%] | Epoch 0 | Time 69.329 (69.329) | Lr 0.0001 | AIC Loss 0.05550 (0.05550) | All Losses 0.17345 (0.17345)
[2022-07-21 22:44:49,375][feature_train_ori.py][L341][INFO] Step [41/2500000=0.00%] | Epoch 0 | Time 69.830 (69.830) | Lr 0.0001 | AIC Loss 0.07816 (0.07816) | All Losses 0.18769 (0.18769)
[2022-07-22 08:53:38,485][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-22 08:53:38,486][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-22 08:54:00,502][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-22 08:54:00,502][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-22 08:54:06,445][feature_train_ori.py][L383][INFO] Concatenation(
  (relu): LeakyReLU(negative_slope=0.01)
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv11): Conv2d(4096, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv11_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv12): Conv2d(512, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv12_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
  (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
  (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
)
[2022-07-22 08:54:13,447][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-22 08:55:26,028][feature_train_ori.py][L341][INFO] Step [1/2500000=0.00%] | Epoch 0 | Time 72.126 (72.126) | Lr 0.0001 | AIC Loss 0.00455 (0.00455) | All Losses 0.35224 (0.35224)
[2022-07-22 08:56:37,136][feature_train_ori.py][L341][INFO] Step [2/2500000=0.00%] | Epoch 0 | Time 71.091 (71.091) | Lr 0.0001 | AIC Loss 0.03498 (0.03498) | All Losses 0.24587 (0.24587)
[2022-07-22 08:57:45,387][feature_train_ori.py][L341][INFO] Step [3/2500000=0.00%] | Epoch 0 | Time 68.235 (68.235) | Lr 0.0001 | AIC Loss 0.11395 (0.11395) | All Losses 0.25054 (0.25054)
[2022-07-22 08:58:53,540][feature_train_ori.py][L341][INFO] Step [4/2500000=0.00%] | Epoch 0 | Time 68.135 (68.135) | Lr 0.0001 | AIC Loss 0.11961 (0.11961) | All Losses 0.23024 (0.23024)
[2022-07-22 09:00:01,851][feature_train_ori.py][L341][INFO] Step [5/2500000=0.00%] | Epoch 0 | Time 68.294 (68.294) | Lr 0.0001 | AIC Loss 0.09922 (0.09922) | All Losses 0.22175 (0.22175)
[2022-07-22 09:01:10,021][feature_train_ori.py][L341][INFO] Step [6/2500000=0.00%] | Epoch 0 | Time 68.153 (68.153) | Lr 0.0001 | AIC Loss 0.07018 (0.07018) | All Losses 0.20640 (0.20640)
[2022-07-22 09:02:19,036][feature_train_ori.py][L341][INFO] Step [7/2500000=0.00%] | Epoch 0 | Time 68.998 (68.998) | Lr 0.0001 | AIC Loss 0.04988 (0.04988) | All Losses 0.20693 (0.20693)
[2022-07-22 09:03:28,058][feature_train_ori.py][L341][INFO] Step [8/2500000=0.00%] | Epoch 0 | Time 69.005 (69.005) | Lr 0.0001 | AIC Loss 0.05566 (0.05566) | All Losses 0.21143 (0.21143)
[2022-07-22 09:04:36,677][feature_train_ori.py][L341][INFO] Step [9/2500000=0.00%] | Epoch 0 | Time 68.602 (68.602) | Lr 0.0001 | AIC Loss 0.06936 (0.06936) | All Losses 0.22866 (0.22866)
[2022-07-22 09:05:45,094][feature_train_ori.py][L341][INFO] Step [10/2500000=0.00%] | Epoch 0 | Time 68.400 (68.400) | Lr 0.0001 | AIC Loss 0.06973 (0.06973) | All Losses 0.21117 (0.21117)
[2022-07-22 09:06:59,347][feature_train_ori.py][L341][INFO] Step [11/2500000=0.00%] | Epoch 0 | Time 68.232 (68.232) | Lr 0.0001 | AIC Loss 0.06584 (0.06584) | All Losses 0.20443 (0.20443)
[2022-07-22 09:08:07,448][feature_train_ori.py][L341][INFO] Step [12/2500000=0.00%] | Epoch 0 | Time 68.083 (68.083) | Lr 0.0001 | AIC Loss 0.07024 (0.07024) | All Losses 0.19913 (0.19913)
[2022-07-22 09:09:15,478][feature_train_ori.py][L341][INFO] Step [13/2500000=0.00%] | Epoch 0 | Time 68.012 (68.012) | Lr 0.0001 | AIC Loss 0.06112 (0.06112) | All Losses 0.20709 (0.20709)
[2022-07-22 09:10:23,841][feature_train_ori.py][L341][INFO] Step [14/2500000=0.00%] | Epoch 0 | Time 68.346 (68.346) | Lr 0.0001 | AIC Loss 0.06890 (0.06890) | All Losses 0.19104 (0.19104)
[2022-07-22 09:11:32,403][feature_train_ori.py][L341][INFO] Step [15/2500000=0.00%] | Epoch 0 | Time 68.543 (68.543) | Lr 0.0001 | AIC Loss 0.06791 (0.06791) | All Losses 0.21284 (0.21284)
[2022-07-22 09:12:42,100][feature_train_ori.py][L341][INFO] Step [16/2500000=0.00%] | Epoch 0 | Time 69.680 (69.680) | Lr 0.0001 | AIC Loss 0.05525 (0.05525) | All Losses 0.18973 (0.18973)
[2022-07-22 09:13:50,588][feature_train_ori.py][L341][INFO] Step [17/2500000=0.00%] | Epoch 0 | Time 68.471 (68.471) | Lr 0.0001 | AIC Loss 0.05657 (0.05657) | All Losses 0.21111 (0.21111)
[2022-07-22 09:14:58,733][feature_train_ori.py][L341][INFO] Step [18/2500000=0.00%] | Epoch 0 | Time 68.127 (68.127) | Lr 0.0001 | AIC Loss 0.07121 (0.07121) | All Losses 0.22436 (0.22436)
[2022-07-22 09:16:06,735][feature_train_ori.py][L341][INFO] Step [19/2500000=0.00%] | Epoch 0 | Time 67.985 (67.985) | Lr 0.0001 | AIC Loss 0.06635 (0.06635) | All Losses 0.20221 (0.20221)
[2022-07-22 09:17:14,753][feature_train_ori.py][L341][INFO] Step [20/2500000=0.00%] | Epoch 0 | Time 68.000 (68.000) | Lr 0.0001 | AIC Loss 0.07237 (0.07237) | All Losses 0.22380 (0.22380)
[2022-07-22 09:26:52,384][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-22 09:26:52,384][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-22 09:27:14,669][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-22 09:27:14,669][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-22 09:27:20,518][feature_train_ori.py][L383][INFO] Concatenation(
  (relu): LeakyReLU(negative_slope=0.01)
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv1): ConvTranspose2d(4096, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv11_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv2): ConvTranspose2d(512, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv12_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
  (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
  (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
)
[2022-07-22 09:27:27,568][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-22 09:28:51,170][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-22 09:28:51,171][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-22 09:28:57,079][feature_train_ori.py][L383][INFO] Concatenation(
  (relu): LeakyReLU(negative_slope=0.01)
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv1): ConvTranspose2d(4096, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv11_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv2): ConvTranspose2d(512, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv12_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
  (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
  (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
)
[2022-07-22 09:29:04,115][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-22 09:30:30,179][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-22 09:30:30,179][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-22 09:30:36,072][feature_train_ori.py][L383][INFO] Concatenation(
  (relu): LeakyReLU(negative_slope=0.01)
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv1): ConvTranspose2d(4096, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv11_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv2): ConvTranspose2d(512, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv12_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
  (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
  (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
)
[2022-07-22 09:30:43,146][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-22 09:33:18,016][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-22 09:33:18,016][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-22 09:33:24,455][feature_train_ori.py][L383][INFO] Concatenation(
  (relu): LeakyReLU(negative_slope=0.01)
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv1): ConvTranspose2d(4096, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv11_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv2): ConvTranspose2d(512, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv12_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
  (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
  (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
)
[2022-07-22 09:33:31,515][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-22 09:35:29,783][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-22 09:35:29,783][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-22 09:35:36,222][feature_train_ori.py][L383][INFO] Concatenation(
  (relu): LeakyReLU(negative_slope=0.01)
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv1): ConvTranspose2d(4096, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv11_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv2): ConvTranspose2d(2048, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv12_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
  (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
  (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
)
[2022-07-22 09:35:43,332][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-22 09:37:11,393][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-22 09:37:11,394][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-22 09:37:17,984][feature_train_ori.py][L383][INFO] Concatenation(
  (relu): LeakyReLU(negative_slope=0.01)
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv1): ConvTranspose2d(4096, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv11_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv2): ConvTranspose2d(4096, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv12_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
  (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
  (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
)
[2022-07-22 09:37:25,005][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-22 09:39:14,413][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-22 09:39:14,413][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-22 09:39:20,991][feature_train_ori.py][L383][INFO] Concatenation(
  (relu): LeakyReLU(negative_slope=0.01)
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv1): ConvTranspose2d(4096, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv11_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv2): ConvTranspose2d(4096, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv12_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
  (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
  (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
)
[2022-07-22 09:39:27,996][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-22 09:40:58,366][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-22 09:40:58,366][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-22 09:41:05,145][feature_train_ori.py][L383][INFO] Concatenation(
  (relu): LeakyReLU(negative_slope=0.01)
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv1): ConvTranspose2d(4096, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv11_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv2): ConvTranspose2d(4096, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv12_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
  (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
  (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
)
[2022-07-22 09:41:12,185][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-22 09:44:31,718][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-22 09:44:31,718][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-22 09:44:38,525][feature_train_ori.py][L383][INFO] Concatenation(
  (relu): LeakyReLU(negative_slope=0.01)
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv1): ConvTranspose2d(4096, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv11_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv2): ConvTranspose2d(4096, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv12_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv3): ConvTranspose2d(2048, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
  (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
  (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
)
[2022-07-22 09:44:45,576][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-22 09:45:57,791][feature_train_ori.py][L341][INFO] Step [1/2500000=0.00%] | Epoch 0 | Time 71.777 (71.777) | Lr 0.0001 | AIC Loss 0.40697 (0.40697) | All Losses 0.41168 (0.41168)
[2022-07-22 09:47:09,184][feature_train_ori.py][L341][INFO] Step [2/2500000=0.00%] | Epoch 0 | Time 71.366 (71.366) | Lr 0.0001 | AIC Loss 0.37248 (0.37248) | All Losses 0.37887 (0.37887)
[2022-07-22 09:48:17,488][feature_train_ori.py][L341][INFO] Step [3/2500000=0.00%] | Epoch 0 | Time 68.277 (68.277) | Lr 0.0001 | AIC Loss 0.36680 (0.36680) | All Losses 0.37043 (0.37043)
[2022-07-22 09:49:25,877][feature_train_ori.py][L341][INFO] Step [4/2500000=0.00%] | Epoch 0 | Time 68.361 (68.361) | Lr 0.0001 | AIC Loss 0.36841 (0.36841) | All Losses 0.37266 (0.37266)
[2022-07-22 09:50:34,100][feature_train_ori.py][L341][INFO] Step [5/2500000=0.00%] | Epoch 0 | Time 68.195 (68.195) | Lr 0.0001 | AIC Loss 0.32803 (0.32803) | All Losses 0.33343 (0.33343)
[2022-07-22 09:51:42,352][feature_train_ori.py][L341][INFO] Step [6/2500000=0.00%] | Epoch 0 | Time 68.225 (68.225) | Lr 0.0001 | AIC Loss 0.33496 (0.33496) | All Losses 0.34179 (0.34179)
[2022-07-22 09:52:50,717][feature_train_ori.py][L341][INFO] Step [7/2500000=0.00%] | Epoch 0 | Time 68.337 (68.337) | Lr 0.0001 | AIC Loss 0.32996 (0.32996) | All Losses 0.33364 (0.33364)
[2022-07-22 09:53:58,997][feature_train_ori.py][L341][INFO] Step [8/2500000=0.00%] | Epoch 0 | Time 68.252 (68.252) | Lr 0.0001 | AIC Loss 0.32847 (0.32847) | All Losses 0.33957 (0.33957)
[2022-07-22 09:55:07,489][feature_train_ori.py][L341][INFO] Step [9/2500000=0.00%] | Epoch 0 | Time 68.464 (68.464) | Lr 0.0001 | AIC Loss 0.32417 (0.32417) | All Losses 0.33402 (0.33402)
[2022-07-22 09:56:18,786][feature_train_ori.py][L341][INFO] Step [10/2500000=0.00%] | Epoch 0 | Time 71.269 (71.269) | Lr 0.0001 | AIC Loss 0.33701 (0.33701) | All Losses 0.35418 (0.35418)
[2022-07-22 09:57:39,852][feature_train_ori.py][L341][INFO] Step [11/2500000=0.00%] | Epoch 0 | Time 70.594 (70.594) | Lr 0.0001 | AIC Loss 0.30978 (0.30978) | All Losses 0.32155 (0.32155)
[2022-07-22 09:58:49,014][feature_train_ori.py][L341][INFO] Step [12/2500000=0.00%] | Epoch 0 | Time 69.135 (69.135) | Lr 0.0001 | AIC Loss 0.34974 (0.34974) | All Losses 0.36176 (0.36176)
[2022-07-22 09:59:58,248][feature_train_ori.py][L341][INFO] Step [13/2500000=0.00%] | Epoch 0 | Time 69.206 (69.206) | Lr 0.0001 | AIC Loss 0.29955 (0.29955) | All Losses 0.32330 (0.32330)
[2022-07-22 10:01:08,490][feature_train_ori.py][L341][INFO] Step [14/2500000=0.00%] | Epoch 0 | Time 70.214 (70.214) | Lr 0.0001 | AIC Loss 0.33102 (0.33102) | All Losses 0.36134 (0.36134)
[2022-07-22 10:02:18,847][feature_train_ori.py][L341][INFO] Step [15/2500000=0.00%] | Epoch 0 | Time 70.329 (70.329) | Lr 0.0001 | AIC Loss 0.28709 (0.28709) | All Losses 0.30893 (0.30893)
[2022-07-22 10:03:29,462][feature_train_ori.py][L341][INFO] Step [16/2500000=0.00%] | Epoch 0 | Time 70.587 (70.587) | Lr 0.0001 | AIC Loss 0.27384 (0.27384) | All Losses 0.30016 (0.30016)
[2022-07-22 10:04:40,721][feature_train_ori.py][L341][INFO] Step [17/2500000=0.00%] | Epoch 0 | Time 71.231 (71.231) | Lr 0.0001 | AIC Loss 0.27403 (0.27403) | All Losses 0.30086 (0.30086)
[2022-07-22 10:05:50,028][feature_train_ori.py][L341][INFO] Step [18/2500000=0.00%] | Epoch 0 | Time 69.280 (69.280) | Lr 0.0001 | AIC Loss 0.27561 (0.27561) | All Losses 0.31330 (0.31330)
[2022-07-22 10:06:59,287][feature_train_ori.py][L341][INFO] Step [19/2500000=0.00%] | Epoch 0 | Time 69.231 (69.231) | Lr 0.0001 | AIC Loss 0.25309 (0.25309) | All Losses 0.29062 (0.29062)
[2022-07-22 10:08:10,696][feature_train_ori.py][L341][INFO] Step [20/2500000=0.00%] | Epoch 0 | Time 71.380 (71.380) | Lr 0.0001 | AIC Loss 0.28100 (0.28100) | All Losses 0.31583 (0.31583)
[2022-07-22 10:09:32,973][feature_train_ori.py][L341][INFO] Step [21/2500000=0.00%] | Epoch 0 | Time 71.738 (71.738) | Lr 0.0001 | AIC Loss 0.26973 (0.26973) | All Losses 0.31577 (0.31577)
[2022-07-22 10:10:43,895][feature_train_ori.py][L341][INFO] Step [22/2500000=0.00%] | Epoch 0 | Time 70.897 (70.897) | Lr 0.0001 | AIC Loss 0.28112 (0.28112) | All Losses 0.32233 (0.32233)
[2022-07-22 10:11:55,175][feature_train_ori.py][L341][INFO] Step [23/2500000=0.00%] | Epoch 0 | Time 71.254 (71.254) | Lr 0.0001 | AIC Loss 0.24433 (0.24433) | All Losses 0.28508 (0.28508)
[2022-07-22 10:13:07,006][feature_train_ori.py][L341][INFO] Step [24/2500000=0.00%] | Epoch 0 | Time 71.806 (71.806) | Lr 0.0001 | AIC Loss 0.23944 (0.23944) | All Losses 0.27942 (0.27942)
[2022-07-22 10:14:18,466][feature_train_ori.py][L341][INFO] Step [25/2500000=0.00%] | Epoch 0 | Time 71.434 (71.434) | Lr 0.0001 | AIC Loss 0.29668 (0.29668) | All Losses 0.35655 (0.35655)
[2022-07-22 10:15:30,247][feature_train_ori.py][L341][INFO] Step [26/2500000=0.00%] | Epoch 0 | Time 71.755 (71.755) | Lr 0.0001 | AIC Loss 0.22886 (0.22886) | All Losses 0.27078 (0.27078)
[2022-07-22 10:16:41,950][feature_train_ori.py][L341][INFO] Step [27/2500000=0.00%] | Epoch 0 | Time 71.677 (71.677) | Lr 0.0001 | AIC Loss 0.25005 (0.25005) | All Losses 0.29920 (0.29920)
[2022-07-22 10:17:52,930][feature_train_ori.py][L341][INFO] Step [28/2500000=0.00%] | Epoch 0 | Time 70.953 (70.953) | Lr 0.0001 | AIC Loss 0.20602 (0.20602) | All Losses 0.26643 (0.26643)
[2022-07-22 10:19:04,096][feature_train_ori.py][L341][INFO] Step [29/2500000=0.00%] | Epoch 0 | Time 71.139 (71.139) | Lr 0.0001 | AIC Loss 0.21350 (0.21350) | All Losses 0.25169 (0.25169)
[2022-07-22 10:20:15,284][feature_train_ori.py][L341][INFO] Step [30/2500000=0.00%] | Epoch 0 | Time 71.160 (71.160) | Lr 0.0001 | AIC Loss 0.21762 (0.21762) | All Losses 0.27000 (0.27000)
[2022-07-22 10:21:37,088][feature_train_ori.py][L341][INFO] Step [31/2500000=0.00%] | Epoch 0 | Time 71.128 (71.128) | Lr 0.0001 | AIC Loss 0.22948 (0.22948) | All Losses 0.28452 (0.28452)
[2022-07-22 10:22:47,200][feature_train_ori.py][L341][INFO] Step [32/2500000=0.00%] | Epoch 0 | Time 70.084 (70.084) | Lr 0.0001 | AIC Loss 0.20999 (0.20999) | All Losses 0.26729 (0.26729)
[2022-07-22 10:23:58,330][feature_train_ori.py][L341][INFO] Step [33/2500000=0.00%] | Epoch 0 | Time 71.103 (71.103) | Lr 0.0001 | AIC Loss 0.21049 (0.21049) | All Losses 0.26225 (0.26225)
[2022-07-22 10:25:09,473][feature_train_ori.py][L341][INFO] Step [34/2500000=0.00%] | Epoch 0 | Time 71.115 (71.115) | Lr 0.0001 | AIC Loss 0.19561 (0.19561) | All Losses 0.25102 (0.25102)
[2022-07-22 10:26:20,342][feature_train_ori.py][L341][INFO] Step [35/2500000=0.00%] | Epoch 0 | Time 70.841 (70.841) | Lr 0.0001 | AIC Loss 0.18419 (0.18419) | All Losses 0.24851 (0.24851)
[2022-07-22 10:27:31,648][feature_train_ori.py][L341][INFO] Step [36/2500000=0.00%] | Epoch 0 | Time 71.278 (71.278) | Lr 0.0001 | AIC Loss 0.20831 (0.20831) | All Losses 0.27754 (0.27754)
[2022-07-22 10:28:42,947][feature_train_ori.py][L341][INFO] Step [37/2500000=0.00%] | Epoch 0 | Time 71.271 (71.271) | Lr 0.0001 | AIC Loss 0.20514 (0.20514) | All Losses 0.26102 (0.26102)
[2022-07-22 10:29:54,394][feature_train_ori.py][L341][INFO] Step [38/2500000=0.00%] | Epoch 0 | Time 71.420 (71.420) | Lr 0.0001 | AIC Loss 0.19101 (0.19101) | All Losses 0.25985 (0.25985)
[2022-07-22 10:31:05,549][feature_train_ori.py][L341][INFO] Step [39/2500000=0.00%] | Epoch 0 | Time 71.127 (71.127) | Lr 0.0001 | AIC Loss 0.21238 (0.21238) | All Losses 0.27771 (0.27771)
[2022-07-22 10:32:16,651][feature_train_ori.py][L341][INFO] Step [40/2500000=0.00%] | Epoch 0 | Time 71.073 (71.073) | Lr 0.0001 | AIC Loss 0.21133 (0.21133) | All Losses 0.26710 (0.26710)
[2022-07-22 10:33:37,535][feature_train_ori.py][L341][INFO] Step [41/2500000=0.00%] | Epoch 0 | Time 70.233 (70.233) | Lr 0.0001 | AIC Loss 0.18745 (0.18745) | All Losses 0.26786 (0.26786)
[2022-07-22 10:34:48,156][feature_train_ori.py][L341][INFO] Step [42/2500000=0.00%] | Epoch 0 | Time 70.594 (70.594) | Lr 0.0001 | AIC Loss 0.19933 (0.19933) | All Losses 0.26618 (0.26618)
[2022-07-22 10:35:58,765][feature_train_ori.py][L341][INFO] Step [43/2500000=0.00%] | Epoch 0 | Time 70.581 (70.581) | Lr 0.0001 | AIC Loss 0.18369 (0.18369) | All Losses 0.24992 (0.24992)
[2022-07-22 10:37:09,429][feature_train_ori.py][L341][INFO] Step [44/2500000=0.00%] | Epoch 0 | Time 70.636 (70.636) | Lr 0.0001 | AIC Loss 0.18955 (0.18955) | All Losses 0.27325 (0.27325)
[2022-07-22 10:38:19,907][feature_train_ori.py][L341][INFO] Step [45/2500000=0.00%] | Epoch 0 | Time 70.450 (70.450) | Lr 0.0001 | AIC Loss 0.19230 (0.19230) | All Losses 0.27273 (0.27273)
[2022-07-22 10:39:30,247][feature_train_ori.py][L341][INFO] Step [46/2500000=0.00%] | Epoch 0 | Time 70.312 (70.312) | Lr 0.0001 | AIC Loss 0.19807 (0.19807) | All Losses 0.27405 (0.27405)
[2022-07-22 10:40:41,315][feature_train_ori.py][L341][INFO] Step [47/2500000=0.00%] | Epoch 0 | Time 71.040 (71.040) | Lr 0.0001 | AIC Loss 0.17256 (0.17256) | All Losses 0.24753 (0.24753)
[2022-07-22 10:41:51,762][feature_train_ori.py][L341][INFO] Step [48/2500000=0.00%] | Epoch 0 | Time 70.419 (70.419) | Lr 0.0001 | AIC Loss 0.18253 (0.18253) | All Losses 0.25853 (0.25853)
[2022-07-22 10:43:02,005][feature_train_ori.py][L341][INFO] Step [49/2500000=0.00%] | Epoch 0 | Time 70.216 (70.216) | Lr 0.0001 | AIC Loss 0.18101 (0.18101) | All Losses 0.26536 (0.26536)
[2022-07-22 10:44:13,434][feature_train_ori.py][L341][INFO] Step [50/2500000=0.00%] | Epoch 0 | Time 71.401 (71.401) | Lr 0.0001 | AIC Loss 0.17362 (0.17362) | All Losses 0.24810 (0.24810)
[2022-07-22 10:45:35,002][feature_train_ori.py][L341][INFO] Step [51/2500000=0.00%] | Epoch 0 | Time 71.036 (71.036) | Lr 0.0001 | AIC Loss 0.16540 (0.16540) | All Losses 0.24631 (0.24631)
[2022-07-22 10:46:43,868][feature_train_ori.py][L341][INFO] Step [52/2500000=0.00%] | Epoch 0 | Time 68.839 (68.839) | Lr 0.0001 | AIC Loss 0.16609 (0.16609) | All Losses 0.25178 (0.25178)
[2022-07-22 10:47:54,920][feature_train_ori.py][L341][INFO] Step [53/2500000=0.00%] | Epoch 0 | Time 71.024 (71.024) | Lr 0.0001 | AIC Loss 0.16689 (0.16689) | All Losses 0.23600 (0.23600)
[2022-07-22 10:49:05,409][feature_train_ori.py][L341][INFO] Step [54/2500000=0.00%] | Epoch 0 | Time 70.462 (70.462) | Lr 0.0001 | AIC Loss 0.15892 (0.15892) | All Losses 0.24250 (0.24250)
[2022-07-22 10:50:16,621][feature_train_ori.py][L341][INFO] Step [55/2500000=0.00%] | Epoch 0 | Time 71.184 (71.184) | Lr 0.0001 | AIC Loss 0.16289 (0.16289) | All Losses 0.25284 (0.25284)
[2022-07-22 10:51:27,899][feature_train_ori.py][L341][INFO] Step [56/2500000=0.00%] | Epoch 0 | Time 71.250 (71.250) | Lr 0.0001 | AIC Loss 0.16099 (0.16099) | All Losses 0.24061 (0.24061)
[2022-07-22 10:52:38,754][feature_train_ori.py][L341][INFO] Step [57/2500000=0.00%] | Epoch 0 | Time 70.827 (70.827) | Lr 0.0001 | AIC Loss 0.16052 (0.16052) | All Losses 0.24177 (0.24177)
[2022-07-22 10:53:48,891][feature_train_ori.py][L341][INFO] Step [58/2500000=0.00%] | Epoch 0 | Time 70.110 (70.110) | Lr 0.0001 | AIC Loss 0.19384 (0.19384) | All Losses 0.26843 (0.26843)
[2022-07-22 10:54:58,950][feature_train_ori.py][L341][INFO] Step [59/2500000=0.00%] | Epoch 0 | Time 70.031 (70.031) | Lr 0.0001 | AIC Loss 0.18433 (0.18433) | All Losses 0.27320 (0.27320)
[2022-07-22 10:56:09,874][feature_train_ori.py][L341][INFO] Step [60/2500000=0.00%] | Epoch 0 | Time 70.896 (70.896) | Lr 0.0001 | AIC Loss 0.18259 (0.18259) | All Losses 0.26161 (0.26161)
[2022-07-22 10:57:31,173][feature_train_ori.py][L341][INFO] Step [61/2500000=0.00%] | Epoch 0 | Time 71.007 (71.007) | Lr 0.0001 | AIC Loss 0.17658 (0.17658) | All Losses 0.26727 (0.26727)
[2022-07-22 10:58:42,210][feature_train_ori.py][L341][INFO] Step [62/2500000=0.00%] | Epoch 0 | Time 71.010 (71.010) | Lr 0.0001 | AIC Loss 0.18391 (0.18391) | All Losses 0.26636 (0.26636)
[2022-07-22 10:59:53,347][feature_train_ori.py][L341][INFO] Step [63/2500000=0.00%] | Epoch 0 | Time 71.109 (71.109) | Lr 0.0001 | AIC Loss 0.19336 (0.19336) | All Losses 0.27350 (0.27350)
[2022-07-22 11:01:04,223][feature_train_ori.py][L341][INFO] Step [64/2500000=0.00%] | Epoch 0 | Time 70.849 (70.849) | Lr 0.0001 | AIC Loss 0.16363 (0.16363) | All Losses 0.24857 (0.24857)
[2022-07-22 11:02:15,219][feature_train_ori.py][L341][INFO] Step [65/2500000=0.00%] | Epoch 0 | Time 70.968 (70.968) | Lr 0.0001 | AIC Loss 0.16000 (0.16000) | All Losses 0.25443 (0.25443)
[2022-07-22 11:03:26,060][feature_train_ori.py][L341][INFO] Step [66/2500000=0.00%] | Epoch 0 | Time 70.813 (70.813) | Lr 0.0001 | AIC Loss 0.17518 (0.17518) | All Losses 0.25477 (0.25477)
[2022-07-22 11:04:37,072][feature_train_ori.py][L341][INFO] Step [67/2500000=0.00%] | Epoch 0 | Time 70.984 (70.984) | Lr 0.0001 | AIC Loss 0.16702 (0.16702) | All Losses 0.24639 (0.24639)
[2022-07-22 11:05:47,864][feature_train_ori.py][L341][INFO] Step [68/2500000=0.00%] | Epoch 0 | Time 70.764 (70.764) | Lr 0.0001 | AIC Loss 0.18721 (0.18721) | All Losses 0.27258 (0.27258)
[2022-07-22 11:06:58,731][feature_train_ori.py][L341][INFO] Step [69/2500000=0.00%] | Epoch 0 | Time 70.840 (70.840) | Lr 0.0001 | AIC Loss 0.17538 (0.17538) | All Losses 0.25281 (0.25281)
[2022-07-22 11:08:09,539][feature_train_ori.py][L341][INFO] Step [70/2500000=0.00%] | Epoch 0 | Time 70.780 (70.780) | Lr 0.0001 | AIC Loss 0.16764 (0.16764) | All Losses 0.24464 (0.24464)
[2022-07-22 11:09:31,287][feature_train_ori.py][L341][INFO] Step [71/2500000=0.00%] | Epoch 0 | Time 71.283 (71.283) | Lr 0.0001 | AIC Loss 0.16702 (0.16702) | All Losses 0.23796 (0.23796)
[2022-07-22 11:10:42,572][feature_train_ori.py][L341][INFO] Step [72/2500000=0.00%] | Epoch 0 | Time 71.256 (71.256) | Lr 0.0001 | AIC Loss 0.17031 (0.17031) | All Losses 0.24265 (0.24265)
[2022-07-22 11:11:53,689][feature_train_ori.py][L341][INFO] Step [73/2500000=0.00%] | Epoch 0 | Time 71.089 (71.089) | Lr 0.0001 | AIC Loss 0.16986 (0.16986) | All Losses 0.24059 (0.24059)
[2022-07-22 11:13:04,757][feature_train_ori.py][L341][INFO] Step [74/2500000=0.00%] | Epoch 0 | Time 71.040 (71.040) | Lr 0.0001 | AIC Loss 0.15916 (0.15916) | All Losses 0.23214 (0.23214)
[2022-07-22 11:14:16,128][feature_train_ori.py][L341][INFO] Step [75/2500000=0.00%] | Epoch 0 | Time 71.344 (71.344) | Lr 0.0001 | AIC Loss 0.16264 (0.16264) | All Losses 0.23803 (0.23803)
[2022-07-22 11:15:27,246][feature_train_ori.py][L341][INFO] Step [76/2500000=0.00%] | Epoch 0 | Time 71.091 (71.091) | Lr 0.0001 | AIC Loss 0.17002 (0.17002) | All Losses 0.23474 (0.23474)
[2022-07-22 11:16:38,602][feature_train_ori.py][L341][INFO] Step [77/2500000=0.00%] | Epoch 0 | Time 71.328 (71.328) | Lr 0.0001 | AIC Loss 0.15360 (0.15360) | All Losses 0.24257 (0.24257)
[2022-07-22 11:17:49,786][feature_train_ori.py][L341][INFO] Step [78/2500000=0.00%] | Epoch 0 | Time 71.156 (71.156) | Lr 0.0001 | AIC Loss 0.16592 (0.16592) | All Losses 0.24366 (0.24366)
[2022-07-22 11:19:01,031][feature_train_ori.py][L341][INFO] Step [79/2500000=0.00%] | Epoch 0 | Time 71.217 (71.217) | Lr 0.0001 | AIC Loss 0.16890 (0.16890) | All Losses 0.23474 (0.23474)
[2022-07-22 11:20:12,387][feature_train_ori.py][L341][INFO] Step [80/2500000=0.00%] | Epoch 0 | Time 71.328 (71.328) | Lr 0.0001 | AIC Loss 0.16625 (0.16625) | All Losses 0.24423 (0.24423)
[2022-07-22 11:21:33,677][feature_train_ori.py][L341][INFO] Step [81/2500000=0.00%] | Epoch 0 | Time 70.809 (70.809) | Lr 0.0001 | AIC Loss 0.15811 (0.15811) | All Losses 0.23498 (0.23498)
[2022-07-22 11:22:44,729][feature_train_ori.py][L341][INFO] Step [82/2500000=0.00%] | Epoch 0 | Time 71.025 (71.025) | Lr 0.0001 | AIC Loss 0.17076 (0.17076) | All Losses 0.27026 (0.27026)
[2022-07-22 11:23:55,724][feature_train_ori.py][L341][INFO] Step [83/2500000=0.00%] | Epoch 0 | Time 70.967 (70.967) | Lr 0.0001 | AIC Loss 0.15289 (0.15289) | All Losses 0.21740 (0.21740)
[2022-07-22 11:25:06,230][feature_train_ori.py][L341][INFO] Step [84/2500000=0.00%] | Epoch 0 | Time 70.478 (70.478) | Lr 0.0001 | AIC Loss 0.16539 (0.16539) | All Losses 0.24072 (0.24072)
[2022-07-22 11:26:16,481][feature_train_ori.py][L341][INFO] Step [85/2500000=0.00%] | Epoch 0 | Time 70.223 (70.223) | Lr 0.0001 | AIC Loss 0.15644 (0.15644) | All Losses 0.23695 (0.23695)
[2022-07-22 11:27:27,516][feature_train_ori.py][L341][INFO] Step [86/2500000=0.00%] | Epoch 0 | Time 71.007 (71.007) | Lr 0.0001 | AIC Loss 0.14026 (0.14026) | All Losses 0.20623 (0.20623)
[2022-07-22 11:28:38,055][feature_train_ori.py][L341][INFO] Step [87/2500000=0.00%] | Epoch 0 | Time 70.512 (70.512) | Lr 0.0001 | AIC Loss 0.14126 (0.14126) | All Losses 0.22714 (0.22714)
[2022-07-22 11:29:49,190][feature_train_ori.py][L341][INFO] Step [88/2500000=0.00%] | Epoch 0 | Time 71.105 (71.105) | Lr 0.0001 | AIC Loss 0.15404 (0.15404) | All Losses 0.23398 (0.23398)
[2022-07-22 11:30:58,194][feature_train_ori.py][L341][INFO] Step [89/2500000=0.00%] | Epoch 0 | Time 68.977 (68.977) | Lr 0.0001 | AIC Loss 0.15550 (0.15550) | All Losses 0.23824 (0.23824)
[2022-07-22 11:32:09,340][feature_train_ori.py][L341][INFO] Step [90/2500000=0.00%] | Epoch 0 | Time 71.118 (71.118) | Lr 0.0001 | AIC Loss 0.13973 (0.13973) | All Losses 0.23110 (0.23110)
[2022-07-22 11:33:30,578][feature_train_ori.py][L341][INFO] Step [91/2500000=0.00%] | Epoch 0 | Time 70.689 (70.689) | Lr 0.0001 | AIC Loss 0.15853 (0.15853) | All Losses 0.24038 (0.24038)
[2022-07-22 11:34:41,540][feature_train_ori.py][L341][INFO] Step [92/2500000=0.00%] | Epoch 0 | Time 70.935 (70.935) | Lr 0.0001 | AIC Loss 0.13501 (0.13501) | All Losses 0.22689 (0.22689)
[2022-07-22 11:35:52,431][feature_train_ori.py][L341][INFO] Step [93/2500000=0.00%] | Epoch 0 | Time 70.863 (70.863) | Lr 0.0001 | AIC Loss 0.14081 (0.14081) | All Losses 0.22453 (0.22453)
[2022-07-22 11:37:03,074][feature_train_ori.py][L341][INFO] Step [94/2500000=0.00%] | Epoch 0 | Time 70.615 (70.615) | Lr 0.0001 | AIC Loss 0.15811 (0.15811) | All Losses 0.25396 (0.25396)
[2022-07-22 11:38:13,311][feature_train_ori.py][L341][INFO] Step [95/2500000=0.00%] | Epoch 0 | Time 70.209 (70.209) | Lr 0.0001 | AIC Loss 0.14886 (0.14886) | All Losses 0.24007 (0.24007)
[2022-07-22 11:39:24,525][feature_train_ori.py][L341][INFO] Step [96/2500000=0.00%] | Epoch 0 | Time 71.186 (71.186) | Lr 0.0001 | AIC Loss 0.14952 (0.14952) | All Losses 0.23483 (0.23483)
[2022-07-22 11:40:35,583][feature_train_ori.py][L341][INFO] Step [97/2500000=0.00%] | Epoch 0 | Time 71.031 (71.031) | Lr 0.0001 | AIC Loss 0.14993 (0.14993) | All Losses 0.23977 (0.23977)
[2022-07-22 11:41:46,279][feature_train_ori.py][L341][INFO] Step [98/2500000=0.00%] | Epoch 0 | Time 70.668 (70.668) | Lr 0.0001 | AIC Loss 0.15503 (0.15503) | All Losses 0.24433 (0.24433)
[2022-07-22 11:42:57,411][feature_train_ori.py][L341][INFO] Step [99/2500000=0.00%] | Epoch 0 | Time 71.103 (71.103) | Lr 0.0001 | AIC Loss 0.14349 (0.14349) | All Losses 0.23810 (0.23810)
[2022-07-22 11:44:08,685][feature_train_ori.py][L341][INFO] Step [100/2500000=0.00%] | Epoch 0 | Time 71.247 (71.247) | Lr 0.0001 | AIC Loss 0.15515 (0.15515) | All Losses 0.26209 (0.26209)
[2022-07-22 11:45:21,806][feature_train_ori.py][L341][INFO] Step [101/2500000=0.00%] | Epoch 0 | Time 70.217 (70.217) | Lr 0.0001 | AIC Loss 0.13367 (0.13367) | All Losses 0.23619 (0.23619)
[2022-07-22 11:46:32,698][feature_train_ori.py][L341][INFO] Step [102/2500000=0.00%] | Epoch 0 | Time 70.864 (70.864) | Lr 0.0001 | AIC Loss 0.15177 (0.15177) | All Losses 0.23513 (0.23513)
[2022-07-22 11:47:44,065][feature_train_ori.py][L341][INFO] Step [103/2500000=0.00%] | Epoch 0 | Time 71.340 (71.340) | Lr 0.0001 | AIC Loss 0.14445 (0.14445) | All Losses 0.23627 (0.23627)
[2022-07-22 11:48:55,208][feature_train_ori.py][L341][INFO] Step [104/2500000=0.00%] | Epoch 0 | Time 71.115 (71.115) | Lr 0.0001 | AIC Loss 0.14736 (0.14736) | All Losses 0.23318 (0.23318)
[2022-07-22 11:50:06,681][feature_train_ori.py][L341][INFO] Step [105/2500000=0.00%] | Epoch 0 | Time 71.446 (71.446) | Lr 0.0001 | AIC Loss 0.14364 (0.14364) | All Losses 0.23081 (0.23081)
[2022-07-22 11:51:17,817][feature_train_ori.py][L341][INFO] Step [106/2500000=0.00%] | Epoch 0 | Time 71.108 (71.108) | Lr 0.0001 | AIC Loss 0.14815 (0.14815) | All Losses 0.21056 (0.21056)
[2022-07-22 11:52:29,235][feature_train_ori.py][L341][INFO] Step [107/2500000=0.00%] | Epoch 0 | Time 71.390 (71.390) | Lr 0.0001 | AIC Loss 0.15764 (0.15764) | All Losses 0.24917 (0.24917)
[2022-07-22 11:53:40,857][feature_train_ori.py][L341][INFO] Step [108/2500000=0.00%] | Epoch 0 | Time 71.594 (71.594) | Lr 0.0001 | AIC Loss 0.14688 (0.14688) | All Losses 0.22800 (0.22800)
[2022-07-22 11:54:52,385][feature_train_ori.py][L341][INFO] Step [109/2500000=0.00%] | Epoch 0 | Time 71.500 (71.500) | Lr 0.0001 | AIC Loss 0.12967 (0.12967) | All Losses 0.22707 (0.22707)
[2022-07-22 11:56:03,863][feature_train_ori.py][L341][INFO] Step [110/2500000=0.00%] | Epoch 0 | Time 71.450 (71.450) | Lr 0.0001 | AIC Loss 0.14491 (0.14491) | All Losses 0.23376 (0.23376)
[2022-07-22 13:35:03,983][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-22 13:35:03,984][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-22 13:35:11,645][feature_train_ori.py][L384][INFO] Concatenation(
  (relu): LeakyReLU(negative_slope=0.01)
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv1): ConvTranspose2d(4096, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv11_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv2): ConvTranspose2d(4096, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv12_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv3): ConvTranspose2d(2048, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
  (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
  (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
)
[2022-07-22 13:35:18,782][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-22 13:36:27,653][feature_train_ori.py][L341][INFO] Step [1/2500000=0.00%] | Epoch 0 | Time 68.353 (68.353) | Lr 0.0001 | AIC Loss 0.14551 (0.14551) | All Losses 0.23733 (0.23733)
[2022-07-22 13:37:36,266][feature_train_ori.py][L341][INFO] Step [2/2500000=0.00%] | Epoch 0 | Time 68.587 (68.587) | Lr 0.0001 | AIC Loss 0.21416 (0.21416) | All Losses 0.25809 (0.25809)
[2022-07-22 13:38:42,352][feature_train_ori.py][L341][INFO] Step [3/2500000=0.00%] | Epoch 0 | Time 66.059 (66.059) | Lr 0.0001 | AIC Loss 0.20099 (0.20099) | All Losses 0.25745 (0.25745)
[2022-07-22 13:39:48,173][feature_train_ori.py][L341][INFO] Step [4/2500000=0.00%] | Epoch 0 | Time 65.784 (65.784) | Lr 0.0001 | AIC Loss 0.21402 (0.21402) | All Losses 0.27264 (0.27264)
[2022-07-22 13:40:54,494][feature_train_ori.py][L341][INFO] Step [5/2500000=0.00%] | Epoch 0 | Time 66.294 (66.294) | Lr 0.0001 | AIC Loss 0.21141 (0.21141) | All Losses 0.25838 (0.25838)
[2022-07-22 13:41:59,983][feature_train_ori.py][L341][INFO] Step [6/2500000=0.00%] | Epoch 0 | Time 65.461 (65.461) | Lr 0.0001 | AIC Loss 0.22461 (0.22461) | All Losses 0.28641 (0.28641)
[2022-07-22 13:43:05,214][feature_train_ori.py][L341][INFO] Step [7/2500000=0.00%] | Epoch 0 | Time 65.203 (65.203) | Lr 0.0001 | AIC Loss 0.20923 (0.20923) | All Losses 0.26131 (0.26131)
[2022-07-22 13:44:11,493][feature_train_ori.py][L341][INFO] Step [8/2500000=0.00%] | Epoch 0 | Time 66.240 (66.240) | Lr 0.0001 | AIC Loss 0.20827 (0.20827) | All Losses 0.27518 (0.27518)
[2022-07-22 13:45:17,360][feature_train_ori.py][L341][INFO] Step [9/2500000=0.00%] | Epoch 0 | Time 65.839 (65.839) | Lr 0.0001 | AIC Loss 0.20249 (0.20249) | All Losses 0.27285 (0.27285)
[2022-07-22 13:46:23,026][feature_train_ori.py][L341][INFO] Step [10/2500000=0.00%] | Epoch 0 | Time 65.628 (65.628) | Lr 0.0001 | AIC Loss 0.19975 (0.19975) | All Losses 0.26707 (0.26707)
[2022-07-22 13:47:31,949][feature_train_ori.py][L341][INFO] Step [11/2500000=0.00%] | Epoch 0 | Time 66.073 (66.073) | Lr 0.0001 | AIC Loss 0.19621 (0.19621) | All Losses 0.26288 (0.26288)
[2022-07-22 13:48:39,305][feature_train_ori.py][L341][INFO] Step [12/2500000=0.00%] | Epoch 0 | Time 67.328 (67.328) | Lr 0.0001 | AIC Loss 0.16544 (0.16544) | All Losses 0.23179 (0.23179)
[2022-07-22 13:49:44,957][feature_train_ori.py][L341][INFO] Step [13/2500000=0.00%] | Epoch 0 | Time 65.625 (65.625) | Lr 0.0001 | AIC Loss 0.19292 (0.19292) | All Losses 0.26415 (0.26415)
[2022-07-22 13:52:15,020][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-22 13:52:15,020][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-22 13:52:21,869][feature_train_ori.py][L384][INFO] Concatenation(
  (relu): LeakyReLU(negative_slope=0.01)
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv1): ConvTranspose2d(4096, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv11_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv2): ConvTranspose2d(4096, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv12_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv3): ConvTranspose2d(2048, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), output_padding=(1, 1))
  (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
  (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
  (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
)
[2022-07-22 13:52:28,923][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-22 13:57:21,903][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-22 13:57:21,903][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-22 13:57:28,726][feature_train_ori.py][L384][INFO] Concatenation(
  (relu): LeakyReLU(negative_slope=0.01)
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv1): ConvTranspose2d(4096, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv11_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv2): ConvTranspose2d(4096, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv12_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv3): Conv2d(2048, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
  (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
  (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
)
[2022-07-22 13:57:35,821][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-22 13:58:48,280][feature_train_ori.py][L341][INFO] Step [1/2500000=0.00%] | Epoch 0 | Time 72.012 (72.012) | Lr 0.0001 | AIC Loss 0.24542 (0.24542) | All Losses 0.68525 (0.68525)
[2022-07-22 13:59:59,981][feature_train_ori.py][L341][INFO] Step [2/2500000=0.00%] | Epoch 0 | Time 71.674 (71.674) | Lr 0.0001 | AIC Loss 0.37512 (0.37512) | All Losses 0.41079 (0.41079)
[2022-07-22 14:01:08,693][feature_train_ori.py][L341][INFO] Step [3/2500000=0.00%] | Epoch 0 | Time 68.685 (68.685) | Lr 0.0001 | AIC Loss 0.32222 (0.32222) | All Losses 0.40038 (0.40038)
[2022-07-22 14:02:17,104][feature_train_ori.py][L341][INFO] Step [4/2500000=0.00%] | Epoch 0 | Time 68.384 (68.384) | Lr 0.0001 | AIC Loss 0.30447 (0.30447) | All Losses 0.39325 (0.39325)
[2022-07-22 14:03:26,736][feature_train_ori.py][L341][INFO] Step [5/2500000=0.00%] | Epoch 0 | Time 69.604 (69.604) | Lr 0.0001 | AIC Loss 0.31441 (0.31441) | All Losses 0.39648 (0.39648)
[2022-07-22 14:04:37,926][feature_train_ori.py][L341][INFO] Step [6/2500000=0.00%] | Epoch 0 | Time 71.162 (71.162) | Lr 0.0001 | AIC Loss 0.28942 (0.28942) | All Losses 0.40068 (0.40068)
[2022-07-22 14:05:47,536][feature_train_ori.py][L341][INFO] Step [7/2500000=0.00%] | Epoch 0 | Time 69.582 (69.582) | Lr 0.0001 | AIC Loss 0.30748 (0.30748) | All Losses 0.39380 (0.39380)
[2022-07-22 14:06:58,312][feature_train_ori.py][L341][INFO] Step [8/2500000=0.00%] | Epoch 0 | Time 70.749 (70.749) | Lr 0.0001 | AIC Loss 0.27533 (0.27533) | All Losses 0.34213 (0.34213)
[2022-07-22 14:08:09,428][feature_train_ori.py][L341][INFO] Step [9/2500000=0.00%] | Epoch 0 | Time 71.088 (71.088) | Lr 0.0001 | AIC Loss 0.26559 (0.26559) | All Losses 0.35713 (0.35713)
[2022-07-22 14:09:20,686][feature_train_ori.py][L341][INFO] Step [10/2500000=0.00%] | Epoch 0 | Time 71.231 (71.231) | Lr 0.0001 | AIC Loss 0.27024 (0.27024) | All Losses 0.35588 (0.35588)
[2022-07-22 14:10:44,266][feature_train_ori.py][L341][INFO] Step [11/2500000=0.00%] | Epoch 0 | Time 72.878 (72.878) | Lr 0.0001 | AIC Loss 0.25250 (0.25250) | All Losses 0.34189 (0.34189)
[2022-07-22 14:11:55,989][feature_train_ori.py][L341][INFO] Step [12/2500000=0.00%] | Epoch 0 | Time 71.697 (71.697) | Lr 0.0001 | AIC Loss 0.26097 (0.26097) | All Losses 0.35936 (0.35936)
[2022-07-22 14:13:07,120][feature_train_ori.py][L341][INFO] Step [13/2500000=0.00%] | Epoch 0 | Time 71.102 (71.102) | Lr 0.0001 | AIC Loss 0.29174 (0.29174) | All Losses 0.45048 (0.45048)
[2022-07-22 14:14:18,205][feature_train_ori.py][L341][INFO] Step [14/2500000=0.00%] | Epoch 0 | Time 71.057 (71.057) | Lr 0.0001 | AIC Loss 0.27565 (0.27565) | All Losses 0.38111 (0.38111)
[2022-07-22 14:15:31,140][feature_train_ori.py][L341][INFO] Step [15/2500000=0.00%] | Epoch 0 | Time 72.908 (72.908) | Lr 0.0001 | AIC Loss 0.28387 (0.28387) | All Losses 0.33828 (0.33828)
[2022-07-22 14:16:42,531][feature_train_ori.py][L341][INFO] Step [16/2500000=0.00%] | Epoch 0 | Time 71.363 (71.363) | Lr 0.0001 | AIC Loss 0.28677 (0.28677) | All Losses 0.33014 (0.33014)
[2022-07-22 14:17:53,267][feature_train_ori.py][L341][INFO] Step [17/2500000=0.00%] | Epoch 0 | Time 70.708 (70.708) | Lr 0.0001 | AIC Loss 0.24104 (0.24104) | All Losses 0.31808 (0.31808)
[2022-07-22 14:19:02,406][feature_train_ori.py][L341][INFO] Step [18/2500000=0.00%] | Epoch 0 | Time 69.111 (69.111) | Lr 0.0001 | AIC Loss 0.27584 (0.27584) | All Losses 0.35492 (0.35492)
[2022-07-22 14:20:13,555][feature_train_ori.py][L341][INFO] Step [19/2500000=0.00%] | Epoch 0 | Time 71.118 (71.118) | Lr 0.0001 | AIC Loss 0.26392 (0.26392) | All Losses 0.36329 (0.36329)
[2022-07-22 14:21:22,818][feature_train_ori.py][L341][INFO] Step [20/2500000=0.00%] | Epoch 0 | Time 69.235 (69.235) | Lr 0.0001 | AIC Loss 0.26314 (0.26314) | All Losses 0.33126 (0.33126)
[2022-07-22 14:22:37,109][feature_train_ori.py][L341][INFO] Step [21/2500000=0.00%] | Epoch 0 | Time 71.317 (71.317) | Lr 0.0001 | AIC Loss 0.26353 (0.26353) | All Losses 0.35218 (0.35218)
[2022-07-22 14:23:48,659][feature_train_ori.py][L341][INFO] Step [22/2500000=0.00%] | Epoch 0 | Time 71.523 (71.523) | Lr 0.0001 | AIC Loss 0.24579 (0.24579) | All Losses 0.29880 (0.29880)
[2022-07-22 14:24:59,918][feature_train_ori.py][L341][INFO] Step [23/2500000=0.00%] | Epoch 0 | Time 71.232 (71.232) | Lr 0.0001 | AIC Loss 0.20407 (0.20407) | All Losses 0.32450 (0.32450)
[2022-07-22 14:26:11,415][feature_train_ori.py][L341][INFO] Step [24/2500000=0.00%] | Epoch 0 | Time 71.469 (71.469) | Lr 0.0001 | AIC Loss 0.26417 (0.26417) | All Losses 0.36458 (0.36458)
[2022-07-22 14:27:22,876][feature_train_ori.py][L341][INFO] Step [25/2500000=0.00%] | Epoch 0 | Time 71.433 (71.433) | Lr 0.0001 | AIC Loss 0.25238 (0.25238) | All Losses 0.35641 (0.35641)
[2022-07-22 14:28:33,978][feature_train_ori.py][L341][INFO] Step [26/2500000=0.00%] | Epoch 0 | Time 71.076 (71.076) | Lr 0.0001 | AIC Loss 0.24412 (0.24412) | All Losses 0.34242 (0.34242)
[2022-07-22 14:29:44,534][feature_train_ori.py][L341][INFO] Step [27/2500000=0.00%] | Epoch 0 | Time 70.527 (70.527) | Lr 0.0001 | AIC Loss 0.23806 (0.23806) | All Losses 0.32514 (0.32514)
[2022-07-22 14:30:55,258][feature_train_ori.py][L341][INFO] Step [28/2500000=0.00%] | Epoch 0 | Time 70.697 (70.697) | Lr 0.0001 | AIC Loss 0.22833 (0.22833) | All Losses 0.30107 (0.30107)
[2022-07-22 14:32:06,746][feature_train_ori.py][L341][INFO] Step [29/2500000=0.00%] | Epoch 0 | Time 71.460 (71.460) | Lr 0.0001 | AIC Loss 0.24923 (0.24923) | All Losses 0.32676 (0.32676)
[2022-07-22 14:33:17,743][feature_train_ori.py][L341][INFO] Step [30/2500000=0.00%] | Epoch 0 | Time 70.970 (70.970) | Lr 0.0001 | AIC Loss 0.24478 (0.24478) | All Losses 0.33632 (0.33632)
[2022-07-22 14:34:31,143][feature_train_ori.py][L341][INFO] Step [31/2500000=0.00%] | Epoch 0 | Time 70.409 (70.409) | Lr 0.0001 | AIC Loss 0.23365 (0.23365) | All Losses 0.31238 (0.31238)
[2022-07-22 14:40:12,754][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-22 14:40:12,754][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-22 14:40:19,594][feature_train_ori.py][L384][INFO] Concatenation(
  (relu): LeakyReLU(negative_slope=0.01)
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv1): ConvTranspose2d(4096, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv11_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv2): ConvTranspose2d(4096, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv12_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv3): ConvTranspose2d(2048, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
  (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
  (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
)
[2022-07-22 14:40:26,708][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-22 14:41:43,693][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-22 14:41:43,693][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-22 14:41:50,531][feature_train_ori.py][L384][INFO] Concatenation(
  (relu): LeakyReLU(negative_slope=0.01)
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv1): ConvTranspose2d(4096, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv11_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv2): ConvTranspose2d(4096, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv12_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv3): ConvTranspose2d(2048, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool1): AdaptiveMaxPool2d(output_size=(22, 22))
  (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool2): AdaptiveMaxPool2d(output_size=(11, 11))
  (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
)
[2022-07-22 14:41:57,592][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-22 14:44:14,988][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-22 14:44:14,989][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-22 14:44:21,827][feature_train_ori.py][L384][INFO] Concatenation(
  (relu): LeakyReLU(negative_slope=0.01)
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv1): ConvTranspose2d(4096, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv11_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv2): ConvTranspose2d(4096, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv12_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv3): ConvTranspose2d(2048, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool1): AdaptiveMaxPool2d(output_size=(22, 22))
  (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool2): AdaptiveMaxPool2d(output_size=(11, 11))
  (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
)
[2022-07-22 14:44:28,942][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-22 14:45:48,591][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-22 14:45:48,591][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-22 14:45:55,411][feature_train_ori.py][L384][INFO] Concatenation(
  (relu): LeakyReLU(negative_slope=0.01)
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv1): ConvTranspose2d(4096, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv11_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv2): ConvTranspose2d(4096, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv12_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv3): ConvTranspose2d(2048, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool1): AdaptiveMaxPool2d(output_size=(44, 44))
  (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool2): AdaptiveMaxPool2d(output_size=(22, 22))
  (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
)
[2022-07-22 14:46:02,459][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-22 14:46:56,110][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-22 14:46:56,110][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-22 14:47:02,955][feature_train_ori.py][L384][INFO] Concatenation(
  (relu): LeakyReLU(negative_slope=0.01)
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv1): ConvTranspose2d(4096, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv11_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv2): ConvTranspose2d(4096, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv12_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv3): ConvTranspose2d(2048, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool1): AdaptiveMaxPool2d(output_size=(11, 11))
  (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool2): AdaptiveMaxPool2d(output_size=(6, 6))
  (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
)
[2022-07-22 14:47:10,021][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-22 14:50:31,564][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-22 14:50:31,564][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-22 14:50:38,414][feature_train_ori.py][L384][INFO] Concatenation(
  (relu): LeakyReLU(negative_slope=0.01)
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv1): ConvTranspose2d(4096, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv11_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv2): ConvTranspose2d(4096, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv12_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv3): ConvTranspose2d(2048, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
  (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
  (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
)
[2022-07-22 14:50:45,562][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-22 14:51:57,421][feature_train_ori.py][L341][INFO] Step [1/2500000=0.00%] | Epoch 0 | Time 71.386 (71.386) | Lr 0.0001 | AIC Loss 0.37069 (0.37069) | All Losses 2.09860 (2.09860)
[2022-07-22 14:53:08,769][feature_train_ori.py][L341][INFO] Step [2/2500000=0.00%] | Epoch 0 | Time 71.321 (71.321) | Lr 0.0001 | AIC Loss 0.40056 (0.40056) | All Losses 1.95092 (1.95092)
[2022-07-22 14:54:17,987][feature_train_ori.py][L341][INFO] Step [3/2500000=0.00%] | Epoch 0 | Time 69.191 (69.191) | Lr 0.0001 | AIC Loss 0.36339 (0.36339) | All Losses 1.84660 (1.84660)
[2022-07-22 14:55:26,588][feature_train_ori.py][L341][INFO] Step [4/2500000=0.00%] | Epoch 0 | Time 68.573 (68.573) | Lr 0.0001 | AIC Loss 0.36388 (0.36388) | All Losses 1.73204 (1.73204)
[2022-07-22 14:56:34,862][feature_train_ori.py][L341][INFO] Step [5/2500000=0.00%] | Epoch 0 | Time 68.247 (68.247) | Lr 0.0001 | AIC Loss 0.34515 (0.34515) | All Losses 1.73323 (1.73323)
[2022-07-22 14:57:43,145][feature_train_ori.py][L341][INFO] Step [6/2500000=0.00%] | Epoch 0 | Time 68.255 (68.255) | Lr 0.0001 | AIC Loss 0.33342 (0.33342) | All Losses 1.55370 (1.55370)
[2022-07-22 14:58:51,606][feature_train_ori.py][L341][INFO] Step [7/2500000=0.00%] | Epoch 0 | Time 68.434 (68.434) | Lr 0.0001 | AIC Loss 0.32547 (0.32547) | All Losses 1.58619 (1.58619)
[2022-07-22 15:00:00,193][feature_train_ori.py][L341][INFO] Step [8/2500000=0.00%] | Epoch 0 | Time 68.559 (68.559) | Lr 0.0001 | AIC Loss 0.34134 (0.34134) | All Losses 1.28797 (1.28797)
[2022-07-22 15:01:09,124][feature_train_ori.py][L341][INFO] Step [9/2500000=0.00%] | Epoch 0 | Time 68.905 (68.905) | Lr 0.0001 | AIC Loss 0.30213 (0.30213) | All Losses 1.31574 (1.31574)
[2022-07-22 15:02:17,919][feature_train_ori.py][L341][INFO] Step [10/2500000=0.00%] | Epoch 0 | Time 68.767 (68.767) | Lr 0.0001 | AIC Loss 0.27471 (0.27471) | All Losses 1.19620 (1.19620)
[2022-07-22 15:03:36,497][feature_train_ori.py][L341][INFO] Step [11/2500000=0.00%] | Epoch 0 | Time 68.646 (68.646) | Lr 0.0001 | AIC Loss 0.26538 (0.26538) | All Losses 1.25355 (1.25355)
[2022-07-22 15:04:46,150][feature_train_ori.py][L341][INFO] Step [12/2500000=0.00%] | Epoch 0 | Time 69.589 (69.589) | Lr 0.0001 | AIC Loss 0.27970 (0.27970) | All Losses 1.16812 (1.16812)
[2022-07-22 15:05:56,941][feature_train_ori.py][L341][INFO] Step [13/2500000=0.00%] | Epoch 0 | Time 70.727 (70.727) | Lr 0.0001 | AIC Loss 0.25914 (0.25914) | All Losses 1.11311 (1.11311)
[2022-07-22 15:07:07,998][feature_train_ori.py][L341][INFO] Step [14/2500000=0.00%] | Epoch 0 | Time 70.997 (70.997) | Lr 0.0001 | AIC Loss 0.25458 (0.25458) | All Losses 0.91484 (0.91484)
[2022-07-22 15:08:18,844][feature_train_ori.py][L341][INFO] Step [15/2500000=0.00%] | Epoch 0 | Time 70.780 (70.780) | Lr 0.0001 | AIC Loss 0.23402 (0.23402) | All Losses 0.92057 (0.92057)
[2022-07-22 15:09:29,889][feature_train_ori.py][L341][INFO] Step [16/2500000=0.00%] | Epoch 0 | Time 70.983 (70.983) | Lr 0.0001 | AIC Loss 0.26882 (0.26882) | All Losses 0.73153 (0.73153)
[2022-07-22 15:10:40,723][feature_train_ori.py][L341][INFO] Step [17/2500000=0.00%] | Epoch 0 | Time 70.772 (70.772) | Lr 0.0001 | AIC Loss 0.22902 (0.22902) | All Losses 0.86974 (0.86974)
[2022-07-22 15:11:51,834][feature_train_ori.py][L341][INFO] Step [18/2500000=0.00%] | Epoch 0 | Time 71.052 (71.052) | Lr 0.0001 | AIC Loss 0.24031 (0.24031) | All Losses 0.71677 (0.71677)
[2022-07-22 15:13:02,640][feature_train_ori.py][L341][INFO] Step [19/2500000=0.00%] | Epoch 0 | Time 70.746 (70.746) | Lr 0.0001 | AIC Loss 0.24122 (0.24122) | All Losses 0.70474 (0.70474)
[2022-07-22 15:14:13,576][feature_train_ori.py][L341][INFO] Step [20/2500000=0.00%] | Epoch 0 | Time 70.870 (70.870) | Lr 0.0001 | AIC Loss 0.20212 (0.20212) | All Losses 0.60810 (0.60810)
[2022-07-22 15:15:38,401][feature_train_ori.py][L341][INFO] Step [21/2500000=0.00%] | Epoch 0 | Time 74.835 (74.835) | Lr 0.0001 | AIC Loss 0.20252 (0.20252) | All Losses 0.76110 (0.76110)
[2022-07-22 15:16:50,468][feature_train_ori.py][L341][INFO] Step [22/2500000=0.00%] | Epoch 0 | Time 71.999 (71.999) | Lr 0.0001 | AIC Loss 0.20577 (0.20577) | All Losses 0.53450 (0.53450)
[2022-07-22 15:18:01,749][feature_train_ori.py][L341][INFO] Step [23/2500000=0.00%] | Epoch 0 | Time 71.219 (71.219) | Lr 0.0001 | AIC Loss 0.19844 (0.19844) | All Losses 0.64766 (0.64766)
[2022-07-22 15:19:12,942][feature_train_ori.py][L341][INFO] Step [24/2500000=0.00%] | Epoch 0 | Time 71.131 (71.131) | Lr 0.0001 | AIC Loss 0.19867 (0.19867) | All Losses 0.58824 (0.58824)
[2022-07-22 15:20:27,465][feature_train_ori.py][L341][INFO] Step [25/2500000=0.00%] | Epoch 0 | Time 74.453 (74.453) | Lr 0.0001 | AIC Loss 0.19933 (0.19933) | All Losses 0.51729 (0.51729)
[2022-07-22 15:21:36,947][feature_train_ori.py][L341][INFO] Step [26/2500000=0.00%] | Epoch 0 | Time 69.453 (69.453) | Lr 0.0001 | AIC Loss 0.20556 (0.20556) | All Losses 0.53835 (0.53835)
[2022-07-22 15:22:46,081][feature_train_ori.py][L341][INFO] Step [27/2500000=0.00%] | Epoch 0 | Time 69.107 (69.107) | Lr 0.0001 | AIC Loss 0.18056 (0.18056) | All Losses 0.51060 (0.51060)
[2022-07-22 15:23:55,932][feature_train_ori.py][L341][INFO] Step [28/2500000=0.00%] | Epoch 0 | Time 69.824 (69.824) | Lr 0.0001 | AIC Loss 0.16696 (0.16696) | All Losses 0.44604 (0.44604)
[2022-07-22 15:25:05,189][feature_train_ori.py][L341][INFO] Step [29/2500000=0.00%] | Epoch 0 | Time 69.221 (69.221) | Lr 0.0001 | AIC Loss 0.15523 (0.15523) | All Losses 0.40126 (0.40126)
[2022-07-22 15:26:14,536][feature_train_ori.py][L341][INFO] Step [30/2500000=0.00%] | Epoch 0 | Time 69.319 (69.319) | Lr 0.0001 | AIC Loss 0.16559 (0.16559) | All Losses 0.62463 (0.62463)
[2022-07-22 15:27:34,864][feature_train_ori.py][L341][INFO] Step [31/2500000=0.00%] | Epoch 0 | Time 70.354 (70.354) | Lr 0.0001 | AIC Loss 0.15172 (0.15172) | All Losses 0.53272 (0.53272)
[2022-07-22 15:28:44,468][feature_train_ori.py][L341][INFO] Step [32/2500000=0.00%] | Epoch 0 | Time 69.567 (69.567) | Lr 0.0001 | AIC Loss 0.17459 (0.17459) | All Losses 0.42537 (0.42537)
[2022-07-22 15:29:54,743][feature_train_ori.py][L341][INFO] Step [33/2500000=0.00%] | Epoch 0 | Time 70.247 (70.247) | Lr 0.0001 | AIC Loss 0.15461 (0.15461) | All Losses 0.37058 (0.37058)
[2022-07-22 15:31:04,625][feature_train_ori.py][L341][INFO] Step [34/2500000=0.00%] | Epoch 0 | Time 69.819 (69.819) | Lr 0.0001 | AIC Loss 0.15612 (0.15612) | All Losses 0.42946 (0.42946)
[2022-07-22 15:32:17,121][feature_train_ori.py][L341][INFO] Step [35/2500000=0.00%] | Epoch 0 | Time 72.435 (72.435) | Lr 0.0001 | AIC Loss 0.16283 (0.16283) | All Losses 0.43967 (0.43967)
[2022-07-22 15:33:28,799][feature_train_ori.py][L341][INFO] Step [36/2500000=0.00%] | Epoch 0 | Time 71.613 (71.613) | Lr 0.0001 | AIC Loss 0.15714 (0.15714) | All Losses 0.51204 (0.51204)
[2022-07-22 15:34:40,626][feature_train_ori.py][L341][INFO] Step [37/2500000=0.00%] | Epoch 0 | Time 71.766 (71.766) | Lr 0.0001 | AIC Loss 0.17128 (0.17128) | All Losses 0.32934 (0.32934)
[2022-07-22 15:35:54,155][feature_train_ori.py][L341][INFO] Step [38/2500000=0.00%] | Epoch 0 | Time 73.435 (73.435) | Lr 0.0001 | AIC Loss 0.15742 (0.15742) | All Losses 0.45304 (0.45304)
[2022-07-22 15:37:13,915][feature_train_ori.py][L341][INFO] Step [39/2500000=0.00%] | Epoch 0 | Time 79.659 (79.659) | Lr 0.0001 | AIC Loss 0.15561 (0.15561) | All Losses 0.40217 (0.40217)
[2022-07-22 15:38:33,730][feature_train_ori.py][L341][INFO] Step [40/2500000=0.00%] | Epoch 0 | Time 79.704 (79.704) | Lr 0.0001 | AIC Loss 0.12901 (0.12901) | All Losses 0.36885 (0.36885)
[2022-07-22 15:39:55,911][feature_train_ori.py][L341][INFO] Step [41/2500000=0.00%] | Epoch 0 | Time 79.239 (79.239) | Lr 0.0001 | AIC Loss 0.15160 (0.15160) | All Losses 0.35427 (0.35427)
[2022-07-22 15:41:15,273][feature_train_ori.py][L341][INFO] Step [42/2500000=0.00%] | Epoch 0 | Time 79.277 (79.277) | Lr 0.0001 | AIC Loss 0.13894 (0.13894) | All Losses 0.34421 (0.34421)
[2022-07-22 15:42:34,791][feature_train_ori.py][L341][INFO] Step [43/2500000=0.00%] | Epoch 0 | Time 79.421 (79.421) | Lr 0.0001 | AIC Loss 0.13702 (0.13702) | All Losses 0.28549 (0.28549)
[2022-07-22 15:43:48,386][feature_train_ori.py][L341][INFO] Step [44/2500000=0.00%] | Epoch 0 | Time 73.531 (73.531) | Lr 0.0001 | AIC Loss 0.13637 (0.13637) | All Losses 0.34981 (0.34981)
[2022-07-22 15:45:00,291][feature_train_ori.py][L341][INFO] Step [45/2500000=0.00%] | Epoch 0 | Time 71.840 (71.840) | Lr 0.0001 | AIC Loss 0.14689 (0.14689) | All Losses 0.33638 (0.33638)
[2022-07-22 15:46:12,356][feature_train_ori.py][L341][INFO] Step [46/2500000=0.00%] | Epoch 0 | Time 72.005 (72.005) | Lr 0.0001 | AIC Loss 0.12009 (0.12009) | All Losses 0.30411 (0.30411)
[2022-07-22 15:47:24,539][feature_train_ori.py][L341][INFO] Step [47/2500000=0.00%] | Epoch 0 | Time 72.119 (72.119) | Lr 0.0001 | AIC Loss 0.12490 (0.12490) | All Losses 0.27710 (0.27710)
[2022-07-22 15:48:34,995][feature_train_ori.py][L341][INFO] Step [48/2500000=0.00%] | Epoch 0 | Time 70.428 (70.428) | Lr 0.0001 | AIC Loss 0.13519 (0.13519) | All Losses 0.32784 (0.32784)
[2022-07-22 15:49:45,209][feature_train_ori.py][L341][INFO] Step [49/2500000=0.00%] | Epoch 0 | Time 70.186 (70.186) | Lr 0.0001 | AIC Loss 0.12081 (0.12081) | All Losses 0.29281 (0.29281)
[2022-07-22 15:50:54,891][feature_train_ori.py][L341][INFO] Step [50/2500000=0.00%] | Epoch 0 | Time 69.655 (69.655) | Lr 0.0001 | AIC Loss 0.12370 (0.12370) | All Losses 0.25192 (0.25192)
[2022-07-22 15:52:07,524][feature_train_ori.py][L341][INFO] Step [51/2500000=0.00%] | Epoch 0 | Time 69.787 (69.787) | Lr 0.0001 | AIC Loss 0.12618 (0.12618) | All Losses 0.41416 (0.41416)
[2022-07-22 15:53:17,802][feature_train_ori.py][L341][INFO] Step [52/2500000=0.00%] | Epoch 0 | Time 70.250 (70.250) | Lr 0.0001 | AIC Loss 0.11415 (0.11415) | All Losses 0.26294 (0.26294)
[2022-07-22 15:54:27,836][feature_train_ori.py][L341][INFO] Step [53/2500000=0.00%] | Epoch 0 | Time 70.008 (70.008) | Lr 0.0001 | AIC Loss 0.11932 (0.11932) | All Losses 0.29660 (0.29660)
[2022-07-22 15:55:38,347][feature_train_ori.py][L341][INFO] Step [54/2500000=0.00%] | Epoch 0 | Time 70.485 (70.485) | Lr 0.0001 | AIC Loss 0.13342 (0.13342) | All Losses 0.28155 (0.28155)
[2022-07-22 15:56:48,411][feature_train_ori.py][L341][INFO] Step [55/2500000=0.00%] | Epoch 0 | Time 70.036 (70.036) | Lr 0.0001 | AIC Loss 0.11403 (0.11403) | All Losses 0.29796 (0.29796)
[2022-07-22 15:57:58,537][feature_train_ori.py][L341][INFO] Step [56/2500000=0.00%] | Epoch 0 | Time 70.098 (70.098) | Lr 0.0001 | AIC Loss 0.12701 (0.12701) | All Losses 0.27777 (0.27777)
[2022-07-22 15:59:08,575][feature_train_ori.py][L341][INFO] Step [57/2500000=0.00%] | Epoch 0 | Time 70.011 (70.011) | Lr 0.0001 | AIC Loss 0.13329 (0.13329) | All Losses 0.21790 (0.21790)
[2022-07-22 16:00:18,557][feature_train_ori.py][L341][INFO] Step [58/2500000=0.00%] | Epoch 0 | Time 69.954 (69.954) | Lr 0.0001 | AIC Loss 0.11046 (0.11046) | All Losses 0.23570 (0.23570)
[2022-07-22 16:01:28,302][feature_train_ori.py][L341][INFO] Step [59/2500000=0.00%] | Epoch 0 | Time 69.717 (69.717) | Lr 0.0001 | AIC Loss 0.12304 (0.12304) | All Losses 0.28226 (0.28226)
[2022-07-22 16:02:38,424][feature_train_ori.py][L341][INFO] Step [60/2500000=0.00%] | Epoch 0 | Time 70.095 (70.095) | Lr 0.0001 | AIC Loss 0.10660 (0.10660) | All Losses 0.26506 (0.26506)
[2022-07-22 16:03:51,588][feature_train_ori.py][L341][INFO] Step [61/2500000=0.00%] | Epoch 0 | Time 70.341 (70.341) | Lr 0.0001 | AIC Loss 0.10019 (0.10019) | All Losses 0.20947 (0.20947)
[2022-07-22 16:05:01,299][feature_train_ori.py][L341][INFO] Step [62/2500000=0.00%] | Epoch 0 | Time 69.683 (69.683) | Lr 0.0001 | AIC Loss 0.12529 (0.12529) | All Losses 0.31660 (0.31660)
[2022-07-22 16:06:10,280][feature_train_ori.py][L341][INFO] Step [63/2500000=0.00%] | Epoch 0 | Time 68.953 (68.953) | Lr 0.0001 | AIC Loss 0.11283 (0.11283) | All Losses 0.29438 (0.29438)
[2022-07-22 16:07:18,985][feature_train_ori.py][L341][INFO] Step [64/2500000=0.00%] | Epoch 0 | Time 68.677 (68.677) | Lr 0.0001 | AIC Loss 0.10550 (0.10550) | All Losses 0.20368 (0.20368)
[2022-07-22 16:08:28,540][feature_train_ori.py][L341][INFO] Step [65/2500000=0.00%] | Epoch 0 | Time 69.527 (69.527) | Lr 0.0001 | AIC Loss 0.10459 (0.10459) | All Losses 0.21053 (0.21053)
[2022-07-22 16:09:38,115][feature_train_ori.py][L341][INFO] Step [66/2500000=0.00%] | Epoch 0 | Time 69.547 (69.547) | Lr 0.0001 | AIC Loss 0.11330 (0.11330) | All Losses 0.27724 (0.27724)
[2022-07-22 16:10:47,838][feature_train_ori.py][L341][INFO] Step [67/2500000=0.00%] | Epoch 0 | Time 69.696 (69.696) | Lr 0.0001 | AIC Loss 0.10591 (0.10591) | All Losses 0.22102 (0.22102)
[2022-07-22 16:11:57,357][feature_train_ori.py][L341][INFO] Step [68/2500000=0.00%] | Epoch 0 | Time 69.491 (69.491) | Lr 0.0001 | AIC Loss 0.10139 (0.10139) | All Losses 0.24922 (0.24922)
[2022-07-22 16:13:07,136][feature_train_ori.py][L341][INFO] Step [69/2500000=0.00%] | Epoch 0 | Time 69.751 (69.751) | Lr 0.0001 | AIC Loss 0.10858 (0.10858) | All Losses 0.23669 (0.23669)
[2022-07-22 16:14:16,871][feature_train_ori.py][L341][INFO] Step [70/2500000=0.00%] | Epoch 0 | Time 69.708 (69.708) | Lr 0.0001 | AIC Loss 0.09746 (0.09746) | All Losses 0.24067 (0.24067)
[2022-07-22 16:15:30,200][feature_train_ori.py][L341][INFO] Step [71/2500000=0.00%] | Epoch 0 | Time 70.435 (70.435) | Lr 0.0001 | AIC Loss 0.10048 (0.10048) | All Losses 0.19259 (0.19259)
[2022-07-22 16:16:40,050][feature_train_ori.py][L341][INFO] Step [72/2500000=0.00%] | Epoch 0 | Time 69.823 (69.823) | Lr 0.0001 | AIC Loss 0.09957 (0.09957) | All Losses 0.19492 (0.19492)
[2022-07-22 16:17:49,635][feature_train_ori.py][L341][INFO] Step [73/2500000=0.00%] | Epoch 0 | Time 69.557 (69.557) | Lr 0.0001 | AIC Loss 0.10713 (0.10713) | All Losses 0.23687 (0.23687)
[2022-07-22 16:18:59,461][feature_train_ori.py][L341][INFO] Step [74/2500000=0.00%] | Epoch 0 | Time 69.798 (69.798) | Lr 0.0001 | AIC Loss 0.10217 (0.10217) | All Losses 0.20957 (0.20957)
[2022-07-22 16:20:09,228][feature_train_ori.py][L341][INFO] Step [75/2500000=0.00%] | Epoch 0 | Time 69.740 (69.740) | Lr 0.0001 | AIC Loss 0.11325 (0.11325) | All Losses 0.21982 (0.21982)
[2022-07-22 16:21:18,798][feature_train_ori.py][L341][INFO] Step [76/2500000=0.00%] | Epoch 0 | Time 69.542 (69.542) | Lr 0.0001 | AIC Loss 0.10183 (0.10183) | All Losses 0.17089 (0.17089)
[2022-07-22 16:22:28,374][feature_train_ori.py][L341][INFO] Step [77/2500000=0.00%] | Epoch 0 | Time 69.548 (69.548) | Lr 0.0001 | AIC Loss 0.10550 (0.10550) | All Losses 0.19649 (0.19649)
[2022-07-22 16:23:37,977][feature_train_ori.py][L341][INFO] Step [78/2500000=0.00%] | Epoch 0 | Time 69.575 (69.575) | Lr 0.0001 | AIC Loss 0.10884 (0.10884) | All Losses 0.24791 (0.24791)
[2022-07-22 16:24:47,423][feature_train_ori.py][L341][INFO] Step [79/2500000=0.00%] | Epoch 0 | Time 69.418 (69.418) | Lr 0.0001 | AIC Loss 0.11191 (0.11191) | All Losses 0.29793 (0.29793)
[2022-07-22 16:25:57,132][feature_train_ori.py][L341][INFO] Step [80/2500000=0.00%] | Epoch 0 | Time 69.681 (69.681) | Lr 0.0001 | AIC Loss 0.10674 (0.10674) | All Losses 0.20174 (0.20174)
[2022-07-22 16:27:09,690][feature_train_ori.py][L341][INFO] Step [81/2500000=0.00%] | Epoch 0 | Time 69.712 (69.712) | Lr 0.0001 | AIC Loss 0.09940 (0.09940) | All Losses 0.18228 (0.18228)
[2022-07-22 16:28:19,570][feature_train_ori.py][L341][INFO] Step [82/2500000=0.00%] | Epoch 0 | Time 69.852 (69.852) | Lr 0.0001 | AIC Loss 0.09611 (0.09611) | All Losses 0.15967 (0.15967)
[2022-07-22 16:29:28,879][feature_train_ori.py][L341][INFO] Step [83/2500000=0.00%] | Epoch 0 | Time 69.282 (69.282) | Lr 0.0001 | AIC Loss 0.11097 (0.11097) | All Losses 0.27681 (0.27681)
[2022-07-22 16:30:38,329][feature_train_ori.py][L341][INFO] Step [84/2500000=0.00%] | Epoch 0 | Time 69.422 (69.422) | Lr 0.0001 | AIC Loss 0.10663 (0.10663) | All Losses 0.15173 (0.15173)
[2022-07-22 16:31:47,757][feature_train_ori.py][L341][INFO] Step [85/2500000=0.00%] | Epoch 0 | Time 69.401 (69.401) | Lr 0.0001 | AIC Loss 0.09975 (0.09975) | All Losses 0.20134 (0.20134)
[2022-07-22 16:32:57,276][feature_train_ori.py][L341][INFO] Step [86/2500000=0.00%] | Epoch 0 | Time 69.492 (69.492) | Lr 0.0001 | AIC Loss 0.10219 (0.10219) | All Losses 0.25614 (0.25614)
[2022-07-22 16:34:07,043][feature_train_ori.py][L341][INFO] Step [87/2500000=0.00%] | Epoch 0 | Time 69.739 (69.739) | Lr 0.0001 | AIC Loss 0.09512 (0.09512) | All Losses 0.18982 (0.18982)
[2022-07-22 16:35:16,834][feature_train_ori.py][L341][INFO] Step [88/2500000=0.00%] | Epoch 0 | Time 69.764 (69.764) | Lr 0.0001 | AIC Loss 0.09928 (0.09928) | All Losses 0.28181 (0.28181)
[2022-07-22 16:36:26,401][feature_train_ori.py][L341][INFO] Step [89/2500000=0.00%] | Epoch 0 | Time 69.539 (69.539) | Lr 0.0001 | AIC Loss 0.10565 (0.10565) | All Losses 0.18698 (0.18698)
[2022-07-22 16:37:36,031][feature_train_ori.py][L341][INFO] Step [90/2500000=0.00%] | Epoch 0 | Time 69.603 (69.603) | Lr 0.0001 | AIC Loss 0.10125 (0.10125) | All Losses 0.20892 (0.20892)
[2022-07-22 16:38:48,365][feature_train_ori.py][L341][INFO] Step [91/2500000=0.00%] | Epoch 0 | Time 69.502 (69.502) | Lr 0.0001 | AIC Loss 0.10025 (0.10025) | All Losses 0.16121 (0.16121)
[2022-07-22 16:39:57,942][feature_train_ori.py][L341][INFO] Step [92/2500000=0.00%] | Epoch 0 | Time 69.550 (69.550) | Lr 0.0001 | AIC Loss 0.09202 (0.09202) | All Losses 0.18995 (0.18995)
[2022-07-22 16:41:07,876][feature_train_ori.py][L341][INFO] Step [93/2500000=0.00%] | Epoch 0 | Time 69.906 (69.906) | Lr 0.0001 | AIC Loss 0.09469 (0.09469) | All Losses 0.16843 (0.16843)
[2022-07-22 16:42:17,144][feature_train_ori.py][L341][INFO] Step [94/2500000=0.00%] | Epoch 0 | Time 69.240 (69.240) | Lr 0.0001 | AIC Loss 0.10597 (0.10597) | All Losses 0.25156 (0.25156)
[2022-07-22 16:43:26,969][feature_train_ori.py][L341][INFO] Step [95/2500000=0.00%] | Epoch 0 | Time 69.790 (69.790) | Lr 0.0001 | AIC Loss 0.08937 (0.08937) | All Losses 0.28316 (0.28316)
[2022-07-22 16:44:36,715][feature_train_ori.py][L341][INFO] Step [96/2500000=0.00%] | Epoch 0 | Time 69.718 (69.718) | Lr 0.0001 | AIC Loss 0.10057 (0.10057) | All Losses 0.20809 (0.20809)
[2022-07-22 16:45:47,292][feature_train_ori.py][L341][INFO] Step [97/2500000=0.00%] | Epoch 0 | Time 70.550 (70.550) | Lr 0.0001 | AIC Loss 0.08726 (0.08726) | All Losses 0.19540 (0.19540)
[2022-07-22 16:46:56,448][feature_train_ori.py][L341][INFO] Step [98/2500000=0.00%] | Epoch 0 | Time 69.128 (69.128) | Lr 0.0001 | AIC Loss 0.08764 (0.08764) | All Losses 0.18904 (0.18904)
[2022-07-22 16:48:05,790][feature_train_ori.py][L341][INFO] Step [99/2500000=0.00%] | Epoch 0 | Time 69.315 (69.315) | Lr 0.0001 | AIC Loss 0.09187 (0.09187) | All Losses 0.16070 (0.16070)
[2022-07-22 16:49:14,946][feature_train_ori.py][L341][INFO] Step [100/2500000=0.00%] | Epoch 0 | Time 69.129 (69.129) | Lr 0.0001 | AIC Loss 0.10098 (0.10098) | All Losses 0.21376 (0.21376)
[2022-07-22 16:50:26,873][feature_train_ori.py][L341][INFO] Step [101/2500000=0.00%] | Epoch 0 | Time 69.105 (69.105) | Lr 0.0001 | AIC Loss 0.08865 (0.08865) | All Losses 0.17291 (0.17291)
[2022-07-22 16:51:35,972][feature_train_ori.py][L341][INFO] Step [102/2500000=0.00%] | Epoch 0 | Time 69.072 (69.072) | Lr 0.0001 | AIC Loss 0.08957 (0.08957) | All Losses 0.17709 (0.17709)
[2022-07-22 16:52:46,760][feature_train_ori.py][L341][INFO] Step [103/2500000=0.00%] | Epoch 0 | Time 70.763 (70.763) | Lr 0.0001 | AIC Loss 0.09219 (0.09219) | All Losses 0.17975 (0.17975)
[2022-07-22 16:53:57,247][feature_train_ori.py][L341][INFO] Step [104/2500000=0.00%] | Epoch 0 | Time 70.454 (70.454) | Lr 0.0001 | AIC Loss 0.10748 (0.10748) | All Losses 0.17252 (0.17252)
[2022-07-22 16:55:07,873][feature_train_ori.py][L341][INFO] Step [105/2500000=0.00%] | Epoch 0 | Time 70.598 (70.598) | Lr 0.0001 | AIC Loss 0.09752 (0.09752) | All Losses 0.14591 (0.14591)
[2022-07-22 16:56:17,982][feature_train_ori.py][L341][INFO] Step [106/2500000=0.00%] | Epoch 0 | Time 70.082 (70.082) | Lr 0.0001 | AIC Loss 0.08907 (0.08907) | All Losses 0.15615 (0.15615)
[2022-07-22 16:57:27,660][feature_train_ori.py][L341][INFO] Step [107/2500000=0.00%] | Epoch 0 | Time 69.651 (69.651) | Lr 0.0001 | AIC Loss 0.09688 (0.09688) | All Losses 0.19186 (0.19186)
[2022-07-22 16:58:36,859][feature_train_ori.py][L341][INFO] Step [108/2500000=0.00%] | Epoch 0 | Time 69.170 (69.170) | Lr 0.0001 | AIC Loss 0.09511 (0.09511) | All Losses 0.15075 (0.15075)
[2022-07-22 16:59:46,115][feature_train_ori.py][L341][INFO] Step [109/2500000=0.00%] | Epoch 0 | Time 69.229 (69.229) | Lr 0.0001 | AIC Loss 0.08957 (0.08957) | All Losses 0.17523 (0.17523)
[2022-07-22 17:00:55,869][feature_train_ori.py][L341][INFO] Step [110/2500000=0.00%] | Epoch 0 | Time 69.726 (69.726) | Lr 0.0001 | AIC Loss 0.09240 (0.09240) | All Losses 0.21886 (0.21886)
[2022-07-22 17:02:07,530][feature_train_ori.py][L341][INFO] Step [111/2500000=0.00%] | Epoch 0 | Time 68.836 (68.836) | Lr 0.0001 | AIC Loss 0.10090 (0.10090) | All Losses 0.16840 (0.16840)
[2022-07-22 17:03:16,829][feature_train_ori.py][L341][INFO] Step [112/2500000=0.00%] | Epoch 0 | Time 69.272 (69.272) | Lr 0.0001 | AIC Loss 0.08405 (0.08405) | All Losses 0.18694 (0.18694)
[2022-07-22 17:04:25,985][feature_train_ori.py][L341][INFO] Step [113/2500000=0.00%] | Epoch 0 | Time 69.128 (69.128) | Lr 0.0001 | AIC Loss 0.08885 (0.08885) | All Losses 0.18171 (0.18171)
[2022-07-22 17:05:34,986][feature_train_ori.py][L341][INFO] Step [114/2500000=0.00%] | Epoch 0 | Time 68.973 (68.973) | Lr 0.0001 | AIC Loss 0.09314 (0.09314) | All Losses 0.15689 (0.15689)
[2022-07-22 17:06:44,263][feature_train_ori.py][L341][INFO] Step [115/2500000=0.00%] | Epoch 0 | Time 69.250 (69.250) | Lr 0.0001 | AIC Loss 0.08254 (0.08254) | All Losses 0.22608 (0.22608)
[2022-07-22 17:07:53,306][feature_train_ori.py][L341][INFO] Step [116/2500000=0.00%] | Epoch 0 | Time 69.014 (69.014) | Lr 0.0001 | AIC Loss 0.09354 (0.09354) | All Losses 0.17038 (0.17038)
[2022-07-22 17:09:02,325][feature_train_ori.py][L341][INFO] Step [117/2500000=0.00%] | Epoch 0 | Time 68.992 (68.992) | Lr 0.0001 | AIC Loss 0.08685 (0.08685) | All Losses 0.15644 (0.15644)
[2022-07-22 17:10:11,512][feature_train_ori.py][L341][INFO] Step [118/2500000=0.00%] | Epoch 0 | Time 69.159 (69.159) | Lr 0.0001 | AIC Loss 0.08372 (0.08372) | All Losses 0.18463 (0.18463)
[2022-07-22 17:11:20,603][feature_train_ori.py][L341][INFO] Step [119/2500000=0.00%] | Epoch 0 | Time 69.063 (69.063) | Lr 0.0001 | AIC Loss 0.08568 (0.08568) | All Losses 0.15796 (0.15796)
[2022-07-22 17:12:30,336][feature_train_ori.py][L341][INFO] Step [120/2500000=0.00%] | Epoch 0 | Time 69.705 (69.705) | Lr 0.0001 | AIC Loss 0.07923 (0.07923) | All Losses 0.15054 (0.15054)
[2022-07-22 17:13:42,566][feature_train_ori.py][L341][INFO] Step [121/2500000=0.00%] | Epoch 0 | Time 69.401 (69.401) | Lr 0.0001 | AIC Loss 0.08708 (0.08708) | All Losses 0.17072 (0.17072)
[2022-07-22 17:14:52,310][feature_train_ori.py][L341][INFO] Step [122/2500000=0.00%] | Epoch 0 | Time 69.716 (69.716) | Lr 0.0001 | AIC Loss 0.08559 (0.08559) | All Losses 0.14192 (0.14192)
[2022-07-22 17:16:01,932][feature_train_ori.py][L341][INFO] Step [123/2500000=0.00%] | Epoch 0 | Time 69.594 (69.594) | Lr 0.0001 | AIC Loss 0.07895 (0.07895) | All Losses 0.14515 (0.14515)
[2022-07-22 17:17:11,458][feature_train_ori.py][L341][INFO] Step [124/2500000=0.00%] | Epoch 0 | Time 69.497 (69.497) | Lr 0.0001 | AIC Loss 0.08563 (0.08563) | All Losses 0.16680 (0.16680)
[2022-07-22 17:18:20,795][feature_train_ori.py][L341][INFO] Step [125/2500000=0.01%] | Epoch 0 | Time 69.310 (69.310) | Lr 0.0001 | AIC Loss 0.08640 (0.08640) | All Losses 0.16733 (0.16733)
[2022-07-22 17:19:30,695][feature_train_ori.py][L341][INFO] Step [126/2500000=0.01%] | Epoch 0 | Time 69.873 (69.873) | Lr 0.0001 | AIC Loss 0.06649 (0.06649) | All Losses 0.11796 (0.11796)
[2022-07-22 17:20:40,824][feature_train_ori.py][L341][INFO] Step [127/2500000=0.01%] | Epoch 0 | Time 70.101 (70.101) | Lr 0.0001 | AIC Loss 0.08417 (0.08417) | All Losses 0.16001 (0.16001)
[2022-07-22 17:21:50,356][feature_train_ori.py][L341][INFO] Step [128/2500000=0.01%] | Epoch 0 | Time 69.504 (69.504) | Lr 0.0001 | AIC Loss 0.08676 (0.08676) | All Losses 0.13471 (0.13471)
[2022-07-22 17:23:00,241][feature_train_ori.py][L341][INFO] Step [129/2500000=0.01%] | Epoch 0 | Time 69.858 (69.858) | Lr 0.0001 | AIC Loss 0.08904 (0.08904) | All Losses 0.13370 (0.13370)
[2022-07-22 17:24:10,003][feature_train_ori.py][L341][INFO] Step [130/2500000=0.01%] | Epoch 0 | Time 69.734 (69.734) | Lr 0.0001 | AIC Loss 0.08932 (0.08932) | All Losses 0.15360 (0.15360)
[2022-07-22 17:25:24,168][feature_train_ori.py][L341][INFO] Step [131/2500000=0.01%] | Epoch 0 | Time 71.157 (71.157) | Lr 0.0001 | AIC Loss 0.09693 (0.09693) | All Losses 0.12141 (0.12141)
[2022-07-22 17:26:34,660][feature_train_ori.py][L341][INFO] Step [132/2500000=0.01%] | Epoch 0 | Time 70.464 (70.464) | Lr 0.0001 | AIC Loss 0.07788 (0.07788) | All Losses 0.12999 (0.12999)
[2022-07-22 17:27:44,258][feature_train_ori.py][L341][INFO] Step [133/2500000=0.01%] | Epoch 0 | Time 69.570 (69.570) | Lr 0.0001 | AIC Loss 0.08040 (0.08040) | All Losses 0.17328 (0.17328)
[2022-07-22 17:28:53,876][feature_train_ori.py][L341][INFO] Step [134/2500000=0.01%] | Epoch 0 | Time 69.589 (69.589) | Lr 0.0001 | AIC Loss 0.10527 (0.10527) | All Losses 0.15685 (0.15685)
[2022-07-22 17:30:03,062][feature_train_ori.py][L341][INFO] Step [135/2500000=0.01%] | Epoch 0 | Time 69.159 (69.159) | Lr 0.0001 | AIC Loss 0.09097 (0.09097) | All Losses 0.20669 (0.20669)
[2022-07-22 17:31:12,898][feature_train_ori.py][L341][INFO] Step [136/2500000=0.01%] | Epoch 0 | Time 69.798 (69.798) | Lr 0.0001 | AIC Loss 0.08965 (0.08965) | All Losses 0.16205 (0.16205)
[2022-07-22 17:32:23,235][feature_train_ori.py][L341][INFO] Step [137/2500000=0.01%] | Epoch 0 | Time 70.307 (70.307) | Lr 0.0001 | AIC Loss 0.08564 (0.08564) | All Losses 0.14788 (0.14788)
[2022-07-22 17:33:32,637][feature_train_ori.py][L341][INFO] Step [138/2500000=0.01%] | Epoch 0 | Time 69.374 (69.374) | Lr 0.0001 | AIC Loss 0.08662 (0.08662) | All Losses 0.15233 (0.15233)
[2022-07-22 17:34:42,649][feature_train_ori.py][L341][INFO] Step [139/2500000=0.01%] | Epoch 0 | Time 69.981 (69.981) | Lr 0.0001 | AIC Loss 0.08406 (0.08406) | All Losses 0.12079 (0.12079)
[2022-07-22 17:35:53,114][feature_train_ori.py][L341][INFO] Step [140/2500000=0.01%] | Epoch 0 | Time 70.437 (70.437) | Lr 0.0001 | AIC Loss 0.08830 (0.08830) | All Losses 0.15144 (0.15144)
[2022-07-22 17:37:06,493][feature_train_ori.py][L341][INFO] Step [141/2500000=0.01%] | Epoch 0 | Time 70.509 (70.509) | Lr 0.0001 | AIC Loss 0.07923 (0.07923) | All Losses 0.16882 (0.16882)
[2022-07-22 17:38:16,175][feature_train_ori.py][L341][INFO] Step [142/2500000=0.01%] | Epoch 0 | Time 69.655 (69.655) | Lr 0.0001 | AIC Loss 0.08704 (0.08704) | All Losses 0.17552 (0.17552)
[2022-07-22 17:39:25,710][feature_train_ori.py][L341][INFO] Step [143/2500000=0.01%] | Epoch 0 | Time 69.507 (69.507) | Lr 0.0001 | AIC Loss 0.08994 (0.08994) | All Losses 0.16000 (0.16000)
[2022-07-22 17:40:35,275][feature_train_ori.py][L341][INFO] Step [144/2500000=0.01%] | Epoch 0 | Time 69.537 (69.537) | Lr 0.0001 | AIC Loss 0.09008 (0.09008) | All Losses 0.16627 (0.16627)
[2022-07-22 17:41:45,272][feature_train_ori.py][L341][INFO] Step [145/2500000=0.01%] | Epoch 0 | Time 69.969 (69.969) | Lr 0.0001 | AIC Loss 0.08300 (0.08300) | All Losses 0.15805 (0.15805)
[2022-07-22 17:42:55,304][feature_train_ori.py][L341][INFO] Step [146/2500000=0.01%] | Epoch 0 | Time 70.005 (70.005) | Lr 0.0001 | AIC Loss 0.07274 (0.07274) | All Losses 0.11708 (0.11708)
[2022-07-22 17:44:04,854][feature_train_ori.py][L341][INFO] Step [147/2500000=0.01%] | Epoch 0 | Time 69.522 (69.522) | Lr 0.0001 | AIC Loss 0.09513 (0.09513) | All Losses 0.13784 (0.13784)
[2022-07-22 17:45:14,576][feature_train_ori.py][L341][INFO] Step [148/2500000=0.01%] | Epoch 0 | Time 69.695 (69.695) | Lr 0.0001 | AIC Loss 0.08371 (0.08371) | All Losses 0.11307 (0.11307)
[2022-07-22 17:46:24,347][feature_train_ori.py][L341][INFO] Step [149/2500000=0.01%] | Epoch 0 | Time 69.743 (69.743) | Lr 0.0001 | AIC Loss 0.08912 (0.08912) | All Losses 0.11378 (0.11378)
[2022-07-22 17:47:34,323][feature_train_ori.py][L341][INFO] Step [150/2500000=0.01%] | Epoch 0 | Time 69.949 (69.949) | Lr 0.0001 | AIC Loss 0.07461 (0.07461) | All Losses 0.15487 (0.15487)
[2022-07-22 19:27:20,895][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-22 19:27:20,896][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-22 19:27:47,321][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-22 19:27:47,321][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-22 19:27:55,060][feature_train_ori.py][L384][INFO] Concatenation(
  (relu): LeakyReLU(negative_slope=0.01)
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv1): ConvTranspose2d(4096, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv11_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv2): ConvTranspose2d(4096, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv12_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv3): ConvTranspose2d(2048, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
  (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
  (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
)
[2022-07-22 19:28:02,145][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-22 19:29:11,632][feature_train_ori.py][L341][INFO] Step [1/2500000=0.00%] | Epoch 0 | Time 68.955 (68.955) | Lr 0.0001 | AIC Loss 0.07851 (0.07851) | All Losses 0.12355 (0.12355)
[2022-07-22 19:30:20,519][feature_train_ori.py][L341][INFO] Step [2/2500000=0.00%] | Epoch 0 | Time 68.860 (68.860) | Lr 0.0001 | AIC Loss 0.18754 (0.18754) | All Losses 0.51091 (0.51091)
[2022-07-22 19:31:27,416][feature_train_ori.py][L341][INFO] Step [3/2500000=0.00%] | Epoch 0 | Time 66.870 (66.870) | Lr 0.0001 | AIC Loss 0.13009 (0.13009) | All Losses 0.35934 (0.35934)
[2022-07-22 19:32:33,617][feature_train_ori.py][L341][INFO] Step [4/2500000=0.00%] | Epoch 0 | Time 66.173 (66.173) | Lr 0.0001 | AIC Loss 0.13713 (0.13713) | All Losses 0.32892 (0.32892)
[2022-07-22 19:33:39,796][feature_train_ori.py][L341][INFO] Step [5/2500000=0.00%] | Epoch 0 | Time 66.146 (66.146) | Lr 0.0001 | AIC Loss 0.13223 (0.13223) | All Losses 0.39972 (0.39972)
[2022-07-22 19:34:46,704][feature_train_ori.py][L341][INFO] Step [6/2500000=0.00%] | Epoch 0 | Time 66.881 (66.881) | Lr 0.0001 | AIC Loss 0.13083 (0.13083) | All Losses 0.25846 (0.25846)
[2022-07-22 19:35:52,885][feature_train_ori.py][L341][INFO] Step [7/2500000=0.00%] | Epoch 0 | Time 66.154 (66.154) | Lr 0.0001 | AIC Loss 0.10662 (0.10662) | All Losses 0.23090 (0.23090)
[2022-07-22 19:36:59,388][feature_train_ori.py][L341][INFO] Step [8/2500000=0.00%] | Epoch 0 | Time 66.476 (66.476) | Lr 0.0001 | AIC Loss 0.11886 (0.11886) | All Losses 0.26035 (0.26035)
[2022-07-22 19:38:04,893][feature_train_ori.py][L341][INFO] Step [9/2500000=0.00%] | Epoch 0 | Time 65.477 (65.477) | Lr 0.0001 | AIC Loss 0.12492 (0.12492) | All Losses 0.26468 (0.26468)
[2022-07-22 19:39:10,648][feature_train_ori.py][L341][INFO] Step [10/2500000=0.00%] | Epoch 0 | Time 65.728 (65.728) | Lr 0.0001 | AIC Loss 0.11424 (0.11424) | All Losses 0.17672 (0.17672)
[2022-07-22 19:40:18,647][feature_train_ori.py][L341][INFO] Step [11/2500000=0.00%] | Epoch 0 | Time 65.184 (65.184) | Lr 0.0001 | AIC Loss 0.09091 (0.09091) | All Losses 0.16334 (0.16334)
[2022-07-22 19:41:24,233][feature_train_ori.py][L341][INFO] Step [12/2500000=0.00%] | Epoch 0 | Time 65.558 (65.558) | Lr 0.0001 | AIC Loss 0.11191 (0.11191) | All Losses 0.25057 (0.25057)
[2022-07-22 19:42:29,749][feature_train_ori.py][L341][INFO] Step [13/2500000=0.00%] | Epoch 0 | Time 65.489 (65.489) | Lr 0.0001 | AIC Loss 0.11690 (0.11690) | All Losses 0.27235 (0.27235)
[2022-07-22 19:43:35,392][feature_train_ori.py][L341][INFO] Step [14/2500000=0.00%] | Epoch 0 | Time 65.614 (65.614) | Lr 0.0001 | AIC Loss 0.08577 (0.08577) | All Losses 0.15585 (0.15585)
[2022-07-22 19:44:41,589][feature_train_ori.py][L341][INFO] Step [15/2500000=0.00%] | Epoch 0 | Time 66.169 (66.169) | Lr 0.0001 | AIC Loss 0.08880 (0.08880) | All Losses 0.17185 (0.17185)
[2022-07-22 19:45:48,017][feature_train_ori.py][L341][INFO] Step [16/2500000=0.00%] | Epoch 0 | Time 66.400 (66.400) | Lr 0.0001 | AIC Loss 0.09346 (0.09346) | All Losses 0.14240 (0.14240)
[2022-07-22 19:46:53,978][feature_train_ori.py][L341][INFO] Step [17/2500000=0.00%] | Epoch 0 | Time 65.934 (65.934) | Lr 0.0001 | AIC Loss 0.10755 (0.10755) | All Losses 0.23311 (0.23311)
[2022-07-22 19:48:00,174][feature_train_ori.py][L341][INFO] Step [18/2500000=0.00%] | Epoch 0 | Time 66.166 (66.166) | Lr 0.0001 | AIC Loss 0.09802 (0.09802) | All Losses 0.15445 (0.15445)
[2022-07-22 19:49:06,153][feature_train_ori.py][L341][INFO] Step [19/2500000=0.00%] | Epoch 0 | Time 65.950 (65.950) | Lr 0.0001 | AIC Loss 0.08875 (0.08875) | All Losses 0.15203 (0.15203)
[2022-07-22 19:50:11,900][feature_train_ori.py][L341][INFO] Step [20/2500000=0.00%] | Epoch 0 | Time 65.719 (65.719) | Lr 0.0001 | AIC Loss 0.09146 (0.09146) | All Losses 0.16056 (0.16056)
[2022-07-22 19:51:20,526][feature_train_ori.py][L341][INFO] Step [21/2500000=0.00%] | Epoch 0 | Time 65.806 (65.806) | Lr 0.0001 | AIC Loss 0.10134 (0.10134) | All Losses 0.16186 (0.16186)
[2022-07-22 19:52:26,046][feature_train_ori.py][L341][INFO] Step [22/2500000=0.00%] | Epoch 0 | Time 65.492 (65.492) | Lr 0.0001 | AIC Loss 0.09200 (0.09200) | All Losses 0.19103 (0.19103)
[2022-07-22 19:53:31,873][feature_train_ori.py][L341][INFO] Step [23/2500000=0.00%] | Epoch 0 | Time 65.799 (65.799) | Lr 0.0001 | AIC Loss 0.09190 (0.09190) | All Losses 0.15861 (0.15861)
[2022-07-22 19:54:38,052][feature_train_ori.py][L341][INFO] Step [24/2500000=0.00%] | Epoch 0 | Time 66.152 (66.152) | Lr 0.0001 | AIC Loss 0.08949 (0.08949) | All Losses 0.11387 (0.11387)
[2022-07-22 19:55:44,419][feature_train_ori.py][L341][INFO] Step [25/2500000=0.00%] | Epoch 0 | Time 66.340 (66.340) | Lr 0.0001 | AIC Loss 0.09970 (0.09970) | All Losses 0.18904 (0.18904)
[2022-07-22 19:56:49,854][feature_train_ori.py][L341][INFO] Step [26/2500000=0.00%] | Epoch 0 | Time 65.407 (65.407) | Lr 0.0001 | AIC Loss 0.08384 (0.08384) | All Losses 0.13218 (0.13218)
[2022-07-22 19:57:55,632][feature_train_ori.py][L341][INFO] Step [27/2500000=0.00%] | Epoch 0 | Time 65.750 (65.750) | Lr 0.0001 | AIC Loss 0.08144 (0.08144) | All Losses 0.15514 (0.15514)
[2022-07-22 19:59:00,971][feature_train_ori.py][L341][INFO] Step [28/2500000=0.00%] | Epoch 0 | Time 65.312 (65.312) | Lr 0.0001 | AIC Loss 0.08050 (0.08050) | All Losses 0.13220 (0.13220)
[2022-07-22 20:00:06,649][feature_train_ori.py][L341][INFO] Step [29/2500000=0.00%] | Epoch 0 | Time 65.650 (65.650) | Lr 0.0001 | AIC Loss 0.07831 (0.07831) | All Losses 0.15284 (0.15284)
[2022-07-22 20:01:12,550][feature_train_ori.py][L341][INFO] Step [30/2500000=0.00%] | Epoch 0 | Time 65.874 (65.874) | Lr 0.0001 | AIC Loss 0.08296 (0.08296) | All Losses 0.18077 (0.18077)
[2022-07-22 20:02:20,697][feature_train_ori.py][L341][INFO] Step [31/2500000=0.00%] | Epoch 0 | Time 65.340 (65.340) | Lr 0.0001 | AIC Loss 0.08933 (0.08933) | All Losses 0.12771 (0.12771)
[2022-07-22 20:03:26,662][feature_train_ori.py][L341][INFO] Step [32/2500000=0.00%] | Epoch 0 | Time 65.930 (65.930) | Lr 0.0001 | AIC Loss 0.07324 (0.07324) | All Losses 0.12155 (0.12155)
[2022-07-22 20:04:32,908][feature_train_ori.py][L341][INFO] Step [33/2500000=0.00%] | Epoch 0 | Time 66.218 (66.218) | Lr 0.0001 | AIC Loss 0.07200 (0.07200) | All Losses 0.10326 (0.10326)
[2022-07-22 20:05:38,730][feature_train_ori.py][L341][INFO] Step [34/2500000=0.00%] | Epoch 0 | Time 65.795 (65.795) | Lr 0.0001 | AIC Loss 0.08396 (0.08396) | All Losses 0.15840 (0.15840)
[2022-07-22 20:06:45,084][feature_train_ori.py][L341][INFO] Step [35/2500000=0.00%] | Epoch 0 | Time 66.327 (66.327) | Lr 0.0001 | AIC Loss 0.07566 (0.07566) | All Losses 0.12338 (0.12338)
[2022-07-22 20:07:50,946][feature_train_ori.py][L341][INFO] Step [36/2500000=0.00%] | Epoch 0 | Time 65.834 (65.834) | Lr 0.0001 | AIC Loss 0.07601 (0.07601) | All Losses 0.13798 (0.13798)
[2022-07-22 20:08:56,737][feature_train_ori.py][L341][INFO] Step [37/2500000=0.00%] | Epoch 0 | Time 65.763 (65.763) | Lr 0.0001 | AIC Loss 0.07113 (0.07113) | All Losses 0.13403 (0.13403)
[2022-07-22 20:10:02,535][feature_train_ori.py][L341][INFO] Step [38/2500000=0.00%] | Epoch 0 | Time 65.770 (65.770) | Lr 0.0001 | AIC Loss 0.07785 (0.07785) | All Losses 0.14339 (0.14339)
[2022-07-22 20:11:08,216][feature_train_ori.py][L341][INFO] Step [39/2500000=0.00%] | Epoch 0 | Time 65.653 (65.653) | Lr 0.0001 | AIC Loss 0.07106 (0.07106) | All Losses 0.13966 (0.13966)
[2022-07-22 20:12:14,354][feature_train_ori.py][L341][INFO] Step [40/2500000=0.00%] | Epoch 0 | Time 66.111 (66.111) | Lr 0.0001 | AIC Loss 0.08570 (0.08570) | All Losses 0.12995 (0.12995)
[2022-07-22 20:13:23,165][feature_train_ori.py][L341][INFO] Step [41/2500000=0.00%] | Epoch 0 | Time 66.000 (66.000) | Lr 0.0001 | AIC Loss 0.08252 (0.08252) | All Losses 0.12548 (0.12548)
[2022-07-22 20:14:29,253][feature_train_ori.py][L341][INFO] Step [42/2500000=0.00%] | Epoch 0 | Time 66.060 (66.060) | Lr 0.0001 | AIC Loss 0.08307 (0.08307) | All Losses 0.16247 (0.16247)
[2022-07-22 20:15:35,121][feature_train_ori.py][L341][INFO] Step [43/2500000=0.00%] | Epoch 0 | Time 65.840 (65.840) | Lr 0.0001 | AIC Loss 0.07775 (0.07775) | All Losses 0.11544 (0.11544)
[2022-07-22 20:16:41,329][feature_train_ori.py][L341][INFO] Step [44/2500000=0.00%] | Epoch 0 | Time 66.180 (66.180) | Lr 0.0001 | AIC Loss 0.06930 (0.06930) | All Losses 0.09376 (0.09376)
[2022-07-22 20:17:47,712][feature_train_ori.py][L341][INFO] Step [45/2500000=0.00%] | Epoch 0 | Time 66.356 (66.356) | Lr 0.0001 | AIC Loss 0.06724 (0.06724) | All Losses 0.14587 (0.14587)
[2022-07-22 20:18:53,417][feature_train_ori.py][L341][INFO] Step [46/2500000=0.00%] | Epoch 0 | Time 65.676 (65.676) | Lr 0.0001 | AIC Loss 0.07149 (0.07149) | All Losses 0.11074 (0.11074)
[2022-07-22 20:19:59,401][feature_train_ori.py][L341][INFO] Step [47/2500000=0.00%] | Epoch 0 | Time 65.957 (65.957) | Lr 0.0001 | AIC Loss 0.08044 (0.08044) | All Losses 0.10190 (0.10190)
[2022-07-22 20:21:05,637][feature_train_ori.py][L341][INFO] Step [48/2500000=0.00%] | Epoch 0 | Time 66.208 (66.208) | Lr 0.0001 | AIC Loss 0.09072 (0.09072) | All Losses 0.12659 (0.12659)
[2022-07-22 20:22:11,373][feature_train_ori.py][L341][INFO] Step [49/2500000=0.00%] | Epoch 0 | Time 65.709 (65.709) | Lr 0.0001 | AIC Loss 0.08739 (0.08739) | All Losses 0.14536 (0.14536)
[2022-07-22 20:23:17,215][feature_train_ori.py][L341][INFO] Step [50/2500000=0.00%] | Epoch 0 | Time 65.814 (65.814) | Lr 0.0001 | AIC Loss 0.07462 (0.07462) | All Losses 0.12885 (0.12885)
[2022-07-22 20:24:26,097][feature_train_ori.py][L341][INFO] Step [51/2500000=0.00%] | Epoch 0 | Time 66.042 (66.042) | Lr 0.0001 | AIC Loss 0.08564 (0.08564) | All Losses 0.14851 (0.14851)
[2022-07-22 20:25:32,888][feature_train_ori.py][L341][INFO] Step [52/2500000=0.00%] | Epoch 0 | Time 66.756 (66.756) | Lr 0.0001 | AIC Loss 0.06923 (0.06923) | All Losses 0.11923 (0.11923)
[2022-07-22 20:26:38,956][feature_train_ori.py][L341][INFO] Step [53/2500000=0.00%] | Epoch 0 | Time 66.040 (66.040) | Lr 0.0001 | AIC Loss 0.07615 (0.07615) | All Losses 0.10175 (0.10175)
[2022-07-22 20:27:45,014][feature_train_ori.py][L341][INFO] Step [54/2500000=0.00%] | Epoch 0 | Time 66.030 (66.030) | Lr 0.0001 | AIC Loss 0.07954 (0.07954) | All Losses 0.11448 (0.11448)
[2022-07-22 20:28:51,220][feature_train_ori.py][L341][INFO] Step [55/2500000=0.00%] | Epoch 0 | Time 66.178 (66.178) | Lr 0.0001 | AIC Loss 0.06586 (0.06586) | All Losses 0.13277 (0.13277)
[2022-07-22 20:29:57,330][feature_train_ori.py][L341][INFO] Step [56/2500000=0.00%] | Epoch 0 | Time 66.082 (66.082) | Lr 0.0001 | AIC Loss 0.08405 (0.08405) | All Losses 0.11040 (0.11040)
[2022-07-22 20:31:02,969][feature_train_ori.py][L341][INFO] Step [57/2500000=0.00%] | Epoch 0 | Time 65.611 (65.611) | Lr 0.0001 | AIC Loss 0.07459 (0.07459) | All Losses 0.11315 (0.11315)
[2022-07-22 20:32:09,013][feature_train_ori.py][L341][INFO] Step [58/2500000=0.00%] | Epoch 0 | Time 66.016 (66.016) | Lr 0.0001 | AIC Loss 0.07396 (0.07396) | All Losses 0.13814 (0.13814)
[2022-07-22 20:33:14,899][feature_train_ori.py][L341][INFO] Step [59/2500000=0.00%] | Epoch 0 | Time 65.858 (65.858) | Lr 0.0001 | AIC Loss 0.08322 (0.08322) | All Losses 0.11055 (0.11055)
[2022-07-22 20:34:21,312][feature_train_ori.py][L341][INFO] Step [60/2500000=0.00%] | Epoch 0 | Time 66.385 (66.385) | Lr 0.0001 | AIC Loss 0.06234 (0.06234) | All Losses 0.12535 (0.12535)
[2022-07-22 20:35:30,102][feature_train_ori.py][L341][INFO] Step [61/2500000=0.00%] | Epoch 0 | Time 65.960 (65.960) | Lr 0.0001 | AIC Loss 0.07340 (0.07340) | All Losses 0.18049 (0.18049)
[2022-07-22 20:36:35,897][feature_train_ori.py][L341][INFO] Step [62/2500000=0.00%] | Epoch 0 | Time 65.767 (65.767) | Lr 0.0001 | AIC Loss 0.07542 (0.07542) | All Losses 0.12143 (0.12143)
[2022-07-22 20:37:41,362][feature_train_ori.py][L341][INFO] Step [63/2500000=0.00%] | Epoch 0 | Time 65.437 (65.437) | Lr 0.0001 | AIC Loss 0.08552 (0.08552) | All Losses 0.15912 (0.15912)
[2022-07-22 20:38:47,073][feature_train_ori.py][L341][INFO] Step [64/2500000=0.00%] | Epoch 0 | Time 65.684 (65.684) | Lr 0.0001 | AIC Loss 0.08422 (0.08422) | All Losses 0.12109 (0.12109)
[2022-07-22 20:39:52,728][feature_train_ori.py][L341][INFO] Step [65/2500000=0.00%] | Epoch 0 | Time 65.627 (65.627) | Lr 0.0001 | AIC Loss 0.07081 (0.07081) | All Losses 0.11392 (0.11392)
[2022-07-22 20:40:58,346][feature_train_ori.py][L341][INFO] Step [66/2500000=0.00%] | Epoch 0 | Time 65.590 (65.590) | Lr 0.0001 | AIC Loss 0.07768 (0.07768) | All Losses 0.15110 (0.15110)
[2022-07-22 20:42:03,880][feature_train_ori.py][L341][INFO] Step [67/2500000=0.00%] | Epoch 0 | Time 65.506 (65.506) | Lr 0.0001 | AIC Loss 0.08067 (0.08067) | All Losses 0.10348 (0.10348)
[2022-07-22 20:43:09,146][feature_train_ori.py][L341][INFO] Step [68/2500000=0.00%] | Epoch 0 | Time 65.239 (65.239) | Lr 0.0001 | AIC Loss 0.08655 (0.08655) | All Losses 0.12693 (0.12693)
[2022-07-22 20:44:14,890][feature_train_ori.py][L341][INFO] Step [69/2500000=0.00%] | Epoch 0 | Time 65.717 (65.717) | Lr 0.0001 | AIC Loss 0.07694 (0.07694) | All Losses 0.11661 (0.11661)
[2022-07-22 20:45:20,663][feature_train_ori.py][L341][INFO] Step [70/2500000=0.00%] | Epoch 0 | Time 65.745 (65.745) | Lr 0.0001 | AIC Loss 0.06253 (0.06253) | All Losses 0.11511 (0.11511)
[2022-07-22 20:46:29,740][feature_train_ori.py][L341][INFO] Step [71/2500000=0.00%] | Epoch 0 | Time 66.264 (66.264) | Lr 0.0001 | AIC Loss 0.08636 (0.08636) | All Losses 0.12640 (0.12640)
[2022-07-22 20:47:35,583][feature_train_ori.py][L341][INFO] Step [72/2500000=0.00%] | Epoch 0 | Time 65.815 (65.815) | Lr 0.0001 | AIC Loss 0.09281 (0.09281) | All Losses 0.11727 (0.11727)
[2022-07-22 20:48:32,531][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-22 20:48:32,531][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-22 20:48:40,323][feature_train_ori.py][L384][INFO] Concatenation(
  (relu): LeakyReLU(negative_slope=0.01)
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv1): ConvTranspose2d(4096, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv11_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv2): ConvTranspose2d(4096, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv12_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv3): ConvTranspose2d(2048, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
  (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
  (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
)
[2022-07-22 20:48:56,821][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-22 20:48:56,821][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-22 20:49:03,689][feature_train_ori.py][L384][INFO] Concatenation(
  (relu): LeakyReLU(negative_slope=0.01)
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv1): ConvTranspose2d(4096, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv11_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv2): ConvTranspose2d(4096, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv12_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv3): ConvTranspose2d(2048, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
  (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
  (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
)
[2022-07-22 20:49:10,823][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-22 20:50:23,238][feature_train_ori.py][L341][INFO] Step [1/2500000=0.00%] | Epoch 0 | Time 71.919 (71.919) | Lr 0.0001 | AIC Loss 0.39287 (0.39287) | All Losses 0.56028 (0.56028)
[2022-07-22 20:51:34,651][feature_train_ori.py][L341][INFO] Step [2/2500000=0.00%] | Epoch 0 | Time 71.386 (71.386) | Lr 0.0001 | AIC Loss 0.40840 (0.40840) | All Losses 0.57014 (0.57014)
[2022-07-22 20:52:43,432][feature_train_ori.py][L341][INFO] Step [3/2500000=0.00%] | Epoch 0 | Time 68.754 (68.754) | Lr 0.0001 | AIC Loss 0.36587 (0.36587) | All Losses 0.51360 (0.51360)
[2022-07-22 20:53:52,131][feature_train_ori.py][L341][INFO] Step [4/2500000=0.00%] | Epoch 0 | Time 68.671 (68.671) | Lr 0.0001 | AIC Loss 0.36991 (0.36991) | All Losses 0.52348 (0.52348)
[2022-07-22 20:55:00,807][feature_train_ori.py][L341][INFO] Step [5/2500000=0.00%] | Epoch 0 | Time 68.647 (68.647) | Lr 0.0001 | AIC Loss 0.33848 (0.33848) | All Losses 0.47257 (0.47257)
[2022-07-22 20:56:09,435][feature_train_ori.py][L341][INFO] Step [6/2500000=0.00%] | Epoch 0 | Time 68.601 (68.601) | Lr 0.0001 | AIC Loss 0.35810 (0.35810) | All Losses 0.49237 (0.49237)
[2022-07-22 20:57:18,298][feature_train_ori.py][L341][INFO] Step [7/2500000=0.00%] | Epoch 0 | Time 68.835 (68.835) | Lr 0.0001 | AIC Loss 0.31949 (0.31949) | All Losses 0.44227 (0.44227)
[2022-07-22 20:58:27,192][feature_train_ori.py][L341][INFO] Step [8/2500000=0.00%] | Epoch 0 | Time 68.866 (68.866) | Lr 0.0001 | AIC Loss 0.31715 (0.31715) | All Losses 0.44461 (0.44461)
[2022-07-22 20:59:36,198][feature_train_ori.py][L341][INFO] Step [9/2500000=0.00%] | Epoch 0 | Time 68.979 (68.979) | Lr 0.0001 | AIC Loss 0.33241 (0.33241) | All Losses 0.44933 (0.44933)
[2022-07-22 21:00:45,187][feature_train_ori.py][L341][INFO] Step [10/2500000=0.00%] | Epoch 0 | Time 68.961 (68.961) | Lr 0.0001 | AIC Loss 0.32578 (0.32578) | All Losses 0.43033 (0.43033)
[2022-07-22 21:01:55,729][feature_train_ori.py][L341][INFO] Step [11/2500000=0.00%] | Epoch 0 | Time 68.608 (68.608) | Lr 0.0001 | AIC Loss 0.32188 (0.32188) | All Losses 0.41731 (0.41731)
[2022-07-22 21:03:04,271][feature_train_ori.py][L341][INFO] Step [12/2500000=0.00%] | Epoch 0 | Time 68.514 (68.514) | Lr 0.0001 | AIC Loss 0.29321 (0.29321) | All Losses 0.38960 (0.38960)
[2022-07-22 21:04:12,663][feature_train_ori.py][L341][INFO] Step [13/2500000=0.00%] | Epoch 0 | Time 68.365 (68.365) | Lr 0.0001 | AIC Loss 0.30186 (0.30186) | All Losses 0.39256 (0.39256)
[2022-07-22 21:05:21,232][feature_train_ori.py][L341][INFO] Step [14/2500000=0.00%] | Epoch 0 | Time 68.541 (68.541) | Lr 0.0001 | AIC Loss 0.29811 (0.29811) | All Losses 0.38718 (0.38718)
[2022-07-22 21:06:29,664][feature_train_ori.py][L341][INFO] Step [15/2500000=0.00%] | Epoch 0 | Time 68.405 (68.405) | Lr 0.0001 | AIC Loss 0.30510 (0.30510) | All Losses 0.38376 (0.38376)
[2022-07-22 21:07:38,147][feature_train_ori.py][L341][INFO] Step [16/2500000=0.00%] | Epoch 0 | Time 68.455 (68.455) | Lr 0.0001 | AIC Loss 0.26945 (0.26945) | All Losses 0.36219 (0.36219)
[2022-07-22 21:08:46,535][feature_train_ori.py][L341][INFO] Step [17/2500000=0.00%] | Epoch 0 | Time 68.361 (68.361) | Lr 0.0001 | AIC Loss 0.25219 (0.25219) | All Losses 0.32976 (0.32976)
[2022-07-22 21:09:55,017][feature_train_ori.py][L341][INFO] Step [18/2500000=0.00%] | Epoch 0 | Time 68.454 (68.454) | Lr 0.0001 | AIC Loss 0.22819 (0.22819) | All Losses 0.29442 (0.29442)
[2022-07-22 21:11:03,329][feature_train_ori.py][L341][INFO] Step [19/2500000=0.00%] | Epoch 0 | Time 68.285 (68.285) | Lr 0.0001 | AIC Loss 0.25632 (0.25632) | All Losses 0.32448 (0.32448)
[2022-07-22 21:12:11,852][feature_train_ori.py][L341][INFO] Step [20/2500000=0.00%] | Epoch 0 | Time 68.495 (68.495) | Lr 0.0001 | AIC Loss 0.22389 (0.22389) | All Losses 0.27514 (0.27514)
[2022-07-22 21:13:22,609][feature_train_ori.py][L341][INFO] Step [21/2500000=0.00%] | Epoch 0 | Time 68.833 (68.833) | Lr 0.0001 | AIC Loss 0.19711 (0.19711) | All Losses 0.25414 (0.25414)
[2022-07-22 21:14:31,383][feature_train_ori.py][L341][INFO] Step [22/2500000=0.00%] | Epoch 0 | Time 68.747 (68.747) | Lr 0.0001 | AIC Loss 0.20697 (0.20697) | All Losses 0.25982 (0.25982)
[2022-07-22 21:15:40,133][feature_train_ori.py][L341][INFO] Step [23/2500000=0.00%] | Epoch 0 | Time 68.723 (68.723) | Lr 0.0001 | AIC Loss 0.20641 (0.20641) | All Losses 0.26228 (0.26228)
[2022-07-22 21:16:48,589][feature_train_ori.py][L341][INFO] Step [24/2500000=0.00%] | Epoch 0 | Time 68.429 (68.429) | Lr 0.0001 | AIC Loss 0.20181 (0.20181) | All Losses 0.25213 (0.25213)
[2022-07-22 21:17:56,900][feature_train_ori.py][L341][INFO] Step [25/2500000=0.00%] | Epoch 0 | Time 68.283 (68.283) | Lr 0.0001 | AIC Loss 0.19987 (0.19987) | All Losses 0.24488 (0.24488)
[2022-07-22 21:19:05,088][feature_train_ori.py][L341][INFO] Step [26/2500000=0.00%] | Epoch 0 | Time 68.160 (68.160) | Lr 0.0001 | AIC Loss 0.18709 (0.18709) | All Losses 0.22761 (0.22761)
[2022-07-22 21:20:13,382][feature_train_ori.py][L341][INFO] Step [27/2500000=0.00%] | Epoch 0 | Time 68.267 (68.267) | Lr 0.0001 | AIC Loss 0.20437 (0.20437) | All Losses 0.25035 (0.25035)
[2022-07-22 21:21:21,579][feature_train_ori.py][L341][INFO] Step [28/2500000=0.00%] | Epoch 0 | Time 68.169 (68.169) | Lr 0.0001 | AIC Loss 0.16971 (0.16971) | All Losses 0.20940 (0.20940)
[2022-07-22 21:22:29,920][feature_train_ori.py][L341][INFO] Step [29/2500000=0.00%] | Epoch 0 | Time 68.314 (68.314) | Lr 0.0001 | AIC Loss 0.18768 (0.18768) | All Losses 0.22045 (0.22045)
[2022-07-22 21:23:38,060][feature_train_ori.py][L341][INFO] Step [30/2500000=0.00%] | Epoch 0 | Time 68.112 (68.112) | Lr 0.0001 | AIC Loss 0.17456 (0.17456) | All Losses 0.20867 (0.20867)
[2022-07-22 21:24:48,273][feature_train_ori.py][L341][INFO] Step [31/2500000=0.00%] | Epoch 0 | Time 68.313 (68.313) | Lr 0.0001 | AIC Loss 0.19744 (0.19744) | All Losses 0.23745 (0.23745)
[2022-07-22 21:25:56,804][feature_train_ori.py][L341][INFO] Step [32/2500000=0.00%] | Epoch 0 | Time 68.504 (68.504) | Lr 0.0001 | AIC Loss 0.18400 (0.18400) | All Losses 0.20760 (0.20760)
[2022-07-22 21:27:05,829][feature_train_ori.py][L341][INFO] Step [33/2500000=0.00%] | Epoch 0 | Time 68.997 (68.997) | Lr 0.0001 | AIC Loss 0.16180 (0.16180) | All Losses 0.19557 (0.19557)
[2022-07-22 21:28:14,893][feature_train_ori.py][L341][INFO] Step [34/2500000=0.00%] | Epoch 0 | Time 69.037 (69.037) | Lr 0.0001 | AIC Loss 0.15114 (0.15114) | All Losses 0.18433 (0.18433)
[2022-07-22 21:29:23,944][feature_train_ori.py][L341][INFO] Step [35/2500000=0.00%] | Epoch 0 | Time 69.024 (69.024) | Lr 0.0001 | AIC Loss 0.16125 (0.16125) | All Losses 0.19070 (0.19070)
[2022-07-22 21:30:32,583][feature_train_ori.py][L341][INFO] Step [36/2500000=0.00%] | Epoch 0 | Time 68.611 (68.611) | Lr 0.0001 | AIC Loss 0.16680 (0.16680) | All Losses 0.19026 (0.19026)
[2022-07-22 21:31:41,420][feature_train_ori.py][L341][INFO] Step [37/2500000=0.00%] | Epoch 0 | Time 68.809 (68.809) | Lr 0.0001 | AIC Loss 0.16820 (0.16820) | All Losses 0.19515 (0.19515)
[2022-07-22 21:32:50,011][feature_train_ori.py][L341][INFO] Step [38/2500000=0.00%] | Epoch 0 | Time 68.564 (68.564) | Lr 0.0001 | AIC Loss 0.15995 (0.15995) | All Losses 0.19880 (0.19880)
[2022-07-22 21:33:59,045][feature_train_ori.py][L341][INFO] Step [39/2500000=0.00%] | Epoch 0 | Time 69.006 (69.006) | Lr 0.0001 | AIC Loss 0.12944 (0.12944) | All Losses 0.15483 (0.15483)
[2022-07-22 21:35:07,707][feature_train_ori.py][L341][INFO] Step [40/2500000=0.00%] | Epoch 0 | Time 68.634 (68.634) | Lr 0.0001 | AIC Loss 0.16475 (0.16475) | All Losses 0.20876 (0.20876)
[2022-07-22 21:36:18,013][feature_train_ori.py][L341][INFO] Step [41/2500000=0.00%] | Epoch 0 | Time 68.370 (68.370) | Lr 0.0001 | AIC Loss 0.14113 (0.14113) | All Losses 0.17239 (0.17239)
[2022-07-22 21:37:26,765][feature_train_ori.py][L341][INFO] Step [42/2500000=0.00%] | Epoch 0 | Time 68.690 (68.690) | Lr 0.0001 | AIC Loss 0.14080 (0.14080) | All Losses 0.17619 (0.17619)
[2022-07-22 21:38:38,563][feature_train_ori.py][L341][INFO] Step [43/2500000=0.00%] | Epoch 0 | Time 71.729 (71.729) | Lr 0.0001 | AIC Loss 0.16476 (0.16476) | All Losses 0.19681 (0.19681)
[2022-07-22 21:39:50,582][feature_train_ori.py][L341][INFO] Step [44/2500000=0.00%] | Epoch 0 | Time 71.958 (71.958) | Lr 0.0001 | AIC Loss 0.12900 (0.12900) | All Losses 0.15081 (0.15081)
[2022-07-22 21:41:02,278][feature_train_ori.py][L341][INFO] Step [45/2500000=0.00%] | Epoch 0 | Time 71.627 (71.627) | Lr 0.0001 | AIC Loss 0.15153 (0.15153) | All Losses 0.17032 (0.17032)
[2022-07-22 21:42:13,717][feature_train_ori.py][L341][INFO] Step [46/2500000=0.00%] | Epoch 0 | Time 71.377 (71.377) | Lr 0.0001 | AIC Loss 0.16115 (0.16115) | All Losses 0.17967 (0.17967)
[2022-07-22 21:43:24,989][feature_train_ori.py][L341][INFO] Step [47/2500000=0.00%] | Epoch 0 | Time 71.205 (71.205) | Lr 0.0001 | AIC Loss 0.16432 (0.16432) | All Losses 0.19383 (0.19383)
[2022-07-22 21:44:34,221][feature_train_ori.py][L341][INFO] Step [48/2500000=0.00%] | Epoch 0 | Time 69.204 (69.204) | Lr 0.0001 | AIC Loss 0.14525 (0.14525) | All Losses 0.16939 (0.16939)
[2022-07-22 21:45:43,188][feature_train_ori.py][L341][INFO] Step [49/2500000=0.00%] | Epoch 0 | Time 68.939 (68.939) | Lr 0.0001 | AIC Loss 0.14892 (0.14892) | All Losses 0.16994 (0.16994)
[2022-07-22 21:46:52,076][feature_train_ori.py][L341][INFO] Step [50/2500000=0.00%] | Epoch 0 | Time 68.861 (68.861) | Lr 0.0001 | AIC Loss 0.15540 (0.15540) | All Losses 0.17113 (0.17113)
[2022-07-22 21:48:03,204][feature_train_ori.py][L341][INFO] Step [51/2500000=0.00%] | Epoch 0 | Time 69.192 (69.192) | Lr 0.0001 | AIC Loss 0.12695 (0.12695) | All Losses 0.14158 (0.14158)
[2022-07-22 21:49:12,268][feature_train_ori.py][L341][INFO] Step [52/2500000=0.00%] | Epoch 0 | Time 69.037 (69.037) | Lr 0.0001 | AIC Loss 0.13510 (0.13510) | All Losses 0.15300 (0.15300)
[2022-07-22 21:50:16,365][feature_train_ori.py][L341][INFO] Step [53/2500000=0.00%] | Epoch 0 | Time 64.069 (64.069) | Lr 0.0001 | AIC Loss 0.13188 (0.13188) | All Losses 0.15030 (0.15030)
[2022-07-22 21:51:25,305][feature_train_ori.py][L341][INFO] Step [54/2500000=0.00%] | Epoch 0 | Time 68.912 (68.912) | Lr 0.0001 | AIC Loss 0.14892 (0.14892) | All Losses 0.17012 (0.17012)
[2022-07-22 21:52:27,622][feature_train_ori.py][L341][INFO] Step [55/2500000=0.00%] | Epoch 0 | Time 62.250 (62.250) | Lr 0.0001 | AIC Loss 0.12901 (0.12901) | All Losses 0.15603 (0.15603)
[2022-07-22 21:53:32,415][feature_train_ori.py][L341][INFO] Step [56/2500000=0.00%] | Epoch 0 | Time 64.724 (64.724) | Lr 0.0001 | AIC Loss 0.13435 (0.13435) | All Losses 0.15552 (0.15552)
[2022-07-22 21:54:37,025][feature_train_ori.py][L341][INFO] Step [57/2500000=0.00%] | Epoch 0 | Time 64.554 (64.554) | Lr 0.0001 | AIC Loss 0.14283 (0.14283) | All Losses 0.17620 (0.17620)
[2022-07-22 21:55:41,790][feature_train_ori.py][L341][INFO] Step [58/2500000=0.00%] | Epoch 0 | Time 64.708 (64.708) | Lr 0.0001 | AIC Loss 0.15343 (0.15343) | All Losses 0.17874 (0.17874)
[2022-07-22 21:56:46,635][feature_train_ori.py][L341][INFO] Step [59/2500000=0.00%] | Epoch 0 | Time 64.777 (64.777) | Lr 0.0001 | AIC Loss 0.14974 (0.14974) | All Losses 0.17710 (0.17710)
[2022-07-22 21:57:51,555][feature_train_ori.py][L341][INFO] Step [60/2500000=0.00%] | Epoch 0 | Time 64.864 (64.864) | Lr 0.0001 | AIC Loss 0.13103 (0.13103) | All Losses 0.15163 (0.15163)
[2022-07-22 21:58:57,992][feature_train_ori.py][L341][INFO] Step [61/2500000=0.00%] | Epoch 0 | Time 64.498 (64.498) | Lr 0.0001 | AIC Loss 0.14522 (0.14522) | All Losses 0.17205 (0.17205)
[2022-07-22 22:00:00,181][feature_train_ori.py][L341][INFO] Step [62/2500000=0.00%] | Epoch 0 | Time 62.161 (62.161) | Lr 0.0001 | AIC Loss 0.12501 (0.12501) | All Losses 0.14008 (0.14008)
[2022-07-22 22:01:02,582][feature_train_ori.py][L341][INFO] Step [63/2500000=0.00%] | Epoch 0 | Time 62.373 (62.373) | Lr 0.0001 | AIC Loss 0.12688 (0.12688) | All Losses 0.15444 (0.15444)
[2022-07-22 22:02:05,129][feature_train_ori.py][L341][INFO] Step [64/2500000=0.00%] | Epoch 0 | Time 62.519 (62.519) | Lr 0.0001 | AIC Loss 0.14779 (0.14779) | All Losses 0.16760 (0.16760)
[2022-07-22 22:03:07,945][feature_train_ori.py][L341][INFO] Step [65/2500000=0.00%] | Epoch 0 | Time 62.789 (62.789) | Lr 0.0001 | AIC Loss 0.12577 (0.12577) | All Losses 0.14449 (0.14449)
[2022-07-22 22:04:10,509][feature_train_ori.py][L341][INFO] Step [66/2500000=0.00%] | Epoch 0 | Time 62.536 (62.536) | Lr 0.0001 | AIC Loss 0.11709 (0.11709) | All Losses 0.13484 (0.13484)
[2022-07-22 22:05:13,073][feature_train_ori.py][L341][INFO] Step [67/2500000=0.00%] | Epoch 0 | Time 62.536 (62.536) | Lr 0.0001 | AIC Loss 0.12622 (0.12622) | All Losses 0.13239 (0.13239)
[2022-07-22 22:06:15,792][feature_train_ori.py][L341][INFO] Step [68/2500000=0.00%] | Epoch 0 | Time 62.691 (62.691) | Lr 0.0001 | AIC Loss 0.11973 (0.11973) | All Losses 0.13602 (0.13602)
[2022-07-22 22:07:18,420][feature_train_ori.py][L341][INFO] Step [69/2500000=0.00%] | Epoch 0 | Time 62.600 (62.600) | Lr 0.0001 | AIC Loss 0.13361 (0.13361) | All Losses 0.15503 (0.15503)
[2022-07-22 22:08:20,835][feature_train_ori.py][L341][INFO] Step [70/2500000=0.00%] | Epoch 0 | Time 62.387 (62.387) | Lr 0.0001 | AIC Loss 0.14878 (0.14878) | All Losses 0.16056 (0.16056)
[2022-07-22 22:09:24,949][feature_train_ori.py][L341][INFO] Step [71/2500000=0.00%] | Epoch 0 | Time 62.181 (62.181) | Lr 0.0001 | AIC Loss 0.12289 (0.12289) | All Losses 0.13213 (0.13213)
[2022-07-22 22:10:27,216][feature_train_ori.py][L341][INFO] Step [72/2500000=0.00%] | Epoch 0 | Time 62.240 (62.240) | Lr 0.0001 | AIC Loss 0.12889 (0.12889) | All Losses 0.14236 (0.14236)
[2022-07-22 22:11:29,935][feature_train_ori.py][L341][INFO] Step [73/2500000=0.00%] | Epoch 0 | Time 62.691 (62.691) | Lr 0.0001 | AIC Loss 0.11396 (0.11396) | All Losses 0.12673 (0.12673)
[2022-07-22 22:12:32,204][feature_train_ori.py][L341][INFO] Step [74/2500000=0.00%] | Epoch 0 | Time 62.241 (62.241) | Lr 0.0001 | AIC Loss 0.12718 (0.12718) | All Losses 0.14765 (0.14765)
[2022-07-22 22:13:34,429][feature_train_ori.py][L341][INFO] Step [75/2500000=0.00%] | Epoch 0 | Time 62.197 (62.197) | Lr 0.0001 | AIC Loss 0.15437 (0.15437) | All Losses 0.16858 (0.16858)
[2022-07-22 22:14:37,004][feature_train_ori.py][L341][INFO] Step [76/2500000=0.00%] | Epoch 0 | Time 62.547 (62.547) | Lr 0.0001 | AIC Loss 0.13213 (0.13213) | All Losses 0.14837 (0.14837)
[2022-07-22 22:15:39,177][feature_train_ori.py][L341][INFO] Step [77/2500000=0.00%] | Epoch 0 | Time 62.145 (62.145) | Lr 0.0001 | AIC Loss 0.11425 (0.11425) | All Losses 0.13296 (0.13296)
[2022-07-22 22:16:41,391][feature_train_ori.py][L341][INFO] Step [78/2500000=0.00%] | Epoch 0 | Time 62.187 (62.187) | Lr 0.0001 | AIC Loss 0.11171 (0.11171) | All Losses 0.12597 (0.12597)
[2022-07-22 22:17:43,506][feature_train_ori.py][L341][INFO] Step [79/2500000=0.00%] | Epoch 0 | Time 62.088 (62.088) | Lr 0.0001 | AIC Loss 0.11068 (0.11068) | All Losses 0.12493 (0.12493)
[2022-07-22 22:18:46,139][feature_train_ori.py][L341][INFO] Step [80/2500000=0.00%] | Epoch 0 | Time 62.605 (62.605) | Lr 0.0001 | AIC Loss 0.11936 (0.11936) | All Losses 0.13387 (0.13387)
[2022-07-22 22:19:50,332][feature_train_ori.py][L341][INFO] Step [81/2500000=0.00%] | Epoch 0 | Time 62.258 (62.258) | Lr 0.0001 | AIC Loss 0.11129 (0.11129) | All Losses 0.12658 (0.12658)
[2022-07-22 22:20:53,361][feature_train_ori.py][L341][INFO] Step [82/2500000=0.00%] | Epoch 0 | Time 63.001 (63.001) | Lr 0.0001 | AIC Loss 0.10976 (0.10976) | All Losses 0.12357 (0.12357)
[2022-07-22 22:21:56,195][feature_train_ori.py][L341][INFO] Step [83/2500000=0.00%] | Epoch 0 | Time 62.806 (62.806) | Lr 0.0001 | AIC Loss 0.12335 (0.12335) | All Losses 0.14173 (0.14173)
[2022-07-22 22:22:58,391][feature_train_ori.py][L341][INFO] Step [84/2500000=0.00%] | Epoch 0 | Time 62.168 (62.168) | Lr 0.0001 | AIC Loss 0.12074 (0.12074) | All Losses 0.13573 (0.13573)
[2022-07-22 22:24:00,944][feature_train_ori.py][L341][INFO] Step [85/2500000=0.00%] | Epoch 0 | Time 62.525 (62.525) | Lr 0.0001 | AIC Loss 0.11537 (0.11537) | All Losses 0.13183 (0.13183)
[2022-07-22 22:25:03,133][feature_train_ori.py][L341][INFO] Step [86/2500000=0.00%] | Epoch 0 | Time 62.160 (62.160) | Lr 0.0001 | AIC Loss 0.11129 (0.11129) | All Losses 0.12538 (0.12538)
[2022-07-22 22:26:05,443][feature_train_ori.py][L341][INFO] Step [87/2500000=0.00%] | Epoch 0 | Time 62.282 (62.282) | Lr 0.0001 | AIC Loss 0.12292 (0.12292) | All Losses 0.13570 (0.13570)
[2022-07-22 22:27:07,674][feature_train_ori.py][L341][INFO] Step [88/2500000=0.00%] | Epoch 0 | Time 62.204 (62.204) | Lr 0.0001 | AIC Loss 0.10651 (0.10651) | All Losses 0.12532 (0.12532)
[2022-07-22 22:28:10,445][feature_train_ori.py][L341][INFO] Step [89/2500000=0.00%] | Epoch 0 | Time 62.744 (62.744) | Lr 0.0001 | AIC Loss 0.11062 (0.11062) | All Losses 0.12688 (0.12688)
[2022-07-22 22:29:13,093][feature_train_ori.py][L341][INFO] Step [90/2500000=0.00%] | Epoch 0 | Time 62.620 (62.620) | Lr 0.0001 | AIC Loss 0.10056 (0.10056) | All Losses 0.11532 (0.11532)
[2022-07-22 22:30:17,746][feature_train_ori.py][L341][INFO] Step [91/2500000=0.00%] | Epoch 0 | Time 62.718 (62.718) | Lr 0.0001 | AIC Loss 0.09888 (0.09888) | All Losses 0.10892 (0.10892)
[2022-07-22 22:31:20,276][feature_train_ori.py][L341][INFO] Step [92/2500000=0.00%] | Epoch 0 | Time 62.503 (62.503) | Lr 0.0001 | AIC Loss 0.11268 (0.11268) | All Losses 0.12549 (0.12549)
[2022-07-22 22:32:23,215][feature_train_ori.py][L341][INFO] Step [93/2500000=0.00%] | Epoch 0 | Time 62.911 (62.911) | Lr 0.0001 | AIC Loss 0.09773 (0.09773) | All Losses 0.11257 (0.11257)
[2022-07-22 22:33:26,347][feature_train_ori.py][L341][INFO] Step [94/2500000=0.00%] | Epoch 0 | Time 63.104 (63.104) | Lr 0.0001 | AIC Loss 0.10383 (0.10383) | All Losses 0.11796 (0.11796)
[2022-07-22 22:34:29,673][feature_train_ori.py][L341][INFO] Step [95/2500000=0.00%] | Epoch 0 | Time 63.298 (63.298) | Lr 0.0001 | AIC Loss 0.11091 (0.11091) | All Losses 0.12869 (0.12869)
[2022-07-22 22:35:31,727][feature_train_ori.py][L341][INFO] Step [96/2500000=0.00%] | Epoch 0 | Time 62.026 (62.026) | Lr 0.0001 | AIC Loss 0.10736 (0.10736) | All Losses 0.12064 (0.12064)
[2022-07-22 22:36:35,262][feature_train_ori.py][L341][INFO] Step [97/2500000=0.00%] | Epoch 0 | Time 63.506 (63.506) | Lr 0.0001 | AIC Loss 0.10856 (0.10856) | All Losses 0.12337 (0.12337)
[2022-07-22 22:37:44,096][feature_train_ori.py][L341][INFO] Step [98/2500000=0.00%] | Epoch 0 | Time 68.807 (68.807) | Lr 0.0001 | AIC Loss 0.09860 (0.09860) | All Losses 0.10611 (0.10611)
[2022-07-22 22:38:52,509][feature_train_ori.py][L341][INFO] Step [99/2500000=0.00%] | Epoch 0 | Time 68.385 (68.385) | Lr 0.0001 | AIC Loss 0.09553 (0.09553) | All Losses 0.10666 (0.10666)
[2022-07-22 22:39:54,829][feature_train_ori.py][L341][INFO] Step [100/2500000=0.00%] | Epoch 0 | Time 62.292 (62.292) | Lr 0.0001 | AIC Loss 0.10684 (0.10684) | All Losses 0.11436 (0.11436)
[2022-07-22 22:40:58,862][feature_train_ori.py][L341][INFO] Step [101/2500000=0.00%] | Epoch 0 | Time 62.109 (62.109) | Lr 0.0001 | AIC Loss 0.10649 (0.10649) | All Losses 0.11633 (0.11633)
[2022-07-22 22:42:01,138][feature_train_ori.py][L341][INFO] Step [102/2500000=0.00%] | Epoch 0 | Time 62.248 (62.248) | Lr 0.0001 | AIC Loss 0.09727 (0.09727) | All Losses 0.10870 (0.10870)
[2022-07-22 22:43:03,276][feature_train_ori.py][L341][INFO] Step [103/2500000=0.00%] | Epoch 0 | Time 62.110 (62.110) | Lr 0.0001 | AIC Loss 0.10512 (0.10512) | All Losses 0.11743 (0.11743)
[2022-07-22 22:44:05,556][feature_train_ori.py][L341][INFO] Step [104/2500000=0.00%] | Epoch 0 | Time 62.253 (62.253) | Lr 0.0001 | AIC Loss 0.11078 (0.11078) | All Losses 0.12351 (0.12351)
[2022-07-22 22:45:07,831][feature_train_ori.py][L341][INFO] Step [105/2500000=0.00%] | Epoch 0 | Time 62.247 (62.247) | Lr 0.0001 | AIC Loss 0.09796 (0.09796) | All Losses 0.11529 (0.11529)
[2022-07-22 22:46:09,762][feature_train_ori.py][L341][INFO] Step [106/2500000=0.00%] | Epoch 0 | Time 61.902 (61.902) | Lr 0.0001 | AIC Loss 0.11053 (0.11053) | All Losses 0.12423 (0.12423)
[2022-07-22 22:47:12,438][feature_train_ori.py][L341][INFO] Step [107/2500000=0.00%] | Epoch 0 | Time 62.649 (62.649) | Lr 0.0001 | AIC Loss 0.10258 (0.10258) | All Losses 0.11072 (0.11072)
[2022-07-22 22:48:15,226][feature_train_ori.py][L341][INFO] Step [108/2500000=0.00%] | Epoch 0 | Time 62.760 (62.760) | Lr 0.0001 | AIC Loss 0.11033 (0.11033) | All Losses 0.12251 (0.12251)
[2022-07-22 22:49:17,667][feature_train_ori.py][L341][INFO] Step [109/2500000=0.00%] | Epoch 0 | Time 62.413 (62.413) | Lr 0.0001 | AIC Loss 0.10543 (0.10543) | All Losses 0.11683 (0.11683)
[2022-07-22 22:50:20,056][feature_train_ori.py][L341][INFO] Step [110/2500000=0.00%] | Epoch 0 | Time 62.361 (62.361) | Lr 0.0001 | AIC Loss 0.10223 (0.10223) | All Losses 0.11913 (0.11913)
[2022-07-22 22:51:25,293][feature_train_ori.py][L341][INFO] Step [111/2500000=0.00%] | Epoch 0 | Time 63.259 (63.259) | Lr 0.0001 | AIC Loss 0.09719 (0.09719) | All Losses 0.10924 (0.10924)
[2022-07-22 22:52:31,718][feature_train_ori.py][L341][INFO] Step [112/2500000=0.00%] | Epoch 0 | Time 66.397 (66.397) | Lr 0.0001 | AIC Loss 0.10667 (0.10667) | All Losses 0.11050 (0.11050)
[2022-07-22 22:53:40,688][feature_train_ori.py][L341][INFO] Step [113/2500000=0.00%] | Epoch 0 | Time 68.943 (68.943) | Lr 0.0001 | AIC Loss 0.09724 (0.09724) | All Losses 0.10546 (0.10546)
[2022-07-22 22:54:45,933][feature_train_ori.py][L341][INFO] Step [114/2500000=0.00%] | Epoch 0 | Time 65.217 (65.217) | Lr 0.0001 | AIC Loss 0.08666 (0.08666) | All Losses 0.09824 (0.09824)
[2022-07-22 22:55:48,328][feature_train_ori.py][L341][INFO] Step [115/2500000=0.00%] | Epoch 0 | Time 62.367 (62.367) | Lr 0.0001 | AIC Loss 0.09211 (0.09211) | All Losses 0.10409 (0.10409)
[2022-07-22 22:56:50,391][feature_train_ori.py][L341][INFO] Step [116/2500000=0.00%] | Epoch 0 | Time 62.034 (62.034) | Lr 0.0001 | AIC Loss 0.09870 (0.09870) | All Losses 0.10853 (0.10853)
[2022-07-22 22:57:53,207][feature_train_ori.py][L341][INFO] Step [117/2500000=0.00%] | Epoch 0 | Time 62.789 (62.789) | Lr 0.0001 | AIC Loss 0.08887 (0.08887) | All Losses 0.10437 (0.10437)
[2022-07-22 22:58:55,436][feature_train_ori.py][L341][INFO] Step [118/2500000=0.00%] | Epoch 0 | Time 62.201 (62.201) | Lr 0.0001 | AIC Loss 0.10775 (0.10775) | All Losses 0.12233 (0.12233)
[2022-07-22 22:59:58,328][feature_train_ori.py][L341][INFO] Step [119/2500000=0.00%] | Epoch 0 | Time 62.866 (62.866) | Lr 0.0001 | AIC Loss 0.08397 (0.08397) | All Losses 0.09600 (0.09600)
[2022-07-22 23:01:02,357][feature_train_ori.py][L341][INFO] Step [120/2500000=0.00%] | Epoch 0 | Time 64.000 (64.000) | Lr 0.0001 | AIC Loss 0.09100 (0.09100) | All Losses 0.10404 (0.10404)
[2022-07-22 23:02:12,741][feature_train_ori.py][L341][INFO] Step [121/2500000=0.00%] | Epoch 0 | Time 68.469 (68.469) | Lr 0.0001 | AIC Loss 0.08655 (0.08655) | All Losses 0.09698 (0.09698)
[2022-07-22 23:03:15,077][feature_train_ori.py][L341][INFO] Step [122/2500000=0.00%] | Epoch 0 | Time 62.309 (62.309) | Lr 0.0001 | AIC Loss 0.09871 (0.09871) | All Losses 0.11417 (0.11417)
[2022-07-22 23:04:16,895][feature_train_ori.py][L341][INFO] Step [123/2500000=0.00%] | Epoch 0 | Time 61.789 (61.789) | Lr 0.0001 | AIC Loss 0.08738 (0.08738) | All Losses 0.09862 (0.09862)
[2022-07-22 23:05:19,204][feature_train_ori.py][L341][INFO] Step [124/2500000=0.00%] | Epoch 0 | Time 62.281 (62.281) | Lr 0.0001 | AIC Loss 0.09719 (0.09719) | All Losses 0.10486 (0.10486)
[2022-07-22 23:06:21,057][feature_train_ori.py][L341][INFO] Step [125/2500000=0.01%] | Epoch 0 | Time 61.826 (61.826) | Lr 0.0001 | AIC Loss 0.09670 (0.09670) | All Losses 0.10881 (0.10881)
[2022-07-22 23:07:23,265][feature_train_ori.py][L341][INFO] Step [126/2500000=0.01%] | Epoch 0 | Time 62.180 (62.180) | Lr 0.0001 | AIC Loss 0.09576 (0.09576) | All Losses 0.10369 (0.10369)
[2022-07-22 23:08:25,732][feature_train_ori.py][L341][INFO] Step [127/2500000=0.01%] | Epoch 0 | Time 62.440 (62.440) | Lr 0.0001 | AIC Loss 0.08966 (0.08966) | All Losses 0.09468 (0.09468)
[2022-07-22 23:09:34,060][feature_train_ori.py][L341][INFO] Step [128/2500000=0.01%] | Epoch 0 | Time 68.300 (68.300) | Lr 0.0001 | AIC Loss 0.08976 (0.08976) | All Losses 0.10420 (0.10420)
[2022-07-22 23:10:36,840][feature_train_ori.py][L341][INFO] Step [129/2500000=0.01%] | Epoch 0 | Time 62.753 (62.753) | Lr 0.0001 | AIC Loss 0.08766 (0.08766) | All Losses 0.10128 (0.10128)
[2022-07-22 23:11:45,119][feature_train_ori.py][L341][INFO] Step [130/2500000=0.01%] | Epoch 0 | Time 68.252 (68.252) | Lr 0.0001 | AIC Loss 0.09807 (0.09807) | All Losses 0.11323 (0.11323)
[2022-07-22 23:12:49,726][feature_train_ori.py][L341][INFO] Step [131/2500000=0.01%] | Epoch 0 | Time 62.710 (62.710) | Lr 0.0001 | AIC Loss 0.08956 (0.08956) | All Losses 0.10201 (0.10201)
[2022-07-22 23:13:53,978][feature_train_ori.py][L341][INFO] Step [132/2500000=0.01%] | Epoch 0 | Time 64.224 (64.224) | Lr 0.0001 | AIC Loss 0.08598 (0.08598) | All Losses 0.09320 (0.09320)
[2022-07-22 23:15:02,584][feature_train_ori.py][L341][INFO] Step [133/2500000=0.01%] | Epoch 0 | Time 68.578 (68.578) | Lr 0.0001 | AIC Loss 0.08742 (0.08742) | All Losses 0.10129 (0.10129)
[2022-07-22 23:16:04,816][feature_train_ori.py][L341][INFO] Step [134/2500000=0.01%] | Epoch 0 | Time 62.204 (62.204) | Lr 0.0001 | AIC Loss 0.10436 (0.10436) | All Losses 0.11144 (0.11144)
[2022-07-22 23:17:06,706][feature_train_ori.py][L341][INFO] Step [135/2500000=0.01%] | Epoch 0 | Time 61.862 (61.862) | Lr 0.0001 | AIC Loss 0.08750 (0.08750) | All Losses 0.09624 (0.09624)
[2022-07-22 23:18:08,721][feature_train_ori.py][L341][INFO] Step [136/2500000=0.01%] | Epoch 0 | Time 61.988 (61.988) | Lr 0.0001 | AIC Loss 0.08707 (0.08707) | All Losses 0.09751 (0.09751)
[2022-07-22 23:19:10,949][feature_train_ori.py][L341][INFO] Step [137/2500000=0.01%] | Epoch 0 | Time 62.200 (62.200) | Lr 0.0001 | AIC Loss 0.09566 (0.09566) | All Losses 0.10451 (0.10451)
[2022-07-22 23:20:12,771][feature_train_ori.py][L341][INFO] Step [138/2500000=0.01%] | Epoch 0 | Time 61.795 (61.795) | Lr 0.0001 | AIC Loss 0.08748 (0.08748) | All Losses 0.09609 (0.09609)
[2022-07-22 23:21:14,647][feature_train_ori.py][L341][INFO] Step [139/2500000=0.01%] | Epoch 0 | Time 61.849 (61.849) | Lr 0.0001 | AIC Loss 0.08382 (0.08382) | All Losses 0.09537 (0.09537)
[2022-07-22 23:22:16,793][feature_train_ori.py][L341][INFO] Step [140/2500000=0.01%] | Epoch 0 | Time 62.118 (62.118) | Lr 0.0001 | AIC Loss 0.08520 (0.08520) | All Losses 0.09548 (0.09548)
[2022-07-22 23:23:31,526][feature_train_ori.py][L341][INFO] Step [141/2500000=0.01%] | Epoch 0 | Time 65.475 (65.475) | Lr 0.0001 | AIC Loss 0.09392 (0.09392) | All Losses 0.09986 (0.09986)
[2022-07-22 23:24:40,406][feature_train_ori.py][L341][INFO] Step [142/2500000=0.01%] | Epoch 0 | Time 68.853 (68.853) | Lr 0.0001 | AIC Loss 0.07740 (0.07740) | All Losses 0.08490 (0.08490)
[2022-07-22 23:25:42,960][feature_train_ori.py][L341][INFO] Step [143/2500000=0.01%] | Epoch 0 | Time 62.526 (62.526) | Lr 0.0001 | AIC Loss 0.08683 (0.08683) | All Losses 0.09813 (0.09813)
[2022-07-22 23:26:45,613][feature_train_ori.py][L341][INFO] Step [144/2500000=0.01%] | Epoch 0 | Time 62.625 (62.625) | Lr 0.0001 | AIC Loss 0.09474 (0.09474) | All Losses 0.10321 (0.10321)
[2022-07-22 23:27:47,934][feature_train_ori.py][L341][INFO] Step [145/2500000=0.01%] | Epoch 0 | Time 62.293 (62.293) | Lr 0.0001 | AIC Loss 0.08702 (0.08702) | All Losses 0.10460 (0.10460)
[2022-07-22 23:28:50,423][feature_train_ori.py][L341][INFO] Step [146/2500000=0.01%] | Epoch 0 | Time 62.461 (62.461) | Lr 0.0001 | AIC Loss 0.08830 (0.08830) | All Losses 0.09635 (0.09635)
[2022-07-22 23:29:52,726][feature_train_ori.py][L341][INFO] Step [147/2500000=0.01%] | Epoch 0 | Time 62.276 (62.276) | Lr 0.0001 | AIC Loss 0.07947 (0.07947) | All Losses 0.08613 (0.08613)
[2022-07-23 08:17:22,193][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-23 08:17:22,193][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-23 08:17:29,941][feature_train_ori.py][L384][INFO] Concatenation(
  (relu): LeakyReLU(negative_slope=0.01)
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv1): ConvTranspose2d(4096, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv11_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv2): ConvTranspose2d(4096, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv12_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv3): ConvTranspose2d(2048, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
  (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
  (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
)
[2022-07-23 08:17:37,023][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-23 08:18:46,695][feature_train_ori.py][L341][INFO] Step [1/2500000=0.00%] | Epoch 0 | Time 69.139 (69.139) | Lr 0.0001 | AIC Loss 0.08859 (0.08859) | All Losses 0.10257 (0.10257)
[2022-07-23 08:19:55,465][feature_train_ori.py][L341][INFO] Step [2/2500000=0.00%] | Epoch 0 | Time 68.744 (68.744) | Lr 0.0001 | AIC Loss 0.17791 (0.17791) | All Losses 0.21593 (0.21593)
[2022-07-23 08:21:01,660][feature_train_ori.py][L341][INFO] Step [3/2500000=0.00%] | Epoch 0 | Time 66.168 (66.168) | Lr 0.0001 | AIC Loss 0.14419 (0.14419) | All Losses 0.18175 (0.18175)
[2022-07-23 08:22:07,841][feature_train_ori.py][L341][INFO] Step [4/2500000=0.00%] | Epoch 0 | Time 66.153 (66.153) | Lr 0.0001 | AIC Loss 0.16307 (0.16307) | All Losses 0.20076 (0.20076)
[2022-07-23 08:23:16,306][feature_train_ori.py][L341][INFO] Step [5/2500000=0.00%] | Epoch 0 | Time 68.437 (68.437) | Lr 0.0001 | AIC Loss 0.15851 (0.15851) | All Losses 0.17790 (0.17790)
[2022-07-23 08:24:24,975][feature_train_ori.py][L341][INFO] Step [6/2500000=0.00%] | Epoch 0 | Time 68.641 (68.641) | Lr 0.0001 | AIC Loss 0.15161 (0.15161) | All Losses 0.16975 (0.16975)
[2022-07-23 08:25:33,353][feature_train_ori.py][L341][INFO] Step [7/2500000=0.00%] | Epoch 0 | Time 68.350 (68.350) | Lr 0.0001 | AIC Loss 0.13178 (0.13178) | All Losses 0.14805 (0.14805)
[2022-07-23 08:26:39,547][feature_train_ori.py][L341][INFO] Step [8/2500000=0.00%] | Epoch 0 | Time 66.167 (66.167) | Lr 0.0001 | AIC Loss 0.14867 (0.14867) | All Losses 0.16946 (0.16946)
[2022-07-23 08:27:46,765][feature_train_ori.py][L341][INFO] Step [9/2500000=0.00%] | Epoch 0 | Time 67.190 (67.190) | Lr 0.0001 | AIC Loss 0.13792 (0.13792) | All Losses 0.15426 (0.15426)
[2022-07-23 08:28:55,099][feature_train_ori.py][L341][INFO] Step [10/2500000=0.00%] | Epoch 0 | Time 68.307 (68.307) | Lr 0.0001 | AIC Loss 0.10610 (0.10610) | All Losses 0.12343 (0.12343)
[2022-07-23 08:30:06,122][feature_train_ori.py][L341][INFO] Step [11/2500000=0.00%] | Epoch 0 | Time 67.789 (67.789) | Lr 0.0001 | AIC Loss 0.13185 (0.13185) | All Losses 0.14529 (0.14529)
[2022-07-23 08:31:13,878][feature_train_ori.py][L341][INFO] Step [12/2500000=0.00%] | Epoch 0 | Time 67.728 (67.728) | Lr 0.0001 | AIC Loss 0.11367 (0.11367) | All Losses 0.12510 (0.12510)
[2022-07-23 08:32:21,464][feature_train_ori.py][L341][INFO] Step [13/2500000=0.00%] | Epoch 0 | Time 67.558 (67.558) | Lr 0.0001 | AIC Loss 0.10886 (0.10886) | All Losses 0.12675 (0.12675)
[2022-07-23 08:33:29,601][feature_train_ori.py][L341][INFO] Step [14/2500000=0.00%] | Epoch 0 | Time 68.110 (68.110) | Lr 0.0001 | AIC Loss 0.11144 (0.11144) | All Losses 0.12849 (0.12849)
[2022-07-23 08:34:37,027][feature_train_ori.py][L341][INFO] Step [15/2500000=0.00%] | Epoch 0 | Time 67.397 (67.397) | Lr 0.0001 | AIC Loss 0.11237 (0.11237) | All Losses 0.12388 (0.12388)
[2022-07-23 08:35:45,543][feature_train_ori.py][L341][INFO] Step [16/2500000=0.00%] | Epoch 0 | Time 68.488 (68.488) | Lr 0.0001 | AIC Loss 0.09738 (0.09738) | All Losses 0.10976 (0.10976)
[2022-07-23 08:36:53,982][feature_train_ori.py][L341][INFO] Step [17/2500000=0.00%] | Epoch 0 | Time 68.412 (68.412) | Lr 0.0001 | AIC Loss 0.09745 (0.09745) | All Losses 0.10888 (0.10888)
[2022-07-23 08:38:02,138][feature_train_ori.py][L341][INFO] Step [18/2500000=0.00%] | Epoch 0 | Time 68.129 (68.129) | Lr 0.0001 | AIC Loss 0.10234 (0.10234) | All Losses 0.11113 (0.11113)
[2022-07-23 08:39:10,850][feature_train_ori.py][L341][INFO] Step [19/2500000=0.00%] | Epoch 0 | Time 68.684 (68.684) | Lr 0.0001 | AIC Loss 0.10003 (0.10003) | All Losses 0.11025 (0.11025)
[2022-07-23 08:40:18,869][feature_train_ori.py][L341][INFO] Step [20/2500000=0.00%] | Epoch 0 | Time 67.991 (67.991) | Lr 0.0001 | AIC Loss 0.08939 (0.08939) | All Losses 0.09987 (0.09987)
[2022-07-23 08:41:30,249][feature_train_ori.py][L341][INFO] Step [21/2500000=0.00%] | Epoch 0 | Time 68.173 (68.173) | Lr 0.0001 | AIC Loss 0.10257 (0.10257) | All Losses 0.11498 (0.11498)
[2022-07-23 08:42:39,260][feature_train_ori.py][L341][INFO] Step [22/2500000=0.00%] | Epoch 0 | Time 68.983 (68.983) | Lr 0.0001 | AIC Loss 0.09646 (0.09646) | All Losses 0.10613 (0.10613)
[2022-07-23 08:43:47,454][feature_train_ori.py][L341][INFO] Step [23/2500000=0.00%] | Epoch 0 | Time 68.167 (68.167) | Lr 0.0001 | AIC Loss 0.08879 (0.08879) | All Losses 0.09580 (0.09580)
[2022-07-23 08:44:54,461][feature_train_ori.py][L341][INFO] Step [24/2500000=0.00%] | Epoch 0 | Time 66.979 (66.979) | Lr 0.0001 | AIC Loss 0.08796 (0.08796) | All Losses 0.09808 (0.09808)
[2022-07-23 08:46:02,710][feature_train_ori.py][L341][INFO] Step [25/2500000=0.00%] | Epoch 0 | Time 68.221 (68.221) | Lr 0.0001 | AIC Loss 0.08857 (0.08857) | All Losses 0.09646 (0.09646)
[2022-07-23 08:47:11,349][feature_train_ori.py][L341][INFO] Step [26/2500000=0.00%] | Epoch 0 | Time 68.612 (68.612) | Lr 0.0001 | AIC Loss 0.08774 (0.08774) | All Losses 0.09643 (0.09643)
[2022-07-23 08:48:19,574][feature_train_ori.py][L341][INFO] Step [27/2500000=0.00%] | Epoch 0 | Time 68.197 (68.197) | Lr 0.0001 | AIC Loss 0.08159 (0.08159) | All Losses 0.08929 (0.08929)
[2022-07-23 08:49:28,006][feature_train_ori.py][L341][INFO] Step [28/2500000=0.00%] | Epoch 0 | Time 68.405 (68.405) | Lr 0.0001 | AIC Loss 0.08519 (0.08519) | All Losses 0.09283 (0.09283)
[2022-07-23 08:50:36,025][feature_train_ori.py][L341][INFO] Step [29/2500000=0.00%] | Epoch 0 | Time 67.992 (67.992) | Lr 0.0001 | AIC Loss 0.07944 (0.07944) | All Losses 0.08985 (0.08985)
[2022-07-23 08:51:44,360][feature_train_ori.py][L341][INFO] Step [30/2500000=0.00%] | Epoch 0 | Time 68.307 (68.307) | Lr 0.0001 | AIC Loss 0.08170 (0.08170) | All Losses 0.08961 (0.08961)
[2022-07-23 08:52:54,924][feature_train_ori.py][L341][INFO] Step [31/2500000=0.00%] | Epoch 0 | Time 67.418 (67.418) | Lr 0.0001 | AIC Loss 0.08465 (0.08465) | All Losses 0.09291 (0.09291)
[2022-07-23 08:54:02,357][feature_train_ori.py][L341][INFO] Step [32/2500000=0.00%] | Epoch 0 | Time 67.405 (67.405) | Lr 0.0001 | AIC Loss 0.08877 (0.08877) | All Losses 0.10100 (0.10100)
[2022-07-23 08:55:10,075][feature_train_ori.py][L341][INFO] Step [33/2500000=0.00%] | Epoch 0 | Time 67.691 (67.691) | Lr 0.0001 | AIC Loss 0.09964 (0.09964) | All Losses 0.10503 (0.10503)
[2022-07-23 08:56:18,010][feature_train_ori.py][L341][INFO] Step [34/2500000=0.00%] | Epoch 0 | Time 67.908 (67.908) | Lr 0.0001 | AIC Loss 0.08324 (0.08324) | All Losses 0.09239 (0.09239)
[2022-07-23 08:57:25,919][feature_train_ori.py][L341][INFO] Step [35/2500000=0.00%] | Epoch 0 | Time 67.882 (67.882) | Lr 0.0001 | AIC Loss 0.08510 (0.08510) | All Losses 0.09088 (0.09088)
[2022-07-23 08:58:34,182][feature_train_ori.py][L341][INFO] Step [36/2500000=0.00%] | Epoch 0 | Time 68.235 (68.235) | Lr 0.0001 | AIC Loss 0.09793 (0.09793) | All Losses 0.10587 (0.10587)
[2022-07-23 08:59:42,768][feature_train_ori.py][L341][INFO] Step [37/2500000=0.00%] | Epoch 0 | Time 68.558 (68.558) | Lr 0.0001 | AIC Loss 0.07334 (0.07334) | All Losses 0.08390 (0.08390)
[2022-07-23 09:00:51,046][feature_train_ori.py][L341][INFO] Step [38/2500000=0.00%] | Epoch 0 | Time 68.250 (68.250) | Lr 0.0001 | AIC Loss 0.08889 (0.08889) | All Losses 0.09520 (0.09520)
[2022-07-23 09:01:58,941][feature_train_ori.py][L341][INFO] Step [39/2500000=0.00%] | Epoch 0 | Time 67.867 (67.867) | Lr 0.0001 | AIC Loss 0.08957 (0.08957) | All Losses 0.09765 (0.09765)
[2022-07-23 09:03:08,032][feature_train_ori.py][L341][INFO] Step [40/2500000=0.00%] | Epoch 0 | Time 69.064 (69.064) | Lr 0.0001 | AIC Loss 0.08596 (0.08596) | All Losses 0.09313 (0.09313)
[2022-07-23 09:04:20,122][feature_train_ori.py][L341][INFO] Step [41/2500000=0.00%] | Epoch 0 | Time 68.870 (68.870) | Lr 0.0001 | AIC Loss 0.07835 (0.07835) | All Losses 0.08525 (0.08525)
[2022-07-23 09:05:28,587][feature_train_ori.py][L341][INFO] Step [42/2500000=0.00%] | Epoch 0 | Time 68.437 (68.437) | Lr 0.0001 | AIC Loss 0.08036 (0.08036) | All Losses 0.08567 (0.08567)
[2022-07-23 09:06:37,774][feature_train_ori.py][L341][INFO] Step [43/2500000=0.00%] | Epoch 0 | Time 69.157 (69.157) | Lr 0.0001 | AIC Loss 0.07912 (0.07912) | All Losses 0.08800 (0.08800)
[2022-07-23 09:07:46,493][feature_train_ori.py][L341][INFO] Step [44/2500000=0.00%] | Epoch 0 | Time 68.693 (68.693) | Lr 0.0001 | AIC Loss 0.08127 (0.08127) | All Losses 0.09000 (0.09000)
[2022-07-23 09:08:55,245][feature_train_ori.py][L341][INFO] Step [45/2500000=0.00%] | Epoch 0 | Time 68.725 (68.725) | Lr 0.0001 | AIC Loss 0.08586 (0.08586) | All Losses 0.09682 (0.09682)
[2022-07-23 09:10:03,625][feature_train_ori.py][L341][INFO] Step [46/2500000=0.00%] | Epoch 0 | Time 68.353 (68.353) | Lr 0.0001 | AIC Loss 0.08161 (0.08161) | All Losses 0.09115 (0.09115)
[2022-07-23 09:11:11,019][feature_train_ori.py][L341][INFO] Step [47/2500000=0.00%] | Epoch 0 | Time 67.366 (67.366) | Lr 0.0001 | AIC Loss 0.09226 (0.09226) | All Losses 0.09742 (0.09742)
[2022-07-23 09:12:19,365][feature_train_ori.py][L341][INFO] Step [48/2500000=0.00%] | Epoch 0 | Time 68.318 (68.318) | Lr 0.0001 | AIC Loss 0.08807 (0.08807) | All Losses 0.09585 (0.09585)
[2022-07-23 09:13:27,696][feature_train_ori.py][L341][INFO] Step [49/2500000=0.00%] | Epoch 0 | Time 68.303 (68.303) | Lr 0.0001 | AIC Loss 0.08359 (0.08359) | All Losses 0.09001 (0.09001)
[2022-07-23 09:14:35,601][feature_train_ori.py][L341][INFO] Step [50/2500000=0.00%] | Epoch 0 | Time 67.877 (67.877) | Lr 0.0001 | AIC Loss 0.07573 (0.07573) | All Losses 0.08387 (0.08387)
[2022-07-23 09:15:47,023][feature_train_ori.py][L341][INFO] Step [51/2500000=0.00%] | Epoch 0 | Time 68.241 (68.241) | Lr 0.0001 | AIC Loss 0.07455 (0.07455) | All Losses 0.07923 (0.07923)
[2022-07-23 09:16:55,690][feature_train_ori.py][L341][INFO] Step [52/2500000=0.00%] | Epoch 0 | Time 68.640 (68.640) | Lr 0.0001 | AIC Loss 0.08006 (0.08006) | All Losses 0.09027 (0.09027)
[2022-07-23 09:18:04,180][feature_train_ori.py][L341][INFO] Step [53/2500000=0.00%] | Epoch 0 | Time 68.462 (68.462) | Lr 0.0001 | AIC Loss 0.06689 (0.06689) | All Losses 0.07372 (0.07372)
[2022-07-23 09:19:12,496][feature_train_ori.py][L341][INFO] Step [54/2500000=0.00%] | Epoch 0 | Time 68.289 (68.289) | Lr 0.0001 | AIC Loss 0.08251 (0.08251) | All Losses 0.08458 (0.08458)
[2022-07-23 09:20:20,533][feature_train_ori.py][L341][INFO] Step [55/2500000=0.00%] | Epoch 0 | Time 68.009 (68.009) | Lr 0.0001 | AIC Loss 0.07283 (0.07283) | All Losses 0.07649 (0.07649)
[2022-07-23 09:21:28,619][feature_train_ori.py][L341][INFO] Step [56/2500000=0.00%] | Epoch 0 | Time 68.058 (68.058) | Lr 0.0001 | AIC Loss 0.08610 (0.08610) | All Losses 0.08959 (0.08959)
[2022-07-23 09:22:37,455][feature_train_ori.py][L341][INFO] Step [57/2500000=0.00%] | Epoch 0 | Time 68.800 (68.800) | Lr 0.0001 | AIC Loss 0.06480 (0.06480) | All Losses 0.06932 (0.06932)
[2022-07-23 09:23:46,246][feature_train_ori.py][L341][INFO] Step [58/2500000=0.00%] | Epoch 0 | Time 68.763 (68.763) | Lr 0.0001 | AIC Loss 0.08168 (0.08168) | All Losses 0.09515 (0.09515)
[2022-07-23 09:24:54,362][feature_train_ori.py][L341][INFO] Step [59/2500000=0.00%] | Epoch 0 | Time 68.088 (68.088) | Lr 0.0001 | AIC Loss 0.07565 (0.07565) | All Losses 0.08259 (0.08259)
[2022-07-23 09:26:01,896][feature_train_ori.py][L341][INFO] Step [60/2500000=0.00%] | Epoch 0 | Time 67.506 (67.506) | Lr 0.0001 | AIC Loss 0.07210 (0.07210) | All Losses 0.07873 (0.07873)
[2022-07-23 09:27:13,418][feature_train_ori.py][L341][INFO] Step [61/2500000=0.00%] | Epoch 0 | Time 68.378 (68.378) | Lr 0.0001 | AIC Loss 0.07810 (0.07810) | All Losses 0.08597 (0.08597)
[2022-07-23 09:27:46,860][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-23 09:27:46,860][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-23 09:27:53,724][feature_train_ori.py][L384][INFO] Concatenation(
  (relu): LeakyReLU(negative_slope=0.01)
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv1): ConvTranspose2d(4096, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv11_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv2): ConvTranspose2d(4096, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv12_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv3): ConvTranspose2d(2048, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
  (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
  (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
)
[2022-07-23 09:28:00,821][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-23 09:29:13,208][feature_train_ori.py][L341][INFO] Step [1/2500000=0.00%] | Epoch 0 | Time 71.903 (71.903) | Lr 0.0001 | AIC Loss 0.41618 (0.41618) | All Losses 0.42169 (0.42169)
[2022-07-23 09:30:24,912][feature_train_ori.py][L341][INFO] Step [2/2500000=0.00%] | Epoch 0 | Time 71.678 (71.678) | Lr 0.0001 | AIC Loss 0.40635 (0.40635) | All Losses 0.41559 (0.41559)
[2022-07-23 09:31:32,965][feature_train_ori.py][L341][INFO] Step [3/2500000=0.00%] | Epoch 0 | Time 68.026 (68.026) | Lr 0.0001 | AIC Loss 0.36895 (0.36895) | All Losses 0.37319 (0.37319)
[2022-07-23 09:32:35,241][feature_train_ori.py][L341][INFO] Step [4/2500000=0.00%] | Epoch 0 | Time 62.248 (62.248) | Lr 0.0001 | AIC Loss 0.38010 (0.38010) | All Losses 0.38539 (0.38539)
[2022-07-23 09:33:40,307][feature_train_ori.py][L341][INFO] Step [5/2500000=0.00%] | Epoch 0 | Time 65.039 (65.039) | Lr 0.0001 | AIC Loss 0.33816 (0.33816) | All Losses 0.34097 (0.34097)
[2022-07-23 09:34:48,921][feature_train_ori.py][L341][INFO] Step [6/2500000=0.00%] | Epoch 0 | Time 68.587 (68.587) | Lr 0.0001 | AIC Loss 0.37158 (0.37158) | All Losses 0.37466 (0.37466)
[2022-07-23 09:35:58,029][feature_train_ori.py][L341][INFO] Step [7/2500000=0.00%] | Epoch 0 | Time 69.082 (69.082) | Lr 0.0001 | AIC Loss 0.35926 (0.35926) | All Losses 0.36756 (0.36756)
[2022-07-23 09:37:07,469][feature_train_ori.py][L341][INFO] Step [8/2500000=0.00%] | Epoch 0 | Time 69.414 (69.414) | Lr 0.0001 | AIC Loss 0.33904 (0.33904) | All Losses 0.34956 (0.34956)
[2022-07-23 09:38:16,527][feature_train_ori.py][L341][INFO] Step [9/2500000=0.00%] | Epoch 0 | Time 69.031 (69.031) | Lr 0.0001 | AIC Loss 0.32399 (0.32399) | All Losses 0.33595 (0.33595)
[2022-07-23 09:39:25,189][feature_train_ori.py][L341][INFO] Step [10/2500000=0.00%] | Epoch 0 | Time 68.635 (68.635) | Lr 0.0001 | AIC Loss 0.32008 (0.32008) | All Losses 0.33079 (0.33079)
[2022-07-23 09:40:35,863][feature_train_ori.py][L341][INFO] Step [11/2500000=0.00%] | Epoch 0 | Time 68.176 (68.176) | Lr 0.0001 | AIC Loss 0.34121 (0.34121) | All Losses 0.35505 (0.35505)
[2022-07-23 09:41:44,506][feature_train_ori.py][L341][INFO] Step [12/2500000=0.00%] | Epoch 0 | Time 68.615 (68.615) | Lr 0.0001 | AIC Loss 0.33482 (0.33482) | All Losses 0.35009 (0.35009)
[2022-07-23 09:42:53,119][feature_train_ori.py][L341][INFO] Step [13/2500000=0.00%] | Epoch 0 | Time 68.586 (68.586) | Lr 0.0001 | AIC Loss 0.32335 (0.32335) | All Losses 0.34247 (0.34247)
[2022-07-23 09:44:02,051][feature_train_ori.py][L341][INFO] Step [14/2500000=0.00%] | Epoch 0 | Time 68.904 (68.904) | Lr 0.0001 | AIC Loss 0.29017 (0.29017) | All Losses 0.31285 (0.31285)
[2022-07-23 09:45:10,735][feature_train_ori.py][L341][INFO] Step [15/2500000=0.00%] | Epoch 0 | Time 68.657 (68.657) | Lr 0.0001 | AIC Loss 0.30518 (0.30518) | All Losses 0.32755 (0.32755)
[2022-07-23 09:46:19,225][feature_train_ori.py][L341][INFO] Step [16/2500000=0.00%] | Epoch 0 | Time 68.462 (68.462) | Lr 0.0001 | AIC Loss 0.28494 (0.28494) | All Losses 0.30276 (0.30276)
[2022-07-23 09:47:27,520][feature_train_ori.py][L341][INFO] Step [17/2500000=0.00%] | Epoch 0 | Time 68.268 (68.268) | Lr 0.0001 | AIC Loss 0.26545 (0.26545) | All Losses 0.28975 (0.28975)
[2022-07-23 09:48:36,005][feature_train_ori.py][L341][INFO] Step [18/2500000=0.00%] | Epoch 0 | Time 68.457 (68.457) | Lr 0.0001 | AIC Loss 0.26143 (0.26143) | All Losses 0.29416 (0.29416)
[2022-07-23 09:49:44,320][feature_train_ori.py][L341][INFO] Step [19/2500000=0.00%] | Epoch 0 | Time 68.288 (68.288) | Lr 0.0001 | AIC Loss 0.23383 (0.23383) | All Losses 0.26332 (0.26332)
[2022-07-23 09:50:52,980][feature_train_ori.py][L341][INFO] Step [20/2500000=0.00%] | Epoch 0 | Time 68.633 (68.633) | Lr 0.0001 | AIC Loss 0.25805 (0.25805) | All Losses 0.28838 (0.28838)
[2022-07-23 09:52:04,039][feature_train_ori.py][L341][INFO] Step [21/2500000=0.00%] | Epoch 0 | Time 68.561 (68.561) | Lr 0.0001 | AIC Loss 0.24125 (0.24125) | All Losses 0.27674 (0.27674)
[2022-07-23 09:53:12,939][feature_train_ori.py][L341][INFO] Step [22/2500000=0.00%] | Epoch 0 | Time 68.873 (68.873) | Lr 0.0001 | AIC Loss 0.26277 (0.26277) | All Losses 0.30751 (0.30751)
[2022-07-23 09:54:21,841][feature_train_ori.py][L341][INFO] Step [23/2500000=0.00%] | Epoch 0 | Time 68.874 (68.874) | Lr 0.0001 | AIC Loss 0.25130 (0.25130) | All Losses 0.30287 (0.30287)
[2022-07-23 09:55:30,653][feature_train_ori.py][L341][INFO] Step [24/2500000=0.00%] | Epoch 0 | Time 68.785 (68.785) | Lr 0.0001 | AIC Loss 0.23487 (0.23487) | All Losses 0.28412 (0.28412)
[2022-07-23 09:56:39,501][feature_train_ori.py][L341][INFO] Step [25/2500000=0.00%] | Epoch 0 | Time 68.820 (68.820) | Lr 0.0001 | AIC Loss 0.23976 (0.23976) | All Losses 0.30238 (0.30238)
[2022-07-23 09:57:48,217][feature_train_ori.py][L341][INFO] Step [26/2500000=0.00%] | Epoch 0 | Time 68.688 (68.688) | Lr 0.0001 | AIC Loss 0.24265 (0.24265) | All Losses 0.29540 (0.29540)
[2022-07-23 09:58:57,092][feature_train_ori.py][L341][INFO] Step [27/2500000=0.00%] | Epoch 0 | Time 68.848 (68.848) | Lr 0.0001 | AIC Loss 0.21748 (0.21748) | All Losses 0.27220 (0.27220)
[2022-07-23 10:00:05,761][feature_train_ori.py][L341][INFO] Step [28/2500000=0.00%] | Epoch 0 | Time 68.641 (68.641) | Lr 0.0001 | AIC Loss 0.24762 (0.24762) | All Losses 0.30781 (0.30781)
[2022-07-23 10:01:14,700][feature_train_ori.py][L341][INFO] Step [29/2500000=0.00%] | Epoch 0 | Time 68.910 (68.910) | Lr 0.0001 | AIC Loss 0.23496 (0.23496) | All Losses 0.29336 (0.29336)
[2022-07-23 10:02:23,230][feature_train_ori.py][L341][INFO] Step [30/2500000=0.00%] | Epoch 0 | Time 68.502 (68.502) | Lr 0.0001 | AIC Loss 0.21460 (0.21460) | All Losses 0.27353 (0.27353)
[2022-07-23 10:03:42,172][feature_train_ori.py][L341][INFO] Step [31/2500000=0.00%] | Epoch 0 | Time 69.078 (69.078) | Lr 0.0001 | AIC Loss 0.21796 (0.21796) | All Losses 0.27408 (0.27408)
[2022-07-23 10:04:50,862][feature_train_ori.py][L341][INFO] Step [32/2500000=0.00%] | Epoch 0 | Time 68.663 (68.663) | Lr 0.0001 | AIC Loss 0.20570 (0.20570) | All Losses 0.27471 (0.27471)
[2022-07-23 10:05:59,936][feature_train_ori.py][L341][INFO] Step [33/2500000=0.00%] | Epoch 0 | Time 69.043 (69.043) | Lr 0.0001 | AIC Loss 0.19957 (0.19957) | All Losses 0.26278 (0.26278)
[2022-07-23 10:07:08,771][feature_train_ori.py][L341][INFO] Step [34/2500000=0.00%] | Epoch 0 | Time 68.807 (68.807) | Lr 0.0001 | AIC Loss 0.23145 (0.23145) | All Losses 0.29769 (0.29769)
[2022-07-23 10:08:17,215][feature_train_ori.py][L341][INFO] Step [35/2500000=0.00%] | Epoch 0 | Time 68.417 (68.417) | Lr 0.0001 | AIC Loss 0.20879 (0.20879) | All Losses 0.25804 (0.25804)
[2022-07-23 10:09:26,021][feature_train_ori.py][L341][INFO] Step [36/2500000=0.00%] | Epoch 0 | Time 68.778 (68.778) | Lr 0.0001 | AIC Loss 0.18403 (0.18403) | All Losses 0.25330 (0.25330)
[2022-07-23 10:10:35,384][feature_train_ori.py][L341][INFO] Step [37/2500000=0.00%] | Epoch 0 | Time 69.335 (69.335) | Lr 0.0001 | AIC Loss 0.19001 (0.19001) | All Losses 0.25979 (0.25979)
[2022-07-23 10:11:44,270][feature_train_ori.py][L341][INFO] Step [38/2500000=0.00%] | Epoch 0 | Time 68.859 (68.859) | Lr 0.0001 | AIC Loss 0.21729 (0.21729) | All Losses 0.28613 (0.28613)
[2022-07-23 10:12:53,032][feature_train_ori.py][L341][INFO] Step [39/2500000=0.00%] | Epoch 0 | Time 68.733 (68.733) | Lr 0.0001 | AIC Loss 0.19378 (0.19378) | All Losses 0.27375 (0.27375)
[2022-07-23 10:14:01,895][feature_train_ori.py][L341][INFO] Step [40/2500000=0.00%] | Epoch 0 | Time 68.836 (68.836) | Lr 0.0001 | AIC Loss 0.20274 (0.20274) | All Losses 0.25521 (0.25521)
[2022-07-23 10:15:20,609][feature_train_ori.py][L341][INFO] Step [41/2500000=0.00%] | Epoch 0 | Time 68.740 (68.740) | Lr 0.0001 | AIC Loss 0.19714 (0.19714) | All Losses 0.25395 (0.25395)
[2022-07-23 10:16:29,673][feature_train_ori.py][L341][INFO] Step [42/2500000=0.00%] | Epoch 0 | Time 69.037 (69.037) | Lr 0.0001 | AIC Loss 0.18178 (0.18178) | All Losses 0.25236 (0.25236)
[2022-07-23 10:17:38,455][feature_train_ori.py][L341][INFO] Step [43/2500000=0.00%] | Epoch 0 | Time 68.755 (68.755) | Lr 0.0001 | AIC Loss 0.16790 (0.16790) | All Losses 0.23923 (0.23923)
[2022-07-23 10:18:47,447][feature_train_ori.py][L341][INFO] Step [44/2500000=0.00%] | Epoch 0 | Time 68.964 (68.964) | Lr 0.0001 | AIC Loss 0.18902 (0.18902) | All Losses 0.25874 (0.25874)
[2022-07-23 10:19:56,210][feature_train_ori.py][L341][INFO] Step [45/2500000=0.00%] | Epoch 0 | Time 68.735 (68.735) | Lr 0.0001 | AIC Loss 0.18916 (0.18916) | All Losses 0.26230 (0.26230)
[2022-07-23 10:21:05,087][feature_train_ori.py][L341][INFO] Step [46/2500000=0.00%] | Epoch 0 | Time 68.850 (68.850) | Lr 0.0001 | AIC Loss 0.18709 (0.18709) | All Losses 0.24460 (0.24460)
[2022-07-23 10:22:14,001][feature_train_ori.py][L341][INFO] Step [47/2500000=0.00%] | Epoch 0 | Time 68.886 (68.886) | Lr 0.0001 | AIC Loss 0.19849 (0.19849) | All Losses 0.28099 (0.28099)
[2022-07-23 10:23:22,708][feature_train_ori.py][L341][INFO] Step [48/2500000=0.00%] | Epoch 0 | Time 68.679 (68.679) | Lr 0.0001 | AIC Loss 0.18939 (0.18939) | All Losses 0.27177 (0.27177)
[2022-07-23 10:24:31,885][feature_train_ori.py][L341][INFO] Step [49/2500000=0.00%] | Epoch 0 | Time 69.150 (69.150) | Lr 0.0001 | AIC Loss 0.18702 (0.18702) | All Losses 0.26743 (0.26743)
[2022-07-23 10:25:40,674][feature_train_ori.py][L341][INFO] Step [50/2500000=0.00%] | Epoch 0 | Time 68.761 (68.761) | Lr 0.0001 | AIC Loss 0.15759 (0.15759) | All Losses 0.22648 (0.22648)
[2022-07-23 10:26:52,350][feature_train_ori.py][L341][INFO] Step [51/2500000=0.00%] | Epoch 0 | Time 69.184 (69.184) | Lr 0.0001 | AIC Loss 0.16819 (0.16819) | All Losses 0.25563 (0.25563)
[2022-07-23 10:28:01,082][feature_train_ori.py][L341][INFO] Step [52/2500000=0.00%] | Epoch 0 | Time 68.704 (68.704) | Lr 0.0001 | AIC Loss 0.18331 (0.18331) | All Losses 0.24668 (0.24668)
[2022-07-23 10:29:10,059][feature_train_ori.py][L341][INFO] Step [53/2500000=0.00%] | Epoch 0 | Time 68.950 (68.950) | Lr 0.0001 | AIC Loss 0.18723 (0.18723) | All Losses 0.26184 (0.26184)
[2022-07-23 10:30:19,004][feature_train_ori.py][L341][INFO] Step [54/2500000=0.00%] | Epoch 0 | Time 68.918 (68.918) | Lr 0.0001 | AIC Loss 0.16247 (0.16247) | All Losses 0.22845 (0.22845)
[2022-07-23 10:31:27,784][feature_train_ori.py][L341][INFO] Step [55/2500000=0.00%] | Epoch 0 | Time 68.753 (68.753) | Lr 0.0001 | AIC Loss 0.13610 (0.13610) | All Losses 0.20895 (0.20895)
[2022-07-23 10:32:36,764][feature_train_ori.py][L341][INFO] Step [56/2500000=0.00%] | Epoch 0 | Time 68.952 (68.952) | Lr 0.0001 | AIC Loss 0.16844 (0.16844) | All Losses 0.24034 (0.24034)
[2022-07-23 10:33:45,722][feature_train_ori.py][L341][INFO] Step [57/2500000=0.00%] | Epoch 0 | Time 68.930 (68.930) | Lr 0.0001 | AIC Loss 0.16947 (0.16947) | All Losses 0.23857 (0.23857)
[2022-07-23 10:34:54,863][feature_train_ori.py][L341][INFO] Step [58/2500000=0.00%] | Epoch 0 | Time 69.113 (69.113) | Lr 0.0001 | AIC Loss 0.16761 (0.16761) | All Losses 0.24522 (0.24522)
[2022-07-23 10:36:03,795][feature_train_ori.py][L341][INFO] Step [59/2500000=0.00%] | Epoch 0 | Time 68.904 (68.904) | Lr 0.0001 | AIC Loss 0.16754 (0.16754) | All Losses 0.24766 (0.24766)
[2022-07-23 10:37:12,922][feature_train_ori.py][L341][INFO] Step [60/2500000=0.00%] | Epoch 0 | Time 69.099 (69.099) | Lr 0.0001 | AIC Loss 0.18234 (0.18234) | All Losses 0.26109 (0.26109)
[2022-07-23 10:38:24,125][feature_train_ori.py][L341][INFO] Step [61/2500000=0.00%] | Epoch 0 | Time 68.705 (68.705) | Lr 0.0001 | AIC Loss 0.16974 (0.16974) | All Losses 0.26036 (0.26036)
[2022-07-23 10:39:33,125][feature_train_ori.py][L341][INFO] Step [62/2500000=0.00%] | Epoch 0 | Time 68.972 (68.972) | Lr 0.0001 | AIC Loss 0.15137 (0.15137) | All Losses 0.22375 (0.22375)
[2022-07-23 10:44:58,356][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-23 10:44:58,356][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-23 10:45:12,179][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-23 10:45:12,179][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-23 10:45:19,062][feature_train_ori.py][L384][INFO] Concatenation(
  (relu): LeakyReLU(negative_slope=0.01)
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv1): ConvTranspose2d(4096, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv11_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv2): ConvTranspose2d(4096, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv12_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv3): ConvTranspose2d(2048, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
  (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
  (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
)
[2022-07-23 10:45:26,137][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-23 10:46:38,703][feature_train_ori.py][L341][INFO] Step [1/2500000=0.00%] | Epoch 0 | Time 72.086 (72.086) | Lr 0.0001 | AIC Loss 0.22549 (0.22549) | All Losses 0.29704 (0.29704)
[2022-07-23 10:47:50,716][feature_train_ori.py][L341][INFO] Step [2/2500000=0.00%] | Epoch 0 | Time 71.985 (71.985) | Lr 0.0001 | AIC Loss 0.27612 (0.27612) | All Losses 0.34801 (0.34801)
[2022-07-23 10:48:53,726][feature_train_ori.py][L341][INFO] Step [3/2500000=0.00%] | Epoch 0 | Time 62.982 (62.982) | Lr 0.0001 | AIC Loss 0.21837 (0.21837) | All Losses 0.27339 (0.27339)
[2022-07-23 10:49:55,051][feature_train_ori.py][L341][INFO] Step [4/2500000=0.00%] | Epoch 0 | Time 61.297 (61.297) | Lr 0.0001 | AIC Loss 0.18265 (0.18265) | All Losses 0.22732 (0.22732)
[2022-07-23 10:50:56,525][feature_train_ori.py][L341][INFO] Step [5/2500000=0.00%] | Epoch 0 | Time 61.445 (61.445) | Lr 0.0001 | AIC Loss 0.16093 (0.16093) | All Losses 0.19334 (0.19334)
[2022-07-23 10:51:57,726][feature_train_ori.py][L341][INFO] Step [6/2500000=0.00%] | Epoch 0 | Time 61.172 (61.172) | Lr 0.0001 | AIC Loss 0.16572 (0.16572) | All Losses 0.20092 (0.20092)
[2022-07-23 10:52:59,168][feature_train_ori.py][L341][INFO] Step [7/2500000=0.00%] | Epoch 0 | Time 61.413 (61.413) | Lr 0.0001 | AIC Loss 0.13689 (0.13689) | All Losses 0.17085 (0.17085)
[2022-07-23 10:54:10,279][feature_train_ori.py][L341][INFO] Step [8/2500000=0.00%] | Epoch 0 | Time 71.082 (71.082) | Lr 0.0001 | AIC Loss 0.17601 (0.17601) | All Losses 0.20289 (0.20289)
[2022-07-23 10:55:21,826][feature_train_ori.py][L341][INFO] Step [9/2500000=0.00%] | Epoch 0 | Time 71.518 (71.518) | Lr 0.0001 | AIC Loss 0.13939 (0.13939) | All Losses 0.16771 (0.16771)
[2022-07-23 10:56:33,198][feature_train_ori.py][L341][INFO] Step [10/2500000=0.00%] | Epoch 0 | Time 71.344 (71.344) | Lr 0.0001 | AIC Loss 0.14661 (0.14661) | All Losses 0.16955 (0.16955)
[2022-07-23 10:57:47,966][feature_train_ori.py][L341][INFO] Step [11/2500000=0.00%] | Epoch 0 | Time 71.528 (71.528) | Lr 0.0001 | AIC Loss 0.14053 (0.14053) | All Losses 0.17239 (0.17239)
[2022-07-23 10:58:59,114][feature_train_ori.py][L341][INFO] Step [12/2500000=0.00%] | Epoch 0 | Time 71.119 (71.119) | Lr 0.0001 | AIC Loss 0.14764 (0.14764) | All Losses 0.17051 (0.17051)
[2022-07-23 11:00:10,642][feature_train_ori.py][L341][INFO] Step [13/2500000=0.00%] | Epoch 0 | Time 71.499 (71.499) | Lr 0.0001 | AIC Loss 0.13024 (0.13024) | All Losses 0.14782 (0.14782)
[2022-07-23 11:01:22,398][feature_train_ori.py][L341][INFO] Step [14/2500000=0.00%] | Epoch 0 | Time 71.727 (71.727) | Lr 0.0001 | AIC Loss 0.11989 (0.11989) | All Losses 0.13832 (0.13832)
[2022-07-23 11:02:33,564][feature_train_ori.py][L341][INFO] Step [15/2500000=0.00%] | Epoch 0 | Time 71.136 (71.136) | Lr 0.0001 | AIC Loss 0.14563 (0.14563) | All Losses 0.17397 (0.17397)
[2022-07-23 11:03:44,931][feature_train_ori.py][L341][INFO] Step [16/2500000=0.00%] | Epoch 0 | Time 71.338 (71.338) | Lr 0.0001 | AIC Loss 0.12515 (0.12515) | All Losses 0.15268 (0.15268)
[2022-07-23 11:04:56,028][feature_train_ori.py][L341][INFO] Step [17/2500000=0.00%] | Epoch 0 | Time 71.067 (71.067) | Lr 0.0001 | AIC Loss 0.12312 (0.12312) | All Losses 0.13507 (0.13507)
[2022-07-23 11:06:07,350][feature_train_ori.py][L341][INFO] Step [18/2500000=0.00%] | Epoch 0 | Time 71.293 (71.293) | Lr 0.0001 | AIC Loss 0.11751 (0.11751) | All Losses 0.13406 (0.13406)
[2022-07-23 11:07:18,736][feature_train_ori.py][L341][INFO] Step [19/2500000=0.00%] | Epoch 0 | Time 71.358 (71.358) | Lr 0.0001 | AIC Loss 0.11266 (0.11266) | All Losses 0.12484 (0.12484)
[2022-07-23 11:08:30,017][feature_train_ori.py][L341][INFO] Step [20/2500000=0.00%] | Epoch 0 | Time 71.253 (71.253) | Lr 0.0001 | AIC Loss 0.10166 (0.10166) | All Losses 0.12064 (0.12064)
[2022-07-23 11:09:44,588][feature_train_ori.py][L341][INFO] Step [21/2500000=0.00%] | Epoch 0 | Time 71.329 (71.329) | Lr 0.0001 | AIC Loss 0.10474 (0.10474) | All Losses 0.12574 (0.12574)
[2022-07-23 11:10:55,824][feature_train_ori.py][L341][INFO] Step [22/2500000=0.00%] | Epoch 0 | Time 71.208 (71.208) | Lr 0.0001 | AIC Loss 0.10406 (0.10406) | All Losses 0.12248 (0.12248)
[2022-07-23 11:12:07,036][feature_train_ori.py][L341][INFO] Step [23/2500000=0.00%] | Epoch 0 | Time 71.184 (71.184) | Lr 0.0001 | AIC Loss 0.10763 (0.10763) | All Losses 0.12228 (0.12228)
[2022-07-23 11:13:18,268][feature_train_ori.py][L341][INFO] Step [24/2500000=0.00%] | Epoch 0 | Time 71.203 (71.203) | Lr 0.0001 | AIC Loss 0.11884 (0.11884) | All Losses 0.14061 (0.14061)
[2022-07-23 11:14:29,815][feature_train_ori.py][L341][INFO] Step [25/2500000=0.00%] | Epoch 0 | Time 71.519 (71.519) | Lr 0.0001 | AIC Loss 0.10135 (0.10135) | All Losses 0.10890 (0.10890)
[2022-07-23 11:15:41,218][feature_train_ori.py][L341][INFO] Step [26/2500000=0.00%] | Epoch 0 | Time 71.375 (71.375) | Lr 0.0001 | AIC Loss 0.09452 (0.09452) | All Losses 0.10856 (0.10856)
[2022-07-23 11:16:52,593][feature_train_ori.py][L341][INFO] Step [27/2500000=0.00%] | Epoch 0 | Time 71.346 (71.346) | Lr 0.0001 | AIC Loss 0.10502 (0.10502) | All Losses 0.11395 (0.11395)
[2022-07-23 11:18:03,886][feature_train_ori.py][L341][INFO] Step [28/2500000=0.00%] | Epoch 0 | Time 71.264 (71.264) | Lr 0.0001 | AIC Loss 0.09789 (0.09789) | All Losses 0.11744 (0.11744)
[2022-07-23 11:19:15,323][feature_train_ori.py][L341][INFO] Step [29/2500000=0.00%] | Epoch 0 | Time 71.408 (71.408) | Lr 0.0001 | AIC Loss 0.09612 (0.09612) | All Losses 0.11866 (0.11866)
[2022-07-23 11:20:27,148][feature_train_ori.py][L341][INFO] Step [30/2500000=0.00%] | Epoch 0 | Time 71.796 (71.796) | Lr 0.0001 | AIC Loss 0.08574 (0.08574) | All Losses 0.09764 (0.09764)
[2022-07-23 11:21:41,877][feature_train_ori.py][L341][INFO] Step [31/2500000=0.00%] | Epoch 0 | Time 71.512 (71.512) | Lr 0.0001 | AIC Loss 0.08660 (0.08660) | All Losses 0.09560 (0.09560)
[2022-07-23 11:22:53,389][feature_train_ori.py][L341][INFO] Step [32/2500000=0.00%] | Epoch 0 | Time 71.483 (71.483) | Lr 0.0001 | AIC Loss 0.09675 (0.09675) | All Losses 0.10543 (0.10543)
[2022-07-23 11:24:04,657][feature_train_ori.py][L341][INFO] Step [33/2500000=0.00%] | Epoch 0 | Time 71.239 (71.239) | Lr 0.0001 | AIC Loss 0.08298 (0.08298) | All Losses 0.09668 (0.09668)
[2022-07-23 11:25:16,123][feature_train_ori.py][L341][INFO] Step [34/2500000=0.00%] | Epoch 0 | Time 71.437 (71.437) | Lr 0.0001 | AIC Loss 0.09241 (0.09241) | All Losses 0.09599 (0.09599)
[2022-07-23 11:26:27,502][feature_train_ori.py][L341][INFO] Step [35/2500000=0.00%] | Epoch 0 | Time 71.351 (71.351) | Lr 0.0001 | AIC Loss 0.08835 (0.08835) | All Losses 0.10176 (0.10176)
[2022-07-23 11:27:38,933][feature_train_ori.py][L341][INFO] Step [36/2500000=0.00%] | Epoch 0 | Time 71.402 (71.402) | Lr 0.0001 | AIC Loss 0.08041 (0.08041) | All Losses 0.09720 (0.09720)
[2022-07-23 11:28:49,942][feature_train_ori.py][L341][INFO] Step [37/2500000=0.00%] | Epoch 0 | Time 70.981 (70.981) | Lr 0.0001 | AIC Loss 0.08449 (0.08449) | All Losses 0.09703 (0.09703)
[2022-07-23 11:30:01,229][feature_train_ori.py][L341][INFO] Step [38/2500000=0.00%] | Epoch 0 | Time 71.258 (71.258) | Lr 0.0001 | AIC Loss 0.10117 (0.10117) | All Losses 0.11088 (0.11088)
[2022-07-23 11:31:12,601][feature_train_ori.py][L341][INFO] Step [39/2500000=0.00%] | Epoch 0 | Time 71.344 (71.344) | Lr 0.0001 | AIC Loss 0.10311 (0.10311) | All Losses 0.11551 (0.11551)
[2022-07-23 11:32:23,690][feature_train_ori.py][L341][INFO] Step [40/2500000=0.00%] | Epoch 0 | Time 71.060 (71.060) | Lr 0.0001 | AIC Loss 0.09318 (0.09318) | All Losses 0.10317 (0.10317)
[2022-07-23 11:33:48,250][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-23 11:33:48,250][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-23 11:33:56,021][feature_train_ori.py][L384][INFO] Concatenation(
  (relu): LeakyReLU(negative_slope=0.01)
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv1): ConvTranspose2d(4096, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv11_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv2): ConvTranspose2d(4096, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv12_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv3): ConvTranspose2d(2048, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
  (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
  (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
)
[2022-07-23 11:34:03,098][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-23 11:35:13,381][feature_train_ori.py][L341][INFO] Step [1/2500000=0.00%] | Epoch 0 | Time 69.735 (69.735) | Lr 0.0001 | AIC Loss 0.09074 (0.09074) | All Losses 0.10793 (0.10793)
[2022-07-23 11:36:22,095][feature_train_ori.py][L341][INFO] Step [2/2500000=0.00%] | Epoch 0 | Time 68.687 (68.687) | Lr 0.0001 | AIC Loss 0.10707 (0.10707) | All Losses 0.11825 (0.11825)
[2022-07-23 11:37:27,719][feature_train_ori.py][L341][INFO] Step [3/2500000=0.00%] | Epoch 0 | Time 65.595 (65.595) | Lr 0.0001 | AIC Loss 0.09762 (0.09762) | All Losses 0.10662 (0.10662)
[2022-07-23 11:38:33,303][feature_train_ori.py][L341][INFO] Step [4/2500000=0.00%] | Epoch 0 | Time 65.556 (65.556) | Lr 0.0001 | AIC Loss 0.09028 (0.09028) | All Losses 0.10974 (0.10974)
[2022-07-23 11:39:39,011][feature_train_ori.py][L341][INFO] Step [5/2500000=0.00%] | Epoch 0 | Time 65.680 (65.680) | Lr 0.0001 | AIC Loss 0.10280 (0.10280) | All Losses 0.11360 (0.11360)
[2022-07-23 11:40:44,799][feature_train_ori.py][L341][INFO] Step [6/2500000=0.00%] | Epoch 0 | Time 65.759 (65.759) | Lr 0.0001 | AIC Loss 0.09209 (0.09209) | All Losses 0.10630 (0.10630)
[2022-07-23 11:41:50,739][feature_train_ori.py][L341][INFO] Step [7/2500000=0.00%] | Epoch 0 | Time 65.911 (65.911) | Lr 0.0001 | AIC Loss 0.09896 (0.09896) | All Losses 0.10882 (0.10882)
[2022-07-23 11:42:56,881][feature_train_ori.py][L341][INFO] Step [8/2500000=0.00%] | Epoch 0 | Time 66.113 (66.113) | Lr 0.0001 | AIC Loss 0.08306 (0.08306) | All Losses 0.09465 (0.09465)
[2022-07-23 11:44:02,358][feature_train_ori.py][L341][INFO] Step [9/2500000=0.00%] | Epoch 0 | Time 65.448 (65.448) | Lr 0.0001 | AIC Loss 0.08993 (0.08993) | All Losses 0.10236 (0.10236)
[2022-07-23 11:45:08,138][feature_train_ori.py][L341][INFO] Step [10/2500000=0.00%] | Epoch 0 | Time 65.751 (65.751) | Lr 0.0001 | AIC Loss 0.08938 (0.08938) | All Losses 0.10036 (0.10036)
[2022-07-23 11:46:25,139][feature_train_ori.py][L341][INFO] Step [11/2500000=0.00%] | Epoch 0 | Time 67.100 (67.100) | Lr 0.0001 | AIC Loss 0.07969 (0.07969) | All Losses 0.09122 (0.09122)
[2022-07-23 11:47:31,902][feature_train_ori.py][L341][INFO] Step [12/2500000=0.00%] | Epoch 0 | Time 66.736 (66.736) | Lr 0.0001 | AIC Loss 0.07164 (0.07164) | All Losses 0.08034 (0.08034)
[2022-07-23 11:48:38,835][feature_train_ori.py][L341][INFO] Step [13/2500000=0.00%] | Epoch 0 | Time 66.896 (66.896) | Lr 0.0001 | AIC Loss 0.08924 (0.08924) | All Losses 0.10503 (0.10503)
[2022-07-23 11:49:44,917][feature_train_ori.py][L341][INFO] Step [14/2500000=0.00%] | Epoch 0 | Time 66.053 (66.053) | Lr 0.0001 | AIC Loss 0.07982 (0.07982) | All Losses 0.08807 (0.08807)
[2022-07-23 11:50:51,397][feature_train_ori.py][L341][INFO] Step [15/2500000=0.00%] | Epoch 0 | Time 66.452 (66.452) | Lr 0.0001 | AIC Loss 0.06289 (0.06289) | All Losses 0.07371 (0.07371)
[2022-07-23 11:51:57,318][feature_train_ori.py][L341][INFO] Step [16/2500000=0.00%] | Epoch 0 | Time 65.892 (65.892) | Lr 0.0001 | AIC Loss 0.08059 (0.08059) | All Losses 0.09789 (0.09789)
[2022-07-23 11:53:02,997][feature_train_ori.py][L341][INFO] Step [17/2500000=0.00%] | Epoch 0 | Time 65.651 (65.651) | Lr 0.0001 | AIC Loss 0.09247 (0.09247) | All Losses 0.10540 (0.10540)
[2022-07-23 11:54:09,037][feature_train_ori.py][L341][INFO] Step [18/2500000=0.00%] | Epoch 0 | Time 66.012 (66.012) | Lr 0.0001 | AIC Loss 0.07423 (0.07423) | All Losses 0.08289 (0.08289)
[2022-07-23 11:55:14,893][feature_train_ori.py][L341][INFO] Step [19/2500000=0.00%] | Epoch 0 | Time 65.827 (65.827) | Lr 0.0001 | AIC Loss 0.08158 (0.08158) | All Losses 0.09462 (0.09462)
[2022-07-23 11:56:20,452][feature_train_ori.py][L341][INFO] Step [20/2500000=0.00%] | Epoch 0 | Time 65.531 (65.531) | Lr 0.0001 | AIC Loss 0.08569 (0.08569) | All Losses 0.09026 (0.09026)
[2022-07-23 11:57:35,714][feature_train_ori.py][L341][INFO] Step [21/2500000=0.00%] | Epoch 0 | Time 65.316 (65.316) | Lr 0.0001 | AIC Loss 0.07968 (0.07968) | All Losses 0.09046 (0.09046)
[2022-07-23 11:58:41,666][feature_train_ori.py][L341][INFO] Step [22/2500000=0.00%] | Epoch 0 | Time 65.924 (65.924) | Lr 0.0001 | AIC Loss 0.07000 (0.07000) | All Losses 0.07888 (0.07888)
[2022-07-23 11:59:47,100][feature_train_ori.py][L341][INFO] Step [23/2500000=0.00%] | Epoch 0 | Time 65.405 (65.405) | Lr 0.0001 | AIC Loss 0.08070 (0.08070) | All Losses 0.09088 (0.09088)
[2022-07-23 12:00:52,588][feature_train_ori.py][L341][INFO] Step [24/2500000=0.00%] | Epoch 0 | Time 65.461 (65.461) | Lr 0.0001 | AIC Loss 0.07116 (0.07116) | All Losses 0.07914 (0.07914)
[2022-07-23 12:01:58,346][feature_train_ori.py][L341][INFO] Step [25/2500000=0.00%] | Epoch 0 | Time 65.730 (65.730) | Lr 0.0001 | AIC Loss 0.07193 (0.07193) | All Losses 0.08048 (0.08048)
[2022-07-23 12:03:04,557][feature_train_ori.py][L341][INFO] Step [26/2500000=0.00%] | Epoch 0 | Time 66.183 (66.183) | Lr 0.0001 | AIC Loss 0.06609 (0.06609) | All Losses 0.07708 (0.07708)
[2022-07-23 12:04:10,915][feature_train_ori.py][L341][INFO] Step [27/2500000=0.00%] | Epoch 0 | Time 66.329 (66.329) | Lr 0.0001 | AIC Loss 0.06268 (0.06268) | All Losses 0.07279 (0.07279)
[2022-07-23 12:05:16,590][feature_train_ori.py][L341][INFO] Step [28/2500000=0.00%] | Epoch 0 | Time 65.647 (65.647) | Lr 0.0001 | AIC Loss 0.07479 (0.07479) | All Losses 0.08335 (0.08335)
[2022-07-23 12:06:22,027][feature_train_ori.py][L341][INFO] Step [29/2500000=0.00%] | Epoch 0 | Time 65.408 (65.408) | Lr 0.0001 | AIC Loss 0.07906 (0.07906) | All Losses 0.08896 (0.08896)
[2022-07-23 12:07:27,733][feature_train_ori.py][L341][INFO] Step [30/2500000=0.00%] | Epoch 0 | Time 65.678 (65.678) | Lr 0.0001 | AIC Loss 0.08036 (0.08036) | All Losses 0.09216 (0.09216)
[2022-07-23 12:08:43,119][feature_train_ori.py][L341][INFO] Step [31/2500000=0.00%] | Epoch 0 | Time 65.416 (65.416) | Lr 0.0001 | AIC Loss 0.07450 (0.07450) | All Losses 0.08363 (0.08363)
[2022-07-23 12:09:49,897][feature_train_ori.py][L341][INFO] Step [32/2500000=0.00%] | Epoch 0 | Time 66.748 (66.748) | Lr 0.0001 | AIC Loss 0.05945 (0.05945) | All Losses 0.07611 (0.07611)
[2022-07-23 12:10:56,676][feature_train_ori.py][L341][INFO] Step [33/2500000=0.00%] | Epoch 0 | Time 66.750 (66.750) | Lr 0.0001 | AIC Loss 0.06690 (0.06690) | All Losses 0.07351 (0.07351)
[2022-07-23 12:12:02,915][feature_train_ori.py][L341][INFO] Step [34/2500000=0.00%] | Epoch 0 | Time 66.200 (66.200) | Lr 0.0001 | AIC Loss 0.07567 (0.07567) | All Losses 0.08249 (0.08249)
[2022-07-23 12:13:09,063][feature_train_ori.py][L341][INFO] Step [35/2500000=0.00%] | Epoch 0 | Time 66.120 (66.120) | Lr 0.0001 | AIC Loss 0.07267 (0.07267) | All Losses 0.07928 (0.07928)
[2022-07-23 12:14:14,730][feature_train_ori.py][L341][INFO] Step [36/2500000=0.00%] | Epoch 0 | Time 65.637 (65.637) | Lr 0.0001 | AIC Loss 0.08227 (0.08227) | All Losses 0.09716 (0.09716)
[2022-07-23 12:15:20,518][feature_train_ori.py][L341][INFO] Step [37/2500000=0.00%] | Epoch 0 | Time 65.760 (65.760) | Lr 0.0001 | AIC Loss 0.06162 (0.06162) | All Losses 0.07327 (0.07327)
[2022-07-23 12:16:26,279][feature_train_ori.py][L341][INFO] Step [38/2500000=0.00%] | Epoch 0 | Time 65.733 (65.733) | Lr 0.0001 | AIC Loss 0.06789 (0.06789) | All Losses 0.07668 (0.07668)
[2022-07-23 12:17:32,475][feature_train_ori.py][L341][INFO] Step [39/2500000=0.00%] | Epoch 0 | Time 66.168 (66.168) | Lr 0.0001 | AIC Loss 0.05949 (0.05949) | All Losses 0.06668 (0.06668)
[2022-07-23 12:18:37,845][feature_train_ori.py][L341][INFO] Step [40/2500000=0.00%] | Epoch 0 | Time 65.342 (65.342) | Lr 0.0001 | AIC Loss 0.06890 (0.06890) | All Losses 0.08549 (0.08549)
[2022-07-23 12:19:54,233][feature_train_ori.py][L341][INFO] Step [41/2500000=0.00%] | Epoch 0 | Time 66.497 (66.497) | Lr 0.0001 | AIC Loss 0.06427 (0.06427) | All Losses 0.07240 (0.07240)
[2022-07-23 12:21:00,476][feature_train_ori.py][L341][INFO] Step [42/2500000=0.00%] | Epoch 0 | Time 66.214 (66.214) | Lr 0.0001 | AIC Loss 0.05952 (0.05952) | All Losses 0.06421 (0.06421)
[2022-07-23 12:22:06,685][feature_train_ori.py][L341][INFO] Step [43/2500000=0.00%] | Epoch 0 | Time 66.181 (66.181) | Lr 0.0001 | AIC Loss 0.06050 (0.06050) | All Losses 0.06786 (0.06786)
[2022-07-23 12:23:12,901][feature_train_ori.py][L341][INFO] Step [44/2500000=0.00%] | Epoch 0 | Time 66.188 (66.188) | Lr 0.0001 | AIC Loss 0.06963 (0.06963) | All Losses 0.07906 (0.07906)
[2022-07-23 12:24:19,344][feature_train_ori.py][L341][INFO] Step [45/2500000=0.00%] | Epoch 0 | Time 66.416 (66.416) | Lr 0.0001 | AIC Loss 0.05126 (0.05126) | All Losses 0.05702 (0.05702)
[2022-07-23 12:25:25,827][feature_train_ori.py][L341][INFO] Step [46/2500000=0.00%] | Epoch 0 | Time 66.455 (66.455) | Lr 0.0001 | AIC Loss 0.06589 (0.06589) | All Losses 0.07638 (0.07638)
[2022-07-23 12:26:31,545][feature_train_ori.py][L341][INFO] Step [47/2500000=0.00%] | Epoch 0 | Time 65.689 (65.689) | Lr 0.0001 | AIC Loss 0.07091 (0.07091) | All Losses 0.07997 (0.07997)
[2022-07-23 12:27:37,499][feature_train_ori.py][L341][INFO] Step [48/2500000=0.00%] | Epoch 0 | Time 65.926 (65.926) | Lr 0.0001 | AIC Loss 0.05974 (0.05974) | All Losses 0.06704 (0.06704)
[2022-07-23 12:28:43,536][feature_train_ori.py][L341][INFO] Step [49/2500000=0.00%] | Epoch 0 | Time 66.008 (66.008) | Lr 0.0001 | AIC Loss 0.06483 (0.06483) | All Losses 0.07273 (0.07273)
[2022-07-23 12:29:49,055][feature_train_ori.py][L341][INFO] Step [50/2500000=0.00%] | Epoch 0 | Time 65.491 (65.491) | Lr 0.0001 | AIC Loss 0.06266 (0.06266) | All Losses 0.07333 (0.07333)
[2022-07-23 12:30:57,379][feature_train_ori.py][L341][INFO] Step [51/2500000=0.00%] | Epoch 0 | Time 65.817 (65.817) | Lr 0.0001 | AIC Loss 0.06928 (0.06928) | All Losses 0.08207 (0.08207)
[2022-07-23 12:32:03,376][feature_train_ori.py][L341][INFO] Step [52/2500000=0.00%] | Epoch 0 | Time 65.969 (65.969) | Lr 0.0001 | AIC Loss 0.06038 (0.06038) | All Losses 0.07148 (0.07148)
[2022-07-23 12:33:08,801][feature_train_ori.py][L341][INFO] Step [53/2500000=0.00%] | Epoch 0 | Time 65.396 (65.396) | Lr 0.0001 | AIC Loss 0.06980 (0.06980) | All Losses 0.07765 (0.07765)
[2022-07-23 12:34:14,529][feature_train_ori.py][L341][INFO] Step [54/2500000=0.00%] | Epoch 0 | Time 65.700 (65.700) | Lr 0.0001 | AIC Loss 0.06602 (0.06602) | All Losses 0.07556 (0.07556)
[2022-07-23 12:35:20,188][feature_train_ori.py][L341][INFO] Step [55/2500000=0.00%] | Epoch 0 | Time 65.630 (65.630) | Lr 0.0001 | AIC Loss 0.06648 (0.06648) | All Losses 0.07955 (0.07955)
[2022-07-23 12:36:25,845][feature_train_ori.py][L341][INFO] Step [56/2500000=0.00%] | Epoch 0 | Time 65.628 (65.628) | Lr 0.0001 | AIC Loss 0.07443 (0.07443) | All Losses 0.08319 (0.08319)
[2022-07-23 12:37:31,505][feature_train_ori.py][L341][INFO] Step [57/2500000=0.00%] | Epoch 0 | Time 65.631 (65.631) | Lr 0.0001 | AIC Loss 0.05824 (0.05824) | All Losses 0.06406 (0.06406)
[2022-07-23 12:38:37,333][feature_train_ori.py][L341][INFO] Step [58/2500000=0.00%] | Epoch 0 | Time 65.800 (65.800) | Lr 0.0001 | AIC Loss 0.05689 (0.05689) | All Losses 0.06582 (0.06582)
[2022-07-23 12:39:42,623][feature_train_ori.py][L341][INFO] Step [59/2500000=0.00%] | Epoch 0 | Time 65.262 (65.262) | Lr 0.0001 | AIC Loss 0.06681 (0.06681) | All Losses 0.07684 (0.07684)
[2022-07-23 12:40:48,542][feature_train_ori.py][L341][INFO] Step [60/2500000=0.00%] | Epoch 0 | Time 65.890 (65.890) | Lr 0.0001 | AIC Loss 0.05352 (0.05352) | All Losses 0.06807 (0.06807)
[2022-07-23 12:41:57,060][feature_train_ori.py][L341][INFO] Step [61/2500000=0.00%] | Epoch 0 | Time 66.041 (66.041) | Lr 0.0001 | AIC Loss 0.05802 (0.05802) | All Losses 0.06625 (0.06625)
[2022-07-23 12:43:02,896][feature_train_ori.py][L341][INFO] Step [62/2500000=0.00%] | Epoch 0 | Time 65.808 (65.808) | Lr 0.0001 | AIC Loss 0.05996 (0.05996) | All Losses 0.07381 (0.07381)
[2022-07-23 12:44:09,502][feature_train_ori.py][L341][INFO] Step [63/2500000=0.00%] | Epoch 0 | Time 66.568 (66.568) | Lr 0.0001 | AIC Loss 0.05742 (0.05742) | All Losses 0.06510 (0.06510)
[2022-07-23 12:45:15,608][feature_train_ori.py][L341][INFO] Step [64/2500000=0.00%] | Epoch 0 | Time 66.077 (66.077) | Lr 0.0001 | AIC Loss 0.06067 (0.06067) | All Losses 0.06883 (0.06883)
[2022-07-23 12:46:21,528][feature_train_ori.py][L341][INFO] Step [65/2500000=0.00%] | Epoch 0 | Time 65.892 (65.892) | Lr 0.0001 | AIC Loss 0.06414 (0.06414) | All Losses 0.07090 (0.07090)
[2022-07-23 12:47:27,895][feature_train_ori.py][L341][INFO] Step [66/2500000=0.00%] | Epoch 0 | Time 66.338 (66.338) | Lr 0.0001 | AIC Loss 0.05649 (0.05649) | All Losses 0.06598 (0.06598)
[2022-07-23 12:48:33,826][feature_train_ori.py][L341][INFO] Step [67/2500000=0.00%] | Epoch 0 | Time 65.903 (65.903) | Lr 0.0001 | AIC Loss 0.05303 (0.05303) | All Losses 0.06343 (0.06343)
[2022-07-23 12:49:39,486][feature_train_ori.py][L341][INFO] Step [68/2500000=0.00%] | Epoch 0 | Time 65.631 (65.631) | Lr 0.0001 | AIC Loss 0.07071 (0.07071) | All Losses 0.08471 (0.08471)
[2022-07-23 12:50:45,330][feature_train_ori.py][L341][INFO] Step [69/2500000=0.00%] | Epoch 0 | Time 65.815 (65.815) | Lr 0.0001 | AIC Loss 0.04911 (0.04911) | All Losses 0.05771 (0.05771)
[2022-07-23 12:51:51,396][feature_train_ori.py][L341][INFO] Step [70/2500000=0.00%] | Epoch 0 | Time 66.039 (66.039) | Lr 0.0001 | AIC Loss 0.05215 (0.05215) | All Losses 0.05987 (0.05987)
[2022-07-23 12:52:59,853][feature_train_ori.py][L341][INFO] Step [71/2500000=0.00%] | Epoch 0 | Time 65.940 (65.940) | Lr 0.0001 | AIC Loss 0.05509 (0.05509) | All Losses 0.06405 (0.06405)
[2022-07-23 12:54:05,558][feature_train_ori.py][L341][INFO] Step [72/2500000=0.00%] | Epoch 0 | Time 65.677 (65.677) | Lr 0.0001 | AIC Loss 0.06151 (0.06151) | All Losses 0.07170 (0.07170)
[2022-07-23 12:55:11,446][feature_train_ori.py][L341][INFO] Step [73/2500000=0.00%] | Epoch 0 | Time 65.859 (65.859) | Lr 0.0001 | AIC Loss 0.06628 (0.06628) | All Losses 0.07053 (0.07053)
[2022-07-23 12:56:17,295][feature_train_ori.py][L341][INFO] Step [74/2500000=0.00%] | Epoch 0 | Time 65.821 (65.821) | Lr 0.0001 | AIC Loss 0.04921 (0.04921) | All Losses 0.05760 (0.05760)
[2022-07-23 12:57:22,739][feature_train_ori.py][L341][INFO] Step [75/2500000=0.00%] | Epoch 0 | Time 65.416 (65.416) | Lr 0.0001 | AIC Loss 0.05500 (0.05500) | All Losses 0.06159 (0.06159)
[2022-07-23 12:58:28,663][feature_train_ori.py][L341][INFO] Step [76/2500000=0.00%] | Epoch 0 | Time 65.896 (65.896) | Lr 0.0001 | AIC Loss 0.05117 (0.05117) | All Losses 0.06004 (0.06004)
[2022-07-23 12:59:34,922][feature_train_ori.py][L341][INFO] Step [77/2500000=0.00%] | Epoch 0 | Time 66.231 (66.231) | Lr 0.0001 | AIC Loss 0.06015 (0.06015) | All Losses 0.06793 (0.06793)
[2022-07-23 13:00:40,872][feature_train_ori.py][L341][INFO] Step [78/2500000=0.00%] | Epoch 0 | Time 65.921 (65.921) | Lr 0.0001 | AIC Loss 0.06060 (0.06060) | All Losses 0.07322 (0.07322)
[2022-07-23 13:01:47,193][feature_train_ori.py][L341][INFO] Step [79/2500000=0.00%] | Epoch 0 | Time 66.284 (66.284) | Lr 0.0001 | AIC Loss 0.05763 (0.05763) | All Losses 0.06531 (0.06531)
[2022-07-23 13:02:54,160][feature_train_ori.py][L341][INFO] Step [80/2500000=0.00%] | Epoch 0 | Time 66.939 (66.939) | Lr 0.0001 | AIC Loss 0.05495 (0.05495) | All Losses 0.05902 (0.05902)
[2022-07-23 13:04:02,866][feature_train_ori.py][L341][INFO] Step [81/2500000=0.00%] | Epoch 0 | Time 66.191 (66.191) | Lr 0.0001 | AIC Loss 0.05296 (0.05296) | All Losses 0.06298 (0.06298)
[2022-07-23 13:05:09,307][feature_train_ori.py][L341][INFO] Step [82/2500000=0.00%] | Epoch 0 | Time 66.404 (66.404) | Lr 0.0001 | AIC Loss 0.05228 (0.05228) | All Losses 0.06386 (0.06386)
[2022-07-23 13:06:15,106][feature_train_ori.py][L341][INFO] Step [83/2500000=0.00%] | Epoch 0 | Time 65.770 (65.770) | Lr 0.0001 | AIC Loss 0.06040 (0.06040) | All Losses 0.06606 (0.06606)
[2022-07-23 13:07:21,304][feature_train_ori.py][L341][INFO] Step [84/2500000=0.00%] | Epoch 0 | Time 66.170 (66.170) | Lr 0.0001 | AIC Loss 0.04880 (0.04880) | All Losses 0.05681 (0.05681)
[2022-07-23 13:08:26,924][feature_train_ori.py][L341][INFO] Step [85/2500000=0.00%] | Epoch 0 | Time 65.592 (65.592) | Lr 0.0001 | AIC Loss 0.05877 (0.05877) | All Losses 0.06924 (0.06924)
[2022-07-23 13:09:33,277][feature_train_ori.py][L341][INFO] Step [86/2500000=0.00%] | Epoch 0 | Time 66.325 (66.325) | Lr 0.0001 | AIC Loss 0.05263 (0.05263) | All Losses 0.06559 (0.06559)
[2022-07-23 13:10:39,102][feature_train_ori.py][L341][INFO] Step [87/2500000=0.00%] | Epoch 0 | Time 65.797 (65.797) | Lr 0.0001 | AIC Loss 0.05032 (0.05032) | All Losses 0.05704 (0.05704)
[2022-07-23 13:11:44,644][feature_train_ori.py][L341][INFO] Step [88/2500000=0.00%] | Epoch 0 | Time 65.513 (65.513) | Lr 0.0001 | AIC Loss 0.05097 (0.05097) | All Losses 0.05894 (0.05894)
[2022-07-23 13:12:50,856][feature_train_ori.py][L341][INFO] Step [89/2500000=0.00%] | Epoch 0 | Time 66.184 (66.184) | Lr 0.0001 | AIC Loss 0.04711 (0.04711) | All Losses 0.05548 (0.05548)
[2022-07-23 13:13:56,655][feature_train_ori.py][L341][INFO] Step [90/2500000=0.00%] | Epoch 0 | Time 65.771 (65.771) | Lr 0.0001 | AIC Loss 0.04961 (0.04961) | All Losses 0.05831 (0.05831)
[2022-07-23 13:15:06,230][feature_train_ori.py][L341][INFO] Step [91/2500000=0.00%] | Epoch 0 | Time 67.061 (67.061) | Lr 0.0001 | AIC Loss 0.05082 (0.05082) | All Losses 0.05485 (0.05485)
[2022-07-23 13:16:12,364][feature_train_ori.py][L341][INFO] Step [92/2500000=0.00%] | Epoch 0 | Time 66.106 (66.106) | Lr 0.0001 | AIC Loss 0.04753 (0.04753) | All Losses 0.05720 (0.05720)
[2022-07-23 13:17:18,356][feature_train_ori.py][L341][INFO] Step [93/2500000=0.00%] | Epoch 0 | Time 65.964 (65.964) | Lr 0.0001 | AIC Loss 0.05510 (0.05510) | All Losses 0.06404 (0.06404)
[2022-07-23 13:18:24,437][feature_train_ori.py][L341][INFO] Step [94/2500000=0.00%] | Epoch 0 | Time 66.053 (66.053) | Lr 0.0001 | AIC Loss 0.04948 (0.04948) | All Losses 0.05865 (0.05865)
[2022-07-23 13:19:30,465][feature_train_ori.py][L341][INFO] Step [95/2500000=0.00%] | Epoch 0 | Time 66.000 (66.000) | Lr 0.0001 | AIC Loss 0.04754 (0.04754) | All Losses 0.05901 (0.05901)
[2022-07-23 13:20:36,332][feature_train_ori.py][L341][INFO] Step [96/2500000=0.00%] | Epoch 0 | Time 65.838 (65.838) | Lr 0.0001 | AIC Loss 0.04497 (0.04497) | All Losses 0.05463 (0.05463)
[2022-07-23 13:21:42,697][feature_train_ori.py][L341][INFO] Step [97/2500000=0.00%] | Epoch 0 | Time 66.337 (66.337) | Lr 0.0001 | AIC Loss 0.05087 (0.05087) | All Losses 0.05824 (0.05824)
[2022-07-23 13:22:48,556][feature_train_ori.py][L341][INFO] Step [98/2500000=0.00%] | Epoch 0 | Time 65.831 (65.831) | Lr 0.0001 | AIC Loss 0.05780 (0.05780) | All Losses 0.06199 (0.06199)
[2022-07-23 13:23:54,748][feature_train_ori.py][L341][INFO] Step [99/2500000=0.00%] | Epoch 0 | Time 66.164 (66.164) | Lr 0.0001 | AIC Loss 0.04890 (0.04890) | All Losses 0.05431 (0.05431)
[2022-07-23 13:25:01,000][feature_train_ori.py][L341][INFO] Step [100/2500000=0.00%] | Epoch 0 | Time 66.224 (66.224) | Lr 0.0001 | AIC Loss 0.04521 (0.04521) | All Losses 0.05359 (0.05359)
[2022-07-23 13:26:09,488][feature_train_ori.py][L341][INFO] Step [101/2500000=0.00%] | Epoch 0 | Time 65.966 (65.966) | Lr 0.0001 | AIC Loss 0.05798 (0.05798) | All Losses 0.06449 (0.06449)
[2022-07-23 13:27:15,365][feature_train_ori.py][L341][INFO] Step [102/2500000=0.00%] | Epoch 0 | Time 65.849 (65.849) | Lr 0.0001 | AIC Loss 0.05268 (0.05268) | All Losses 0.05976 (0.05976)
[2022-07-23 13:28:21,441][feature_train_ori.py][L341][INFO] Step [103/2500000=0.00%] | Epoch 0 | Time 66.047 (66.047) | Lr 0.0001 | AIC Loss 0.05450 (0.05450) | All Losses 0.06455 (0.06455)
[2022-07-23 13:29:27,525][feature_train_ori.py][L341][INFO] Step [104/2500000=0.00%] | Epoch 0 | Time 66.056 (66.056) | Lr 0.0001 | AIC Loss 0.04833 (0.04833) | All Losses 0.05867 (0.05867)
[2022-07-23 13:30:34,444][feature_train_ori.py][L341][INFO] Step [105/2500000=0.00%] | Epoch 0 | Time 66.890 (66.890) | Lr 0.0001 | AIC Loss 0.04988 (0.04988) | All Losses 0.05667 (0.05667)
[2022-07-23 13:37:16,111][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-23 13:37:16,111][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-23 13:52:46,417][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-23 13:52:46,417][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-23 13:52:53,286][feature_train_ori.py][L384][INFO] Concatenation(
  (relu): LeakyReLU(negative_slope=0.01)
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv1): ConvTranspose2d(4096, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv11_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv2): ConvTranspose2d(4096, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv12_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv3): ConvTranspose2d(2048, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
  (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
  (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
)
[2022-07-23 13:53:00,364][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-23 13:54:12,935][feature_train_ori.py][L341][INFO] Step [1/2500000=0.00%] | Epoch 0 | Time 72.079 (72.079) | Lr 0.0001 | AIC Loss 0.27155 (0.27155) | All Losses 0.31543 (0.31543)
[2022-07-23 13:55:24,569][feature_train_ori.py][L341][INFO] Step [2/2500000=0.00%] | Epoch 0 | Time 71.606 (71.606) | Lr 0.0001 | AIC Loss 0.30585 (0.30585) | All Losses 0.33853 (0.33853)
[2022-07-23 13:56:29,656][feature_train_ori.py][L341][INFO] Step [3/2500000=0.00%] | Epoch 0 | Time 65.059 (65.059) | Lr 0.0001 | AIC Loss 0.27751 (0.27751) | All Losses 0.32424 (0.32424)
[2022-07-23 13:57:38,032][feature_train_ori.py][L341][INFO] Step [4/2500000=0.00%] | Epoch 0 | Time 68.348 (68.348) | Lr 0.0001 | AIC Loss 0.23653 (0.23653) | All Losses 0.29695 (0.29695)
[2022-07-23 13:58:39,291][feature_train_ori.py][L341][INFO] Step [5/2500000=0.00%] | Epoch 0 | Time 61.230 (61.230) | Lr 0.0001 | AIC Loss 0.21670 (0.21670) | All Losses 0.28446 (0.28446)
[2022-07-23 13:59:40,541][feature_train_ori.py][L341][INFO] Step [6/2500000=0.00%] | Epoch 0 | Time 61.221 (61.221) | Lr 0.0001 | AIC Loss 0.17184 (0.17184) | All Losses 0.25454 (0.25454)
[2022-07-23 14:00:42,080][feature_train_ori.py][L341][INFO] Step [7/2500000=0.00%] | Epoch 0 | Time 61.510 (61.510) | Lr 0.0001 | AIC Loss 0.14702 (0.14702) | All Losses 0.22077 (0.22077)
[2022-07-23 14:01:43,453][feature_train_ori.py][L341][INFO] Step [8/2500000=0.00%] | Epoch 0 | Time 61.344 (61.344) | Lr 0.0001 | AIC Loss 0.15127 (0.15127) | All Losses 0.23888 (0.23888)
[2022-07-23 14:02:44,759][feature_train_ori.py][L341][INFO] Step [9/2500000=0.00%] | Epoch 0 | Time 61.277 (61.277) | Lr 0.0001 | AIC Loss 0.17225 (0.17225) | All Losses 0.26398 (0.26398)
[2022-07-23 14:03:45,998][feature_train_ori.py][L341][INFO] Step [10/2500000=0.00%] | Epoch 0 | Time 61.211 (61.211) | Lr 0.0001 | AIC Loss 0.14081 (0.14081) | All Losses 0.22390 (0.22390)
[2022-07-23 14:04:49,069][feature_train_ori.py][L341][INFO] Step [11/2500000=0.00%] | Epoch 0 | Time 61.376 (61.376) | Lr 0.0001 | AIC Loss 0.14676 (0.14676) | All Losses 0.22557 (0.22557)
[2022-07-23 14:05:50,536][feature_train_ori.py][L341][INFO] Step [12/2500000=0.00%] | Epoch 0 | Time 61.438 (61.438) | Lr 0.0001 | AIC Loss 0.15103 (0.15103) | All Losses 0.23733 (0.23733)
[2022-07-23 14:06:51,794][feature_train_ori.py][L341][INFO] Step [13/2500000=0.00%] | Epoch 0 | Time 61.230 (61.230) | Lr 0.0001 | AIC Loss 0.15122 (0.15122) | All Losses 0.24211 (0.24211)
[2022-07-23 14:07:53,075][feature_train_ori.py][L341][INFO] Step [14/2500000=0.00%] | Epoch 0 | Time 61.253 (61.253) | Lr 0.0001 | AIC Loss 0.12680 (0.12680) | All Losses 0.21807 (0.21807)
[2022-07-23 14:08:54,423][feature_train_ori.py][L341][INFO] Step [15/2500000=0.00%] | Epoch 0 | Time 61.319 (61.319) | Lr 0.0001 | AIC Loss 0.13917 (0.13917) | All Losses 0.22696 (0.22696)
[2022-07-23 14:09:55,650][feature_train_ori.py][L341][INFO] Step [16/2500000=0.00%] | Epoch 0 | Time 61.198 (61.198) | Lr 0.0001 | AIC Loss 0.13551 (0.13551) | All Losses 0.22500 (0.22500)
[2022-07-23 14:10:56,958][feature_train_ori.py][L341][INFO] Step [17/2500000=0.00%] | Epoch 0 | Time 61.279 (61.279) | Lr 0.0001 | AIC Loss 0.14343 (0.14343) | All Losses 0.23611 (0.23611)
[2022-07-23 14:11:58,424][feature_train_ori.py][L341][INFO] Step [18/2500000=0.00%] | Epoch 0 | Time 61.438 (61.438) | Lr 0.0001 | AIC Loss 0.13949 (0.13949) | All Losses 0.24063 (0.24063)
[2022-07-23 14:12:59,718][feature_train_ori.py][L341][INFO] Step [19/2500000=0.00%] | Epoch 0 | Time 61.265 (61.265) | Lr 0.0001 | AIC Loss 0.11548 (0.11548) | All Losses 0.21830 (0.21830)
[2022-07-23 14:14:01,146][feature_train_ori.py][L341][INFO] Step [20/2500000=0.00%] | Epoch 0 | Time 61.399 (61.399) | Lr 0.0001 | AIC Loss 0.12868 (0.12868) | All Losses 0.24455 (0.24455)
[2022-07-23 14:15:05,985][feature_train_ori.py][L341][INFO] Step [21/2500000=0.00%] | Epoch 0 | Time 63.146 (63.146) | Lr 0.0001 | AIC Loss 0.14029 (0.14029) | All Losses 0.23306 (0.23306)
[2022-07-23 14:16:07,147][feature_train_ori.py][L341][INFO] Step [22/2500000=0.00%] | Epoch 0 | Time 61.133 (61.133) | Lr 0.0001 | AIC Loss 0.12845 (0.12845) | All Losses 0.23162 (0.23162)
[2022-07-23 14:17:08,378][feature_train_ori.py][L341][INFO] Step [23/2500000=0.00%] | Epoch 0 | Time 61.203 (61.203) | Lr 0.0001 | AIC Loss 0.12421 (0.12421) | All Losses 0.22234 (0.22234)
[2022-07-23 14:18:09,469][feature_train_ori.py][L341][INFO] Step [24/2500000=0.00%] | Epoch 0 | Time 61.062 (61.062) | Lr 0.0001 | AIC Loss 0.12346 (0.12346) | All Losses 0.22622 (0.22622)
[2022-07-23 14:19:13,795][feature_train_ori.py][L341][INFO] Step [25/2500000=0.00%] | Epoch 0 | Time 64.297 (64.297) | Lr 0.0001 | AIC Loss 0.13240 (0.13240) | All Losses 0.24850 (0.24850)
[2022-07-23 14:20:15,317][feature_train_ori.py][L341][INFO] Step [26/2500000=0.00%] | Epoch 0 | Time 61.493 (61.493) | Lr 0.0001 | AIC Loss 0.13329 (0.13329) | All Losses 0.24413 (0.24413)
[2022-07-23 14:21:19,663][feature_train_ori.py][L341][INFO] Step [27/2500000=0.00%] | Epoch 0 | Time 64.317 (64.317) | Lr 0.0001 | AIC Loss 0.12577 (0.12577) | All Losses 0.23775 (0.23775)
[2022-07-23 14:22:20,977][feature_train_ori.py][L341][INFO] Step [28/2500000=0.00%] | Epoch 0 | Time 61.285 (61.285) | Lr 0.0001 | AIC Loss 0.10745 (0.10745) | All Losses 0.22828 (0.22828)
[2022-07-23 14:23:22,199][feature_train_ori.py][L341][INFO] Step [29/2500000=0.00%] | Epoch 0 | Time 61.194 (61.194) | Lr 0.0001 | AIC Loss 0.11174 (0.11174) | All Losses 0.20843 (0.20843)
[2022-07-23 14:24:23,577][feature_train_ori.py][L341][INFO] Step [30/2500000=0.00%] | Epoch 0 | Time 61.349 (61.349) | Lr 0.0001 | AIC Loss 0.11537 (0.11537) | All Losses 0.21018 (0.21018)
[2022-07-23 14:25:26,651][feature_train_ori.py][L341][INFO] Step [31/2500000=0.00%] | Epoch 0 | Time 61.389 (61.389) | Lr 0.0001 | AIC Loss 0.10444 (0.10444) | All Losses 0.22790 (0.22790)
[2022-07-23 14:26:28,151][feature_train_ori.py][L341][INFO] Step [32/2500000=0.00%] | Epoch 0 | Time 61.471 (61.471) | Lr 0.0001 | AIC Loss 0.11526 (0.11526) | All Losses 0.24365 (0.24365)
[2022-07-23 14:27:29,605][feature_train_ori.py][L341][INFO] Step [33/2500000=0.00%] | Epoch 0 | Time 61.426 (61.426) | Lr 0.0001 | AIC Loss 0.09911 (0.09911) | All Losses 0.20792 (0.20792)
[2022-07-23 14:28:30,858][feature_train_ori.py][L341][INFO] Step [34/2500000=0.00%] | Epoch 0 | Time 61.224 (61.224) | Lr 0.0001 | AIC Loss 0.11121 (0.11121) | All Losses 0.20696 (0.20696)
[2022-07-23 14:29:32,531][feature_train_ori.py][L341][INFO] Step [35/2500000=0.00%] | Epoch 0 | Time 61.644 (61.644) | Lr 0.0001 | AIC Loss 0.11370 (0.11370) | All Losses 0.22075 (0.22075)
[2022-07-23 14:30:40,696][feature_train_ori.py][L341][INFO] Step [36/2500000=0.00%] | Epoch 0 | Time 68.137 (68.137) | Lr 0.0001 | AIC Loss 0.11645 (0.11645) | All Losses 0.21897 (0.21897)
[2022-07-23 14:31:41,853][feature_train_ori.py][L341][INFO] Step [37/2500000=0.00%] | Epoch 0 | Time 61.122 (61.122) | Lr 0.0001 | AIC Loss 0.11295 (0.11295) | All Losses 0.21435 (0.21435)
[2022-07-23 14:32:43,454][feature_train_ori.py][L341][INFO] Step [38/2500000=0.00%] | Epoch 0 | Time 61.572 (61.572) | Lr 0.0001 | AIC Loss 0.11065 (0.11065) | All Losses 0.22311 (0.22311)
[2022-07-23 14:33:47,180][feature_train_ori.py][L341][INFO] Step [39/2500000=0.00%] | Epoch 0 | Time 63.698 (63.698) | Lr 0.0001 | AIC Loss 0.11145 (0.11145) | All Losses 0.21347 (0.21347)
[2022-07-23 14:34:48,531][feature_train_ori.py][L341][INFO] Step [40/2500000=0.00%] | Epoch 0 | Time 61.322 (61.322) | Lr 0.0001 | AIC Loss 0.08455 (0.08455) | All Losses 0.20107 (0.20107)
[2022-07-23 14:35:51,876][feature_train_ori.py][L341][INFO] Step [41/2500000=0.00%] | Epoch 0 | Time 61.664 (61.664) | Lr 0.0001 | AIC Loss 0.10775 (0.10775) | All Losses 0.21722 (0.21722)
[2022-07-23 14:36:53,234][feature_train_ori.py][L341][INFO] Step [42/2500000=0.00%] | Epoch 0 | Time 61.329 (61.329) | Lr 0.0001 | AIC Loss 0.11718 (0.11718) | All Losses 0.22796 (0.22796)
[2022-07-23 14:37:54,635][feature_train_ori.py][L341][INFO] Step [43/2500000=0.00%] | Epoch 0 | Time 61.373 (61.373) | Lr 0.0001 | AIC Loss 0.11277 (0.11277) | All Losses 0.22621 (0.22621)
[2022-07-23 14:38:55,904][feature_train_ori.py][L341][INFO] Step [44/2500000=0.00%] | Epoch 0 | Time 61.240 (61.240) | Lr 0.0001 | AIC Loss 0.10802 (0.10802) | All Losses 0.22224 (0.22224)
[2022-07-23 14:39:57,274][feature_train_ori.py][L341][INFO] Step [45/2500000=0.00%] | Epoch 0 | Time 61.342 (61.342) | Lr 0.0001 | AIC Loss 0.10093 (0.10093) | All Losses 0.22649 (0.22649)
[2022-07-23 14:40:58,372][feature_train_ori.py][L341][INFO] Step [46/2500000=0.00%] | Epoch 0 | Time 61.069 (61.069) | Lr 0.0001 | AIC Loss 0.10909 (0.10909) | All Losses 0.23546 (0.23546)
[2022-07-23 14:41:59,628][feature_train_ori.py][L341][INFO] Step [47/2500000=0.00%] | Epoch 0 | Time 61.228 (61.228) | Lr 0.0001 | AIC Loss 0.11100 (0.11100) | All Losses 0.21958 (0.21958)
[2022-07-23 14:43:02,925][feature_train_ori.py][L341][INFO] Step [48/2500000=0.00%] | Epoch 0 | Time 63.269 (63.269) | Lr 0.0001 | AIC Loss 0.11498 (0.11498) | All Losses 0.23166 (0.23166)
[2022-07-23 14:44:11,440][feature_train_ori.py][L341][INFO] Step [49/2500000=0.00%] | Epoch 0 | Time 68.486 (68.486) | Lr 0.0001 | AIC Loss 0.10822 (0.10822) | All Losses 0.20749 (0.20749)
[2022-07-23 14:45:15,353][feature_train_ori.py][L341][INFO] Step [50/2500000=0.00%] | Epoch 0 | Time 63.884 (63.884) | Lr 0.0001 | AIC Loss 0.10904 (0.10904) | All Losses 0.21937 (0.21937)
[2022-07-23 14:46:20,620][feature_train_ori.py][L341][INFO] Step [51/2500000=0.00%] | Epoch 0 | Time 63.598 (63.598) | Lr 0.0001 | AIC Loss 0.09837 (0.09837) | All Losses 0.21182 (0.21182)
[2022-07-23 14:47:24,698][feature_train_ori.py][L341][INFO] Step [52/2500000=0.00%] | Epoch 0 | Time 64.050 (64.050) | Lr 0.0001 | AIC Loss 0.11111 (0.11111) | All Losses 0.23731 (0.23731)
[2022-07-23 14:49:55,907][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-23 14:49:55,907][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-23 14:50:03,233][feature_train_ori.py][L384][INFO] Concatenation(
  (relu): LeakyReLU(negative_slope=0.01)
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv1): ConvTranspose2d(4096, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv11_1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv2): ConvTranspose2d(4096, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv12_1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv3): ConvTranspose2d(2048, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv13_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
  (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
  (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
)
[2022-07-23 14:50:10,447][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-23 14:51:47,557][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-23 14:51:47,557][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-23 14:51:56,261][feature_train_ori.py][L384][INFO] Concatenation(
  (relu): LeakyReLU(negative_slope=0.01)
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv1): ConvTranspose2d(4096, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv11_1): Conv2d(4096, 4096, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv2): ConvTranspose2d(4096, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv12_1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv3): ConvTranspose2d(2048, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv13_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
  (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
  (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
)
[2022-07-23 14:52:03,359][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-23 14:53:16,922][feature_train_ori.py][L341][INFO] Step [1/2500000=0.00%] | Epoch 0 | Time 73.065 (73.065) | Lr 0.0001 | AIC Loss 0.08078 (0.08078) | All Losses 0.08566 (0.08566)
[2022-07-23 14:54:29,671][feature_train_ori.py][L341][INFO] Step [2/2500000=0.00%] | Epoch 0 | Time 72.700 (72.700) | Lr 0.0001 | AIC Loss 0.44046 (0.44046) | All Losses 0.60946 (0.60946)
[2022-07-23 14:55:39,034][feature_train_ori.py][L341][INFO] Step [3/2500000=0.00%] | Epoch 0 | Time 69.315 (69.315) | Lr 0.0001 | AIC Loss 0.38027 (0.38027) | All Losses 0.51965 (0.51965)
[2022-07-23 14:56:41,767][feature_train_ori.py][L341][INFO] Step [4/2500000=0.00%] | Epoch 0 | Time 62.684 (62.684) | Lr 0.0001 | AIC Loss 0.36968 (0.36968) | All Losses 0.47348 (0.47348)
[2022-07-23 14:57:44,096][feature_train_ori.py][L341][INFO] Step [5/2500000=0.00%] | Epoch 0 | Time 62.281 (62.281) | Lr 0.0001 | AIC Loss 0.28690 (0.28690) | All Losses 0.36555 (0.36555)
[2022-07-23 14:58:46,548][feature_train_ori.py][L341][INFO] Step [6/2500000=0.00%] | Epoch 0 | Time 62.404 (62.404) | Lr 0.0001 | AIC Loss 0.23218 (0.23218) | All Losses 0.29219 (0.29219)
[2022-07-23 14:59:48,965][feature_train_ori.py][L341][INFO] Step [7/2500000=0.00%] | Epoch 0 | Time 62.368 (62.368) | Lr 0.0001 | AIC Loss 0.20214 (0.20214) | All Losses 0.23748 (0.23748)
[2022-07-23 15:00:51,448][feature_train_ori.py][L341][INFO] Step [8/2500000=0.00%] | Epoch 0 | Time 62.435 (62.435) | Lr 0.0001 | AIC Loss 0.19566 (0.19566) | All Losses 0.21612 (0.21612)
[2022-07-23 15:01:53,986][feature_train_ori.py][L341][INFO] Step [9/2500000=0.00%] | Epoch 0 | Time 62.490 (62.490) | Lr 0.0001 | AIC Loss 0.12210 (0.12210) | All Losses 0.13204 (0.13204)
[2022-07-23 15:02:56,907][feature_train_ori.py][L341][INFO] Step [10/2500000=0.00%] | Epoch 0 | Time 62.873 (62.873) | Lr 0.0001 | AIC Loss 0.11938 (0.11938) | All Losses 0.13068 (0.13068)
[2022-07-23 15:04:13,903][feature_train_ori.py][L341][INFO] Step [11/2500000=0.00%] | Epoch 0 | Time 62.293 (62.293) | Lr 0.0001 | AIC Loss 0.11132 (0.11132) | All Losses 0.12222 (0.12222)
[2022-07-23 15:05:16,269][feature_train_ori.py][L341][INFO] Step [12/2500000=0.00%] | Epoch 0 | Time 62.317 (62.317) | Lr 0.0001 | AIC Loss 0.12416 (0.12416) | All Losses 0.12788 (0.12788)
[2022-07-23 15:06:18,968][feature_train_ori.py][L341][INFO] Step [13/2500000=0.00%] | Epoch 0 | Time 62.650 (62.650) | Lr 0.0001 | AIC Loss 0.07394 (0.07394) | All Losses 0.07787 (0.07787)
[2022-07-23 15:07:21,356][feature_train_ori.py][L341][INFO] Step [14/2500000=0.00%] | Epoch 0 | Time 62.340 (62.340) | Lr 0.0001 | AIC Loss 0.08195 (0.08195) | All Losses 0.08500 (0.08500)
[2022-07-23 15:08:23,998][feature_train_ori.py][L341][INFO] Step [15/2500000=0.00%] | Epoch 0 | Time 62.592 (62.592) | Lr 0.0001 | AIC Loss 0.10002 (0.10002) | All Losses 0.10435 (0.10435)
[2022-07-23 15:09:26,416][feature_train_ori.py][L341][INFO] Step [16/2500000=0.00%] | Epoch 0 | Time 62.371 (62.371) | Lr 0.0001 | AIC Loss 0.06499 (0.06499) | All Losses 0.06698 (0.06698)
[2022-07-23 15:10:29,151][feature_train_ori.py][L341][INFO] Step [17/2500000=0.00%] | Epoch 0 | Time 62.686 (62.686) | Lr 0.0001 | AIC Loss 0.05413 (0.05413) | All Losses 0.05959 (0.05959)
[2022-07-23 15:11:42,058][feature_train_ori.py][L341][INFO] Step [18/2500000=0.00%] | Epoch 0 | Time 72.858 (72.858) | Lr 0.0001 | AIC Loss 0.05707 (0.05707) | All Losses 0.05924 (0.05924)
[2022-07-23 15:12:54,984][feature_train_ori.py][L341][INFO] Step [19/2500000=0.00%] | Epoch 0 | Time 72.877 (72.877) | Lr 0.0001 | AIC Loss 0.05386 (0.05386) | All Losses 0.05893 (0.05893)
[2022-07-23 15:14:05,308][feature_train_ori.py][L341][INFO] Step [20/2500000=0.00%] | Epoch 0 | Time 70.274 (70.274) | Lr 0.0001 | AIC Loss 0.04399 (0.04399) | All Losses 0.05039 (0.05039)
[2022-07-23 15:15:29,542][feature_train_ori.py][L341][INFO] Step [21/2500000=0.00%] | Epoch 0 | Time 69.398 (69.398) | Lr 0.0001 | AIC Loss 0.04802 (0.04802) | All Losses 0.05527 (0.05527)
[2022-07-23 15:16:39,638][feature_train_ori.py][L341][INFO] Step [22/2500000=0.00%] | Epoch 0 | Time 70.048 (70.048) | Lr 0.0001 | AIC Loss 0.04022 (0.04022) | All Losses 0.04712 (0.04712)
[2022-07-23 15:17:49,691][feature_train_ori.py][L341][INFO] Step [23/2500000=0.00%] | Epoch 0 | Time 70.004 (70.004) | Lr 0.0001 | AIC Loss 0.03354 (0.03354) | All Losses 0.04298 (0.04298)
[2022-07-23 15:18:59,499][feature_train_ori.py][L341][INFO] Step [24/2500000=0.00%] | Epoch 0 | Time 69.759 (69.759) | Lr 0.0001 | AIC Loss 0.04021 (0.04021) | All Losses 0.05287 (0.05287)
[2022-07-23 15:20:08,996][feature_train_ori.py][L341][INFO] Step [25/2500000=0.00%] | Epoch 0 | Time 69.449 (69.449) | Lr 0.0001 | AIC Loss 0.03100 (0.03100) | All Losses 0.03891 (0.03891)
[2022-07-23 15:21:18,803][feature_train_ori.py][L341][INFO] Step [26/2500000=0.00%] | Epoch 0 | Time 69.758 (69.758) | Lr 0.0001 | AIC Loss 0.03060 (0.03060) | All Losses 0.03684 (0.03684)
[2022-07-23 15:22:28,779][feature_train_ori.py][L341][INFO] Step [27/2500000=0.00%] | Epoch 0 | Time 69.928 (69.928) | Lr 0.0001 | AIC Loss 0.04431 (0.04431) | All Losses 0.05523 (0.05523)
[2022-07-23 15:23:40,495][feature_train_ori.py][L341][INFO] Step [28/2500000=0.00%] | Epoch 0 | Time 71.668 (71.668) | Lr 0.0001 | AIC Loss 0.03131 (0.03131) | All Losses 0.03718 (0.03718)
[2022-07-23 15:24:50,716][feature_train_ori.py][L341][INFO] Step [29/2500000=0.00%] | Epoch 0 | Time 70.173 (70.173) | Lr 0.0001 | AIC Loss 0.03828 (0.03828) | All Losses 0.04640 (0.04640)
[2022-07-23 15:26:01,337][feature_train_ori.py][L341][INFO] Step [30/2500000=0.00%] | Epoch 0 | Time 70.572 (70.572) | Lr 0.0001 | AIC Loss 0.02736 (0.02736) | All Losses 0.03770 (0.03770)
[2022-07-23 15:27:27,038][feature_train_ori.py][L341][INFO] Step [31/2500000=0.00%] | Epoch 0 | Time 70.416 (70.416) | Lr 0.0001 | AIC Loss 0.02844 (0.02844) | All Losses 0.03730 (0.03730)
[2022-07-23 15:28:37,679][feature_train_ori.py][L341][INFO] Step [32/2500000=0.00%] | Epoch 0 | Time 70.576 (70.576) | Lr 0.0001 | AIC Loss 0.02919 (0.02919) | All Losses 0.03950 (0.03950)
[2022-07-23 15:29:48,777][feature_train_ori.py][L341][INFO] Step [33/2500000=0.00%] | Epoch 0 | Time 71.049 (71.049) | Lr 0.0001 | AIC Loss 0.04035 (0.04035) | All Losses 0.04637 (0.04637)
[2022-07-23 15:30:58,851][feature_train_ori.py][L341][INFO] Step [34/2500000=0.00%] | Epoch 0 | Time 70.025 (70.025) | Lr 0.0001 | AIC Loss 0.02950 (0.02950) | All Losses 0.03885 (0.03885)
[2022-07-23 15:32:08,941][feature_train_ori.py][L341][INFO] Step [35/2500000=0.00%] | Epoch 0 | Time 70.042 (70.042) | Lr 0.0001 | AIC Loss 0.03013 (0.03013) | All Losses 0.03722 (0.03722)
[2022-07-23 15:33:20,352][feature_train_ori.py][L341][INFO] Step [36/2500000=0.00%] | Epoch 0 | Time 71.363 (71.363) | Lr 0.0001 | AIC Loss 0.03155 (0.03155) | All Losses 0.03917 (0.03917)
[2022-07-23 15:34:30,144][feature_train_ori.py][L341][INFO] Step [37/2500000=0.00%] | Epoch 0 | Time 69.724 (69.724) | Lr 0.0001 | AIC Loss 0.03331 (0.03331) | All Losses 0.04456 (0.04456)
[2022-07-23 15:35:40,384][feature_train_ori.py][L341][INFO] Step [38/2500000=0.00%] | Epoch 0 | Time 70.191 (70.191) | Lr 0.0001 | AIC Loss 0.03566 (0.03566) | All Losses 0.04797 (0.04797)
[2022-07-23 15:36:50,387][feature_train_ori.py][L341][INFO] Step [39/2500000=0.00%] | Epoch 0 | Time 69.949 (69.949) | Lr 0.0001 | AIC Loss 0.03220 (0.03220) | All Losses 0.04353 (0.04353)
[2022-07-23 15:38:01,121][feature_train_ori.py][L341][INFO] Step [40/2500000=0.00%] | Epoch 0 | Time 70.686 (70.686) | Lr 0.0001 | AIC Loss 0.02317 (0.02317) | All Losses 0.02967 (0.02967)
[2022-07-23 15:39:29,304][feature_train_ori.py][L341][INFO] Step [41/2500000=0.00%] | Epoch 0 | Time 71.667 (71.667) | Lr 0.0001 | AIC Loss 0.02968 (0.02968) | All Losses 0.04113 (0.04113)
[2022-07-23 15:40:39,426][feature_train_ori.py][L341][INFO] Step [42/2500000=0.00%] | Epoch 0 | Time 70.073 (70.073) | Lr 0.0001 | AIC Loss 0.03369 (0.03369) | All Losses 0.04248 (0.04248)
[2022-07-23 15:41:49,746][feature_train_ori.py][L341][INFO] Step [43/2500000=0.00%] | Epoch 0 | Time 70.272 (70.272) | Lr 0.0001 | AIC Loss 0.02711 (0.02711) | All Losses 0.03862 (0.03862)
[2022-07-23 15:42:59,886][feature_train_ori.py][L341][INFO] Step [44/2500000=0.00%] | Epoch 0 | Time 70.091 (70.091) | Lr 0.0001 | AIC Loss 0.03790 (0.03790) | All Losses 0.04503 (0.04503)
[2022-07-23 15:44:10,246][feature_train_ori.py][L341][INFO] Step [45/2500000=0.00%] | Epoch 0 | Time 70.315 (70.315) | Lr 0.0001 | AIC Loss 0.03375 (0.03375) | All Losses 0.04225 (0.04225)
[2022-07-23 15:45:20,657][feature_train_ori.py][L341][INFO] Step [46/2500000=0.00%] | Epoch 0 | Time 70.363 (70.363) | Lr 0.0001 | AIC Loss 0.02751 (0.02751) | All Losses 0.03838 (0.03838)
[2022-07-23 15:46:30,934][feature_train_ori.py][L341][INFO] Step [47/2500000=0.00%] | Epoch 0 | Time 70.228 (70.228) | Lr 0.0001 | AIC Loss 0.03209 (0.03209) | All Losses 0.03773 (0.03773)
[2022-07-23 15:47:41,163][feature_train_ori.py][L341][INFO] Step [48/2500000=0.00%] | Epoch 0 | Time 70.181 (70.181) | Lr 0.0001 | AIC Loss 0.03036 (0.03036) | All Losses 0.04142 (0.04142)
[2022-07-23 15:48:51,709][feature_train_ori.py][L341][INFO] Step [49/2500000=0.00%] | Epoch 0 | Time 70.497 (70.497) | Lr 0.0001 | AIC Loss 0.02430 (0.02430) | All Losses 0.03357 (0.03357)
[2022-07-23 15:50:02,549][feature_train_ori.py][L341][INFO] Step [50/2500000=0.00%] | Epoch 0 | Time 70.792 (70.792) | Lr 0.0001 | AIC Loss 0.03418 (0.03418) | All Losses 0.04322 (0.04322)
[2022-07-23 15:51:27,496][feature_train_ori.py][L341][INFO] Step [51/2500000=0.00%] | Epoch 0 | Time 70.016 (70.016) | Lr 0.0001 | AIC Loss 0.02935 (0.02935) | All Losses 0.03631 (0.03631)
[2022-07-23 15:52:38,150][feature_train_ori.py][L341][INFO] Step [52/2500000=0.00%] | Epoch 0 | Time 70.606 (70.606) | Lr 0.0001 | AIC Loss 0.03573 (0.03573) | All Losses 0.04070 (0.04070)
[2022-07-23 15:53:48,005][feature_train_ori.py][L341][INFO] Step [53/2500000=0.00%] | Epoch 0 | Time 69.806 (69.806) | Lr 0.0001 | AIC Loss 0.03093 (0.03093) | All Losses 0.04156 (0.04156)
[2022-07-23 15:54:58,397][feature_train_ori.py][L341][INFO] Step [54/2500000=0.00%] | Epoch 0 | Time 70.343 (70.343) | Lr 0.0001 | AIC Loss 0.03131 (0.03131) | All Losses 0.04324 (0.04324)
[2022-07-23 15:56:09,873][feature_train_ori.py][L341][INFO] Step [55/2500000=0.00%] | Epoch 0 | Time 71.428 (71.428) | Lr 0.0001 | AIC Loss 0.03045 (0.03045) | All Losses 0.03949 (0.03949)
[2022-07-23 15:57:19,503][feature_train_ori.py][L341][INFO] Step [56/2500000=0.00%] | Epoch 0 | Time 69.582 (69.582) | Lr 0.0001 | AIC Loss 0.03477 (0.03477) | All Losses 0.04057 (0.04057)
[2022-07-23 15:58:29,468][feature_train_ori.py][L341][INFO] Step [57/2500000=0.00%] | Epoch 0 | Time 69.916 (69.916) | Lr 0.0001 | AIC Loss 0.03208 (0.03208) | All Losses 0.03985 (0.03985)
[2022-07-23 16:12:16,778][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-23 16:12:16,779][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-23 16:12:25,470][feature_train_ori.py][L384][INFO] Concatenation(
  (relu): LeakyReLU(negative_slope=0.01)
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv1): ConvTranspose2d(4096, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv11_1): Conv2d(4096, 4096, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv2): ConvTranspose2d(4096, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv12_1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv3): ConvTranspose2d(2048, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv13_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
  (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
  (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
)
[2022-07-23 16:12:32,692][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-23 16:13:46,042][feature_train_ori.py][L341][INFO] Step [1/2500000=0.00%] | Epoch 0 | Time 72.857 (72.857) | Lr 0.0001 | AIC Loss 0.07220 (0.07220) | All Losses 0.21428 (0.21428)
[2022-07-23 16:14:58,357][feature_train_ori.py][L341][INFO] Step [2/2500000=0.00%] | Epoch 0 | Time 72.266 (72.266) | Lr 0.0001 | AIC Loss 0.42504 (0.42504) | All Losses 0.42787 (0.42787)
[2022-07-23 16:16:08,074][feature_train_ori.py][L341][INFO] Step [3/2500000=0.00%] | Epoch 0 | Time 69.670 (69.670) | Lr 0.0001 | AIC Loss 0.32266 (0.32266) | All Losses 0.33076 (0.33076)
[2022-07-23 16:17:20,327][feature_train_ori.py][L341][INFO] Step [4/2500000=0.00%] | Epoch 0 | Time 72.206 (72.206) | Lr 0.0001 | AIC Loss 0.25904 (0.25904) | All Losses 0.29246 (0.29246)
[2022-07-23 16:18:30,055][feature_train_ori.py][L341][INFO] Step [5/2500000=0.00%] | Epoch 0 | Time 69.680 (69.680) | Lr 0.0001 | AIC Loss 0.22120 (0.22120) | All Losses 0.26481 (0.26481)
[2022-07-23 16:19:40,502][feature_train_ori.py][L341][INFO] Step [6/2500000=0.00%] | Epoch 0 | Time 70.399 (70.399) | Lr 0.0001 | AIC Loss 0.21711 (0.21711) | All Losses 0.28195 (0.28195)
[2022-07-23 16:20:51,583][feature_train_ori.py][L341][INFO] Step [7/2500000=0.00%] | Epoch 0 | Time 71.021 (71.021) | Lr 0.0001 | AIC Loss 0.18750 (0.18750) | All Losses 0.28618 (0.28618)
[2022-07-23 16:22:02,018][feature_train_ori.py][L341][INFO] Step [8/2500000=0.00%] | Epoch 0 | Time 70.386 (70.386) | Lr 0.0001 | AIC Loss 0.16453 (0.16453) | All Losses 0.25097 (0.25097)
[2022-07-23 16:23:11,752][feature_train_ori.py][L341][INFO] Step [9/2500000=0.00%] | Epoch 0 | Time 69.686 (69.686) | Lr 0.0001 | AIC Loss 0.15466 (0.15466) | All Losses 0.25894 (0.25894)
[2022-07-23 16:24:21,307][feature_train_ori.py][L341][INFO] Step [10/2500000=0.00%] | Epoch 0 | Time 69.506 (69.506) | Lr 0.0001 | AIC Loss 0.16178 (0.16178) | All Losses 0.27610 (0.27610)
[2022-07-23 16:25:35,861][feature_train_ori.py][L341][INFO] Step [11/2500000=0.00%] | Epoch 0 | Time 69.548 (69.548) | Lr 0.0001 | AIC Loss 0.10303 (0.10303) | All Losses 0.21980 (0.21980)
[2022-07-23 16:26:45,690][feature_train_ori.py][L341][INFO] Step [12/2500000=0.00%] | Epoch 0 | Time 69.781 (69.781) | Lr 0.0001 | AIC Loss 0.11807 (0.11807) | All Losses 0.23172 (0.23172)
[2022-07-23 16:27:56,821][feature_train_ori.py][L341][INFO] Step [13/2500000=0.00%] | Epoch 0 | Time 71.082 (71.082) | Lr 0.0001 | AIC Loss 0.09171 (0.09171) | All Losses 0.22338 (0.22338)
[2022-07-23 16:29:06,382][feature_train_ori.py][L341][INFO] Step [14/2500000=0.00%] | Epoch 0 | Time 69.513 (69.513) | Lr 0.0001 | AIC Loss 0.10704 (0.10704) | All Losses 0.24030 (0.24030)
[2022-07-23 16:30:16,458][feature_train_ori.py][L341][INFO] Step [15/2500000=0.00%] | Epoch 0 | Time 70.028 (70.028) | Lr 0.0001 | AIC Loss 0.09577 (0.09577) | All Losses 0.23142 (0.23142)
[2022-07-23 16:31:29,087][feature_train_ori.py][L341][INFO] Step [16/2500000=0.00%] | Epoch 0 | Time 72.581 (72.581) | Lr 0.0001 | AIC Loss 0.06934 (0.06934) | All Losses 0.20454 (0.20454)
[2022-07-23 16:32:40,565][feature_train_ori.py][L341][INFO] Step [17/2500000=0.00%] | Epoch 0 | Time 71.431 (71.431) | Lr 0.0001 | AIC Loss 0.09315 (0.09315) | All Losses 0.22475 (0.22475)
[2022-07-23 16:33:51,914][feature_train_ori.py][L341][INFO] Step [18/2500000=0.00%] | Epoch 0 | Time 71.301 (71.301) | Lr 0.0001 | AIC Loss 0.09996 (0.09996) | All Losses 0.23359 (0.23359)
[2022-07-23 16:35:01,955][feature_train_ori.py][L341][INFO] Step [19/2500000=0.00%] | Epoch 0 | Time 69.992 (69.992) | Lr 0.0001 | AIC Loss 0.07269 (0.07269) | All Losses 0.21683 (0.21683)
[2022-07-23 16:36:12,515][feature_train_ori.py][L341][INFO] Step [20/2500000=0.00%] | Epoch 0 | Time 70.512 (70.512) | Lr 0.0001 | AIC Loss 0.08493 (0.08493) | All Losses 0.21663 (0.21663)
[2022-07-23 16:37:28,994][feature_train_ori.py][L341][INFO] Step [21/2500000=0.00%] | Epoch 0 | Time 71.761 (71.761) | Lr 0.0001 | AIC Loss 0.07563 (0.07563) | All Losses 0.21177 (0.21177)
[2022-07-23 16:38:43,358][feature_train_ori.py][L341][INFO] Step [22/2500000=0.00%] | Epoch 0 | Time 74.315 (74.315) | Lr 0.0001 | AIC Loss 0.08650 (0.08650) | All Losses 0.20903 (0.20903)
[2022-07-23 16:39:53,728][feature_train_ori.py][L341][INFO] Step [23/2500000=0.00%] | Epoch 0 | Time 70.322 (70.322) | Lr 0.0001 | AIC Loss 0.07627 (0.07627) | All Losses 0.21445 (0.21445)
[2022-07-23 16:41:03,588][feature_train_ori.py][L341][INFO] Step [24/2500000=0.00%] | Epoch 0 | Time 69.811 (69.811) | Lr 0.0001 | AIC Loss 0.08965 (0.08965) | All Losses 0.22588 (0.22588)
[2022-07-23 16:42:13,758][feature_train_ori.py][L341][INFO] Step [25/2500000=0.00%] | Epoch 0 | Time 70.122 (70.122) | Lr 0.0001 | AIC Loss 0.08078 (0.08078) | All Losses 0.21922 (0.21922)
[2022-07-23 16:43:23,815][feature_train_ori.py][L341][INFO] Step [26/2500000=0.00%] | Epoch 0 | Time 70.008 (70.008) | Lr 0.0001 | AIC Loss 0.07686 (0.07686) | All Losses 0.19119 (0.19119)
[2022-07-23 16:44:34,735][feature_train_ori.py][L341][INFO] Step [27/2500000=0.00%] | Epoch 0 | Time 70.870 (70.870) | Lr 0.0001 | AIC Loss 0.08581 (0.08581) | All Losses 0.20196 (0.20196)
[2022-07-23 16:45:46,503][feature_train_ori.py][L341][INFO] Step [28/2500000=0.00%] | Epoch 0 | Time 71.719 (71.719) | Lr 0.0001 | AIC Loss 0.08868 (0.08868) | All Losses 0.20839 (0.20839)
[2022-07-23 16:46:56,713][feature_train_ori.py][L341][INFO] Step [29/2500000=0.00%] | Epoch 0 | Time 70.162 (70.162) | Lr 0.0001 | AIC Loss 0.08358 (0.08358) | All Losses 0.21775 (0.21775)
[2022-07-23 16:48:06,499][feature_train_ori.py][L341][INFO] Step [30/2500000=0.00%] | Epoch 0 | Time 69.737 (69.737) | Lr 0.0001 | AIC Loss 0.07808 (0.07808) | All Losses 0.21667 (0.21667)
[2022-07-23 16:49:21,225][feature_train_ori.py][L341][INFO] Step [31/2500000=0.00%] | Epoch 0 | Time 70.083 (70.083) | Lr 0.0001 | AIC Loss 0.06967 (0.06967) | All Losses 0.19734 (0.19734)
[2022-07-23 16:50:31,152][feature_train_ori.py][L341][INFO] Step [32/2500000=0.00%] | Epoch 0 | Time 69.879 (69.879) | Lr 0.0001 | AIC Loss 0.09274 (0.09274) | All Losses 0.22289 (0.22289)
[2022-07-23 16:51:40,925][feature_train_ori.py][L341][INFO] Step [33/2500000=0.00%] | Epoch 0 | Time 69.725 (69.725) | Lr 0.0001 | AIC Loss 0.09384 (0.09384) | All Losses 0.21699 (0.21699)
[2022-07-23 16:52:50,791][feature_train_ori.py][L341][INFO] Step [34/2500000=0.00%] | Epoch 0 | Time 69.818 (69.818) | Lr 0.0001 | AIC Loss 0.08279 (0.08279) | All Losses 0.21722 (0.21722)
[2022-07-23 16:54:00,308][feature_train_ori.py][L341][INFO] Step [35/2500000=0.00%] | Epoch 0 | Time 69.468 (69.468) | Lr 0.0001 | AIC Loss 0.07087 (0.07087) | All Losses 0.21158 (0.21158)
[2022-07-23 16:55:10,207][feature_train_ori.py][L341][INFO] Step [36/2500000=0.00%] | Epoch 0 | Time 69.851 (69.851) | Lr 0.0001 | AIC Loss 0.06667 (0.06667) | All Losses 0.19959 (0.19959)
[2022-07-23 16:56:20,015][feature_train_ori.py][L341][INFO] Step [37/2500000=0.00%] | Epoch 0 | Time 69.760 (69.760) | Lr 0.0001 | AIC Loss 0.10001 (0.10001) | All Losses 0.22939 (0.22939)
[2022-07-23 16:57:29,699][feature_train_ori.py][L341][INFO] Step [38/2500000=0.00%] | Epoch 0 | Time 69.635 (69.635) | Lr 0.0001 | AIC Loss 0.08799 (0.08799) | All Losses 0.21426 (0.21426)
[2022-07-23 17:03:35,872][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-23 17:03:35,872][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-23 17:03:44,540][feature_train_ori.py][L384][INFO] Concatenation(
  (relu): LeakyReLU(negative_slope=0.01)
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv1): ConvTranspose2d(4096, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv11_1): Conv2d(4096, 4096, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv2): ConvTranspose2d(4096, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv12_1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv3): ConvTranspose2d(2048, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv13_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
  (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
  (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
)
[2022-07-23 17:03:51,668][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-23 17:05:13,979][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-23 17:05:13,979][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-23 17:05:22,635][feature_train_ori.py][L384][INFO] Concatenation(
  (relu): LeakyReLU(negative_slope=0.01)
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv1): ConvTranspose2d(4096, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv11_1): Conv2d(4096, 4096, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv2): ConvTranspose2d(4096, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv12_1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv3): ConvTranspose2d(2048, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv13_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
  (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
  (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
)
[2022-07-23 17:05:29,747][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-23 17:06:22,700][feature_train_ori.py][L371][INFO] Auto Encoder training
[2022-07-23 17:06:22,700][feature_train_ori.py][L372][INFO] Encoder & Decoder Model : 
[2022-07-23 17:06:31,362][feature_train_ori.py][L384][INFO] Concatenation(
  (relu): LeakyReLU(negative_slope=0.01)
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv1): ConvTranspose2d(4096, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv11_1): Conv2d(4096, 4096, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv2): ConvTranspose2d(4096, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv12_1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv3): ConvTranspose2d(2048, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv13_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
  (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
  (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
)
[2022-07-23 17:06:38,462][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-23 17:07:51,228][feature_train_ori.py][L341][INFO] Step [1/2500000=0.00%] | Epoch 0 | Time 72.312 (72.312) | Lr 0.0001 | AIC Loss 0.39019 (0.39019) | All Losses 0.55182 (0.55182)
[2022-07-23 17:09:03,197][feature_train_ori.py][L341][INFO] Step [2/2500000=0.00%] | Epoch 0 | Time 71.942 (71.942) | Lr 0.0001 | AIC Loss 0.39184 (0.39184) | All Losses 0.54087 (0.54087)
[2022-07-23 17:10:11,804][feature_train_ori.py][L341][INFO] Step [3/2500000=0.00%] | Epoch 0 | Time 68.580 (68.580) | Lr 0.0001 | AIC Loss 0.33733 (0.33733) | All Losses 0.46174 (0.46174)
[2022-07-23 17:11:20,663][feature_train_ori.py][L341][INFO] Step [4/2500000=0.00%] | Epoch 0 | Time 68.831 (68.831) | Lr 0.0001 | AIC Loss 0.28005 (0.28005) | All Losses 0.39905 (0.39905)
[2022-07-23 17:12:29,337][feature_train_ori.py][L341][INFO] Step [5/2500000=0.00%] | Epoch 0 | Time 68.647 (68.647) | Lr 0.0001 | AIC Loss 0.29987 (0.29987) | All Losses 0.40086 (0.40086)
[2022-07-23 17:13:37,920][feature_train_ori.py][L341][INFO] Step [6/2500000=0.00%] | Epoch 0 | Time 68.555 (68.555) | Lr 0.0001 | AIC Loss 0.35867 (0.35867) | All Losses 0.43706 (0.43706)
[2022-07-23 17:14:40,186][feature_train_ori.py][L341][INFO] Step [7/2500000=0.00%] | Epoch 0 | Time 62.239 (62.239) | Lr 0.0001 | AIC Loss 0.29494 (0.29494) | All Losses 0.37578 (0.37578)
[2022-07-23 17:15:45,608][feature_train_ori.py][L341][INFO] Step [8/2500000=0.00%] | Epoch 0 | Time 65.393 (65.393) | Lr 0.0001 | AIC Loss 0.28539 (0.28539) | All Losses 0.38031 (0.38031)
[2022-07-23 17:16:49,793][feature_train_ori.py][L341][INFO] Step [9/2500000=0.00%] | Epoch 0 | Time 64.158 (64.158) | Lr 0.0001 | AIC Loss 0.28237 (0.28237) | All Losses 0.36011 (0.36011)
[2022-07-23 17:17:54,398][feature_train_ori.py][L341][INFO] Step [10/2500000=0.00%] | Epoch 0 | Time 64.577 (64.577) | Lr 0.0001 | AIC Loss 0.28030 (0.28030) | All Losses 0.37165 (0.37165)
[2022-07-23 17:19:11,564][feature_train_ori.py][L341][INFO] Step [11/2500000=0.00%] | Epoch 0 | Time 61.952 (61.952) | Lr 0.0001 | AIC Loss 0.29430 (0.29430) | All Losses 0.36646 (0.36646)
[2022-07-23 17:20:13,608][feature_train_ori.py][L341][INFO] Step [12/2500000=0.00%] | Epoch 0 | Time 62.016 (62.016) | Lr 0.0001 | AIC Loss 0.28385 (0.28385) | All Losses 0.35195 (0.35195)
[2022-07-23 17:21:15,896][feature_train_ori.py][L341][INFO] Step [13/2500000=0.00%] | Epoch 0 | Time 62.261 (62.261) | Lr 0.0001 | AIC Loss 0.25949 (0.25949) | All Losses 0.32161 (0.32161)
[2022-07-23 17:22:24,677][feature_train_ori.py][L341][INFO] Step [14/2500000=0.00%] | Epoch 0 | Time 68.754 (68.754) | Lr 0.0001 | AIC Loss 0.24697 (0.24697) | All Losses 0.32110 (0.32110)
[2022-07-23 17:23:33,399][feature_train_ori.py][L341][INFO] Step [15/2500000=0.00%] | Epoch 0 | Time 68.694 (68.694) | Lr 0.0001 | AIC Loss 0.22854 (0.22854) | All Losses 0.28857 (0.28857)
[2022-07-23 17:24:42,269][feature_train_ori.py][L341][INFO] Step [16/2500000=0.00%] | Epoch 0 | Time 68.843 (68.843) | Lr 0.0001 | AIC Loss 0.24342 (0.24342) | All Losses 0.30339 (0.30339)
[2022-07-23 17:25:50,852][feature_train_ori.py][L341][INFO] Step [17/2500000=0.00%] | Epoch 0 | Time 68.556 (68.556) | Lr 0.0001 | AIC Loss 0.21288 (0.21288) | All Losses 0.25878 (0.25878)
[2022-07-23 17:26:53,338][feature_train_ori.py][L341][INFO] Step [18/2500000=0.00%] | Epoch 0 | Time 62.459 (62.459) | Lr 0.0001 | AIC Loss 0.21530 (0.21530) | All Losses 0.26006 (0.26006)
[2022-07-23 17:27:55,365][feature_train_ori.py][L341][INFO] Step [19/2500000=0.00%] | Epoch 0 | Time 62.000 (62.000) | Lr 0.0001 | AIC Loss 0.19441 (0.19441) | All Losses 0.24173 (0.24173)
[2022-07-23 17:28:58,534][feature_train_ori.py][L341][INFO] Step [20/2500000=0.00%] | Epoch 0 | Time 63.142 (63.142) | Lr 0.0001 | AIC Loss 0.21603 (0.21603) | All Losses 0.26136 (0.26136)
[2022-07-23 17:30:17,097][feature_train_ori.py][L341][INFO] Step [21/2500000=0.00%] | Epoch 0 | Time 62.956 (62.956) | Lr 0.0001 | AIC Loss 0.18392 (0.18392) | All Losses 0.21691 (0.21691)
[2022-07-23 17:31:19,914][feature_train_ori.py][L341][INFO] Step [22/2500000=0.00%] | Epoch 0 | Time 62.790 (62.790) | Lr 0.0001 | AIC Loss 0.20012 (0.20012) | All Losses 0.23211 (0.23211)
[2022-07-23 17:34:31,595][feature_train_ori.py][L372][INFO] Auto Encoder training
[2022-07-23 17:34:31,595][feature_train_ori.py][L373][INFO] Encoder & Decoder Model : 
[2022-07-23 17:34:40,260][feature_train_ori.py][L385][INFO] Concatenation(
  (relu): LeakyReLU(negative_slope=0.01)
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv1_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv1_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2_2): Conv2d(512, 512, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv2_3): Conv2d(512, 512, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(2, 2))
  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv3_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv3_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4_2): Conv2d(1024, 1024, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv4_3): Conv2d(1024, 1024, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (resconv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(2, 2))
  (bn4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv5_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(2, 2), padding=(1, 0), bias=False)
  (conv5_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(2, 2), padding=(0, 1), bias=False)
  (bn5): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv6): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6_2): Conv2d(2048, 2048, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
  (conv6_3): Conv2d(2048, 2048, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
  (bn6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv1): ConvTranspose2d(4096, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv11_1): Conv2d(4096, 4096, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv2): ConvTranspose2d(4096, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
  (conv12_1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (deconv_bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (deconv3): ConvTranspose2d(2048, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv13_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (GP_conv0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool1): AdaptiveMaxPool2d(output_size=(6, 6))
  (GP_conv1): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))
  (GP_pool2): AdaptiveMaxPool2d(output_size=(3, 3))
  (GP_conv2): Conv2d(384, 2048, kernel_size=(1, 1), stride=(1, 1))
)
[2022-07-23 17:34:47,367][feature_train_ori.py][L121][INFO] Epoch 0 begin
[2022-07-23 17:36:00,853][feature_train_ori.py][L342][INFO] Step [1/2500000=0.00%] | Epoch 0 | Time 73.002 (73.002) | Lr 0.0001 | AIC Loss 0.11787 (0.11787) | All Losses 0.11787 (0.11787)
[2022-07-23 17:37:13,753][feature_train_ori.py][L342][INFO] Step [2/2500000=0.00%] | Epoch 0 | Time 72.852 (72.852) | Lr 0.0001 | AIC Loss 0.41603 (0.41603) | All Losses 0.41603 (0.41603)
[2022-07-23 17:38:23,740][feature_train_ori.py][L342][INFO] Step [3/2500000=0.00%] | Epoch 0 | Time 69.938 (69.938) | Lr 0.0001 | AIC Loss 0.38333 (0.38333) | All Losses 0.38333 (0.38333)
[2022-07-23 17:39:33,954][feature_train_ori.py][L342][INFO] Step [4/2500000=0.00%] | Epoch 0 | Time 70.165 (70.165) | Lr 0.0001 | AIC Loss 0.38253 (0.38253) | All Losses 0.38253 (0.38253)
[2022-07-23 17:40:43,687][feature_train_ori.py][L342][INFO] Step [5/2500000=0.00%] | Epoch 0 | Time 69.685 (69.685) | Lr 0.0001 | AIC Loss 0.32950 (0.32950) | All Losses 0.32950 (0.32950)
[2022-07-23 17:41:54,310][feature_train_ori.py][L342][INFO] Step [6/2500000=0.00%] | Epoch 0 | Time 70.575 (70.575) | Lr 0.0001 | AIC Loss 0.28934 (0.28934) | All Losses 0.28934 (0.28934)
[2022-07-23 17:43:06,091][feature_train_ori.py][L342][INFO] Step [7/2500000=0.00%] | Epoch 0 | Time 71.732 (71.732) | Lr 0.0001 | AIC Loss 0.28937 (0.28937) | All Losses 0.28937 (0.28937)
[2022-07-23 17:44:15,888][feature_train_ori.py][L342][INFO] Step [8/2500000=0.00%] | Epoch 0 | Time 69.747 (69.747) | Lr 0.0001 | AIC Loss 0.19471 (0.19471) | All Losses 0.19471 (0.19471)
[2022-07-23 17:45:25,586][feature_train_ori.py][L342][INFO] Step [9/2500000=0.00%] | Epoch 0 | Time 69.648 (69.648) | Lr 0.0001 | AIC Loss 0.14959 (0.14959) | All Losses 0.14959 (0.14959)
[2022-07-23 17:46:35,552][feature_train_ori.py][L342][INFO] Step [10/2500000=0.00%] | Epoch 0 | Time 69.916 (69.916) | Lr 0.0001 | AIC Loss 0.10808 (0.10808) | All Losses 0.10808 (0.10808)
[2022-07-23 17:47:59,848][feature_train_ori.py][L342][INFO] Step [11/2500000=0.00%] | Epoch 0 | Time 68.900 (68.900) | Lr 0.0001 | AIC Loss 0.08901 (0.08901) | All Losses 0.08901 (0.08901)
[2022-07-23 17:49:09,160][feature_train_ori.py][L342][INFO] Step [12/2500000=0.00%] | Epoch 0 | Time 69.262 (69.262) | Lr 0.0001 | AIC Loss 0.11081 (0.11081) | All Losses 0.11081 (0.11081)
[2022-07-23 17:50:18,929][feature_train_ori.py][L342][INFO] Step [13/2500000=0.00%] | Epoch 0 | Time 69.720 (69.720) | Lr 0.0001 | AIC Loss 0.08866 (0.08866) | All Losses 0.08866 (0.08866)
[2022-07-23 17:51:28,330][feature_train_ori.py][L342][INFO] Step [14/2500000=0.00%] | Epoch 0 | Time 69.352 (69.352) | Lr 0.0001 | AIC Loss 0.08655 (0.08655) | All Losses 0.08655 (0.08655)
[2022-07-23 17:52:39,859][feature_train_ori.py][L342][INFO] Step [15/2500000=0.00%] | Epoch 0 | Time 71.478 (71.478) | Lr 0.0001 | AIC Loss 0.07677 (0.07677) | All Losses 0.07677 (0.07677)
[2022-07-23 17:53:49,380][feature_train_ori.py][L342][INFO] Step [16/2500000=0.00%] | Epoch 0 | Time 69.472 (69.472) | Lr 0.0001 | AIC Loss 0.06491 (0.06491) | All Losses 0.06491 (0.06491)
[2022-07-23 17:54:59,341][feature_train_ori.py][L342][INFO] Step [17/2500000=0.00%] | Epoch 0 | Time 69.912 (69.912) | Lr 0.0001 | AIC Loss 0.05661 (0.05661) | All Losses 0.05661 (0.05661)
[2022-07-23 17:56:08,189][feature_train_ori.py][L342][INFO] Step [18/2500000=0.00%] | Epoch 0 | Time 68.799 (68.799) | Lr 0.0001 | AIC Loss 0.05082 (0.05082) | All Losses 0.05082 (0.05082)
[2022-07-23 17:57:16,808][feature_train_ori.py][L342][INFO] Step [19/2500000=0.00%] | Epoch 0 | Time 68.570 (68.570) | Lr 0.0001 | AIC Loss 0.04046 (0.04046) | All Losses 0.04046 (0.04046)
[2022-07-23 17:58:25,595][feature_train_ori.py][L342][INFO] Step [20/2500000=0.00%] | Epoch 0 | Time 68.738 (68.738) | Lr 0.0001 | AIC Loss 0.06641 (0.06641) | All Losses 0.06641 (0.06641)
[2022-07-23 17:59:50,059][feature_train_ori.py][L342][INFO] Step [21/2500000=0.00%] | Epoch 0 | Time 69.594 (69.594) | Lr 0.0001 | AIC Loss 0.04815 (0.04815) | All Losses 0.04815 (0.04815)
[2022-07-23 18:00:59,979][feature_train_ori.py][L342][INFO] Step [22/2500000=0.00%] | Epoch 0 | Time 69.871 (69.871) | Lr 0.0001 | AIC Loss 0.04569 (0.04569) | All Losses 0.04569 (0.04569)
[2022-07-23 18:02:09,111][feature_train_ori.py][L342][INFO] Step [23/2500000=0.00%] | Epoch 0 | Time 69.083 (69.083) | Lr 0.0001 | AIC Loss 0.03409 (0.03409) | All Losses 0.03409 (0.03409)
[2022-07-23 18:03:19,641][feature_train_ori.py][L342][INFO] Step [24/2500000=0.00%] | Epoch 0 | Time 70.481 (70.481) | Lr 0.0001 | AIC Loss 0.05160 (0.05160) | All Losses 0.05160 (0.05160)
[2022-07-23 18:04:28,815][feature_train_ori.py][L342][INFO] Step [25/2500000=0.00%] | Epoch 0 | Time 69.124 (69.124) | Lr 0.0001 | AIC Loss 0.03545 (0.03545) | All Losses 0.03545 (0.03545)
[2022-07-23 18:05:38,080][feature_train_ori.py][L342][INFO] Step [26/2500000=0.00%] | Epoch 0 | Time 69.217 (69.217) | Lr 0.0001 | AIC Loss 0.03134 (0.03134) | All Losses 0.03134 (0.03134)
[2022-07-23 18:06:47,481][feature_train_ori.py][L342][INFO] Step [27/2500000=0.00%] | Epoch 0 | Time 69.352 (69.352) | Lr 0.0001 | AIC Loss 0.02674 (0.02674) | All Losses 0.02674 (0.02674)
[2022-07-23 18:07:57,034][feature_train_ori.py][L342][INFO] Step [28/2500000=0.00%] | Epoch 0 | Time 69.505 (69.505) | Lr 0.0001 | AIC Loss 0.03341 (0.03341) | All Losses 0.03341 (0.03341)
[2022-07-23 18:09:07,235][feature_train_ori.py][L342][INFO] Step [29/2500000=0.00%] | Epoch 0 | Time 70.153 (70.153) | Lr 0.0001 | AIC Loss 0.02649 (0.02649) | All Losses 0.02649 (0.02649)
[2022-07-23 18:10:17,190][feature_train_ori.py][L342][INFO] Step [30/2500000=0.00%] | Epoch 0 | Time 69.907 (69.907) | Lr 0.0001 | AIC Loss 0.02352 (0.02352) | All Losses 0.02352 (0.02352)
[2022-07-23 18:11:44,659][feature_train_ori.py][L342][INFO] Step [31/2500000=0.00%] | Epoch 0 | Time 71.837 (71.837) | Lr 0.0001 | AIC Loss 0.02601 (0.02601) | All Losses 0.02601 (0.02601)
[2022-07-23 18:12:56,009][feature_train_ori.py][L342][INFO] Step [32/2500000=0.00%] | Epoch 0 | Time 71.287 (71.287) | Lr 0.0001 | AIC Loss 0.02272 (0.02272) | All Losses 0.02272 (0.02272)
[2022-07-23 18:14:08,045][feature_train_ori.py][L342][INFO] Step [33/2500000=0.00%] | Epoch 0 | Time 71.988 (71.988) | Lr 0.0001 | AIC Loss 0.02173 (0.02173) | All Losses 0.02173 (0.02173)
[2022-07-23 18:15:18,375][feature_train_ori.py][L342][INFO] Step [34/2500000=0.00%] | Epoch 0 | Time 70.281 (70.281) | Lr 0.0001 | AIC Loss 0.02176 (0.02176) | All Losses 0.02176 (0.02176)
[2022-07-23 18:16:28,472][feature_train_ori.py][L342][INFO] Step [35/2500000=0.00%] | Epoch 0 | Time 70.049 (70.049) | Lr 0.0001 | AIC Loss 0.02295 (0.02295) | All Losses 0.02295 (0.02295)
[2022-07-23 18:17:38,355][feature_train_ori.py][L342][INFO] Step [36/2500000=0.00%] | Epoch 0 | Time 69.835 (69.835) | Lr 0.0001 | AIC Loss 0.02072 (0.02072) | All Losses 0.02072 (0.02072)
[2022-07-23 18:18:48,464][feature_train_ori.py][L342][INFO] Step [37/2500000=0.00%] | Epoch 0 | Time 70.060 (70.060) | Lr 0.0001 | AIC Loss 0.02248 (0.02248) | All Losses 0.02248 (0.02248)
[2022-07-23 18:19:58,096][feature_train_ori.py][L342][INFO] Step [38/2500000=0.00%] | Epoch 0 | Time 69.583 (69.583) | Lr 0.0001 | AIC Loss 0.02699 (0.02699) | All Losses 0.02699 (0.02699)
[2022-07-23 18:21:06,773][feature_train_ori.py][L342][INFO] Step [39/2500000=0.00%] | Epoch 0 | Time 68.628 (68.628) | Lr 0.0001 | AIC Loss 0.02180 (0.02180) | All Losses 0.02180 (0.02180)
[2022-07-23 18:22:16,202][feature_train_ori.py][L342][INFO] Step [40/2500000=0.00%] | Epoch 0 | Time 69.380 (69.380) | Lr 0.0001 | AIC Loss 0.02137 (0.02137) | All Losses 0.02137 (0.02137)
